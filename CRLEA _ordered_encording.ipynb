{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 過去データを読み込む\n",
    "2. 数学だけ抜き出す\n",
    "3.　最終ペースに学年による有意差はあるか？\n",
    "4.　分野で分けた場合に、3はどうなる？\n",
    "5.　分野別最終ペースを多い順に並べて順序変数を振る\n",
    "6.　5を分野に代わる特徴料として使用する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "#ライブラリの読み込み\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f8f5e-c319-4e63-8814-18c1325b5d80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6552b818-9c06-4fd6-9b40-f3aa7491454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科目          0\n",
       "企画ペース     171\n",
       "最終ペース       0\n",
       "年度          0\n",
       "採点回         0\n",
       "学年          0\n",
       "分野1         0\n",
       "分野2         0\n",
       "ポイント採点      0\n",
       "文字数         0\n",
       "ポイント数       0\n",
       "配点          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ読み込み マークダウンにしてあるから必要ならコードセルにする\n",
    "\"\"\"\n",
    "data1を加工したcsvファイルを読み込む場合　\n",
    "\"\"\"\n",
    "\n",
    "name_csv = \"crlea_bunya_dm_0613received_0613cleaned_filled_test.csv\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#データが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "df = pd.read_csv(filepath_or_buffer = path_file, sep=\",\",\n",
    "                 usecols=['科目',\n",
    "                          '分野名_修正v1',\n",
    "                          '分野名_修正v2',\n",
    "                          'ポイント採点',\n",
    "                          '年度',\n",
    "                          '採点回',\n",
    "                          '学年',\n",
    "                          '置換後のポイント数',\n",
    "                          # '置換後の文字数',\n",
    "                          '置換後の文字数5',\n",
    "                          # '解答言語',\n",
    "                          '置換後の配点',\n",
    "                          '企画ペース',\n",
    "                          '最終ペース'])\n",
    "#列のリネーム\n",
    "df = df.rename(columns={'分野名_修正v1':'分野1',\n",
    "                        '分野名_修正v2':'分野2',\n",
    "                        '置換後のポイント数':'ポイント数',\n",
    "                        # '置換後の文字数':'文字数',#英語1単語も1文字として数えた\n",
    "                        '置換後の文字数5':'文字数',#英語１単語を5文字とした。前の分析ではこっち。精度を比較する。\n",
    "                        '置換後の配点':'配点'})\n",
    "df_raw = df\n",
    "\n",
    "df1 = df_raw\n",
    "df1 = df1.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1cd74-2b99-44c8-8bab-6d91faa9653c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9115482-7b20-4f68-8ea8-45b367e2f4e4",
   "metadata": {},
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b81a0-3fe3-4721-815b-04fd8f09c98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f54609d-bcf8-4526-8f09-8f10be8bb204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n作業方針\\n20年と２１年で分ける\\n２０年の分野別最終ペース平均を作る\\n２１年にマージする\\n２１年の夏とそれ以外で機械学習を実施\\n結果を検証する\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "作業方針\n",
    "20年と２１年で分ける\n",
    "２０年の分野別最終ペース平均を作る\n",
    "２１年にマージする\n",
    "２１年の夏とそれ以外で機械学習を実施\n",
    "結果を検証する\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c090252e-59f4-4e37-b329-f5018cb46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_20to21_order(df):\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df = df[df['科目']==\"数学\"]\n",
    "\n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "\n",
    "    bunya1 = df1.groupby('分野1', as_index=False)['最終ペース'].mean()\n",
    "    bunya1= bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya1=bunya1.sort_values('分野1TS',ascending=True).reset_index()\n",
    "    order =pd.Series(data = [1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8])\n",
    "    bunya1['分野1_order']=order\n",
    "\n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key='分野1')\n",
    "    \n",
    "    df2 = df2.drop(columns = ['index','分野1TS','分野2'])\n",
    "\n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b6a2a1b-ed6a-4f46-b9b6-c4742d4d81d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "90\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:16\n",
      "mergeのオブザベーション:106\n",
      "X_train66\n",
      "X_testは66\n",
      "y_trainは40\n",
      "y_testは40\n"
     ]
    }
   ],
   "source": [
    "#データ数のチェック\n",
    "df2 = te_20to21_order(df_raw)\n",
    "print(\"X_train\" + str(len(df2[0])))\n",
    "print(\"X_testは\" + str(len(df2[1])))\n",
    "print(\"y_trainは\" + str(len(df2[2])))\n",
    "print(\"y_testは\" + str(len(df2[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4f556ba-5873-4f54-a22b-aedbc2b9c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>科目</th>\n",
       "      <th>学年</th>\n",
       "      <th>分野1</th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>文字数</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野1_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>数学</td>\n",
       "      <td>1</td>\n",
       "      <td>数と式</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>数学</td>\n",
       "      <td>1</td>\n",
       "      <td>場合の数と確率</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>数学</td>\n",
       "      <td>1</td>\n",
       "      <td>整数の性質</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>数学</td>\n",
       "      <td>1</td>\n",
       "      <td>図形の性質</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>数学</td>\n",
       "      <td>2</td>\n",
       "      <td>場合の数と確率</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   科目  学年      分野1  ポイント採点  文字数  ポイント数  配点  分野1_order\n",
       "0  数学   1      数と式     0.0    3     10  10          4\n",
       "1  数学   1  場合の数と確率     0.0    3     10  20          6\n",
       "2  数学   1    整数の性質     0.0    3     10  20          3\n",
       "3  数学   1    図形の性質     0.0    3     10  20          4\n",
       "4  数学   2  場合の数と確率     0.0    3     10  40          6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cb78947-b274-4a34-9dbc-de9daa6349d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def test_model(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    kikaku = df[4]\n",
    "    kamoku = df[5]\n",
    "    rem_cols= [\"科目\",\"分野1\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    \n",
    "    X_test_excel = df[2]\n",
    "    rem_cols= [\"科目\"]\n",
    "    X_test_excel = X_test_excel.drop(columns = rem_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    #得た結果の樹形図を表示する\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    \n",
    "    #検証に使った説明変数データのダミー変数を元に戻す\n",
    "    df_res = X_test_excel \n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'企画ペース']= kikaku\n",
    "    df_res.loc[:,'科目']= kamoku\n",
    "    df_res.loc[:,'誤差']= df_res['AI想定ペース']-df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI想定ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "            \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d24250a9-ed53-4c15-b7cc-95fb9b10f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_leaf(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    rem_cols= [\"科目\",\"分野1\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    X_train_feature_names = X_train.columns.values.tolist() \n",
    "  \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "                                feature_names= X_train_feature_names,\n",
    "                                # class_names=iris.target_names,\n",
    "                                filled=True, rounded=True, special_characters=True\n",
    "                               ) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04731d-161c-47f6-93b4-48e3fe78f334",
   "metadata": {},
   "source": [
    "# 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9380392-3858-46ff-9b47-6ddd43087d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "90\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:16\n",
      "mergeのオブザベーション:106\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "\n",
    "df_v = test_model(te_20to21_order(df_raw))\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,['最終ペース','企画ペース','AI想定ペース','誤差','AI乖離度','元の乖離度']])[0]\n",
    "\n",
    "\n",
    "name_excel_output = \"分野別ペース順序変数8_20target_21機械学習_分野1TS.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9f3db2d-0f8a-4398-b3a3-083f0c8c98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "90\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:16\n",
      "mergeのオブザベーション:106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/s.ogura/Documents/CRLEA/data/output/分野別ペース順序変数8_20target_21機械学習_分野1TS.pdf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = te_20to21_order(df_raw)\n",
    "fig = make_leaf(df)\n",
    "\n",
    "name_file = \"分野別ペース順序変数8_20target_21機械学習_分野1TS\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "fig.render(path_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
