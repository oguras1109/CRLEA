{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2939ce7a-f8cf-4972-8c5f-8052e41e0851",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "2023.1.13作成<br>\n",
    "1. 21年、22年夏、22年冬の採点者情報を使用。採点者品質予測_22冬納品_前処理済み学習データ_v2.xlsx\n",
    "2. 学年情報と科目情報を削除し、科目別に分離\n",
    "3. 設問情報を読み込み。科目別に学年と分野の組み合わせを作成\n",
    "4. 22冬データに組み合わせ表を結合。これを予測用訓練データとする。\n",
    "5. 21年と22夏データを読み込む。21年データを学習データに、22夏データを検証データとする。\n",
    "6. 上記の二つのデータフレームを結合し、学習データ、検証データ、予測データのラベルをつける\n",
    "7. モデルを作成し、予測値をリストとして出力\n",
    "\n",
    "データ加工に使用しているスクリプト<br>\n",
    "採点者品質予測_22冬納品_前処理_1226_V1.IPYNB<br>\n",
    "採点者品質予測_22冬納品_機械学習_1226_V1.IPYNB<br>\n",
    "\n",
    "reference:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9cd9a-867a-4d6e-821e-b128df0410e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ce6306-52f5-447d-b30f-374896262f13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "import scipy as sp\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report #2値分類評価指標を出力\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6061074-af24-48fb-bd60-c8d5f1ae3e33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7ddf0-5982-49fc-a669-f1f92ab58026",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 予測値リストの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58fd282-0fdd-46c1-aa6f-5303379887db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 前処理済みデータを読み込み,予測データに学年分野を組み合わせて追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4d22b4-3e1a-46f9-a360-279e1acc96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの読み込み\n",
    "\"\"\"\n",
    "name_file = \"採点者品質予測_22冬納品_前処理済み学習データ_v2.xlsx\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "#sn_list ['整形済みデータ', '前処理済みデータ', '機械学習用データ_新人', '機械学習用データ_経験者', '機械学習用データ_etc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4c1cb7-6bfc-46c4-a247-b7ac2d68bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excelファイルの読み込み\n",
    "df_shinjin = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None)\n",
    "df_keiken = pd.read_excel(path_file, sn_list[3], header=0, index_col=None,skiprows=None)\n",
    "df_etc = pd.read_excel(path_file, sn_list[4], header=0, index_col=None,skiprows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a0c679-1a05-44a1-95dc-5d8ef75c65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keiken = df_keiken.rename(columns = {'今回の分野':'分野'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2623ddc-7f22-4f5a-87cb-0b5485962fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021, 2022])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shinjin['年度'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "82a64a20-ec9c-4589-a304-ac99c14f06ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13850"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_shinjin['data']==2)+len(df_keiken['data']==2)+len(df_etc['data']==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec6d8cb-f79c-499b-80ab-80345a6ad3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remake_bunya(df_input):\n",
    "    df = df_input.copy()\n",
    "    #22冬データを選択\n",
    "    df_res = df[~(df['data']==2)]\n",
    "    df = df[df['data']==2]\n",
    "    #科目別に抽出\n",
    "    df_jpn = df[df['科目']=='国語']\n",
    "    df_math= df[df['科目']=='数学']\n",
    "    df_eng = df[df['科目']=='英語']\n",
    "    dfs = [df_jpn, df_math, df_eng]\n",
    "    for i in dfs:\n",
    "        #分野と学年のユニーク値を取得し、データフレーム化して結合キーを付加\n",
    "        df_bunya=pd.DataFrame({'分野':i['分野'].unique()})\n",
    "        df_bunya['join_key']=0\n",
    "        df_gakunen=pd.DataFrame({'学年':i['学年'].unique()})\n",
    "        df_gakunen['join_key']=0\n",
    "        #全結合 crossjoinを行う\n",
    "        df_bunya_gakunen = pd.merge(df_bunya, df_gakunen,  on=\"join_key\")\n",
    "        df_bunya_gakunen['join_key']=0\n",
    "        #元の分野を削除し、結合キーを付加\n",
    "        df_temp = i.drop(columns = {'分野','学年'})\n",
    "        df_temp['join_key']=0\n",
    "        #全結合 crossjoinを行う\n",
    "        df_test = pd.merge(df_temp, df_bunya_gakunen,  on=\"join_key\")\n",
    "        df_test = df_test.drop(columns = 'join_key')\n",
    "        df_res = df_res.append(df_test)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ab929b-2904-4dc5-9d6f-c28e04ca41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pret_shinjin = remake_bunya(df_shinjin)\n",
    "df_pret_keiken = remake_bunya(df_keiken)\n",
    "df_pret_etc = remake_bunya(df_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7781c1db-0fe1-445e-9a5a-95f83f508b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021, 2022])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pret_shinjin['年度'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b559b9d-7b7a-4682-b165-dffcf32fc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "name = \"配置最適化_前処理済み学習データ_v2\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df1 = df_pret_shinjin\n",
    "df2 = df_pret_keiken\n",
    "df3 = df_pret_etc\n",
    "\n",
    "#Excel\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name)) as writer:\n",
    "    df1.to_excel(writer, sheet_name='機械学習用データ_新人',encoding='utf-8-sig', index = False)\n",
    "    df2.to_excel(writer, sheet_name='機械学習用データ_経験者',encoding='utf-8-sig', index = False)\n",
    "    df3.to_excel(writer, sheet_name='機械学習用データ_etc',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6e295-1a5d-4ad8-b67b-31ecab491b35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 予測値の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e7a49-c484-4850-a7dd-7ea4937ca203",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d2c1f-0272-4649-9daa-4e074861a8c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431c20fd-68b6-471e-8d0a-52495d95bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
    "ダミー変数を元に戻す。エクセル出力用\n",
    "\"\"\"\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f0ca3e-8082-4365-85e2-3d4b3e5ba249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '参加回数', '科目', '分野', '年度', '採点回', '学年', '完全一致率',\n",
       "       '登録試験点数', '身分', '年齢', '偏差値', 'data'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#機械学習に使うデータの前処理_新人用\n",
    "df_pret_shinjin.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c77996-b2a6-4da2-bb4f-ee5ed133e9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_shinjin(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df_pred = df[df['data']==2].copy()\n",
    "    \n",
    "    #rem_y = '参加回数'\n",
    "    use_y = '完全一致率'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    #df = df.drop(columns = rem_y)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8e4d34-a48b-4efd-9832-01b6a261eed3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_shinjin(df_input):#オリジナル\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    #0の場合、完全一致率を予測。　1の場合、最終ペース相対値を予測\n",
    "    rem_y = '参加回数'\n",
    "    use_y = '完全一致率'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_y)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==2022))]#秋に変更するところ\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==2022))]#秋に変更するところ\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==2022)]#秋に変更するところ\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==2022)]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a61cb7-72e1-40df-8aff-1d20c952577b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '前回の参加回数', '前回の分野', '前回の完全一致率', '科目', '今回の参加回数', '分野',\n",
       "       '今回の年度', '今回の採点回', '学年', '今回の完全一致率', '登録試験点数', '身分', '年齢', '偏差値',\n",
       "       'data'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pret_keiken.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0395927-8249-45ab-beca-970434a9a4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_keiken(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df_pred = df[df['data']==2].copy()\n",
    "    df_pred = df_pred.rename(columns = {'今回の採点回':'採点回',#0始まりで数えているため、\n",
    "                             '今回の年度':'年度',\n",
    "                             '今回の参加回数':'参加回数',\n",
    "                             '今回の分野':'分野'})\n",
    "    rem_y = ['前回の分野','前回の参加回数']\n",
    "    use_y = '今回の完全一致率'\n",
    "\n",
    "    \n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_y)\n",
    "    df = df.rename(columns = {'今回の採点回':'採点回',#0始まりで数えているため、\n",
    "                             '今回の年度':'年度',\n",
    "                             '今回の参加回数':'参加回数',\n",
    "                             '今回の分野':'分野'})\n",
    "\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['data',use_y]]#目的変数と選択用変数だけ含むデータフレーム　#秋に変更するところ\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]#秋に変更するところ\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]#秋に変更するところ\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]#秋に変更するところ\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]#秋に変更するところ\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"data\"]\n",
    "    rem_cols_y = [\"data\"]#秋に変更するところ\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c21beac-703f-49ad-bc12-e7bdc26db199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成\n",
    "\"\"\"\n",
    "def train_model(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=0,#出力結果の固定のため \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c8020e-4042-49fb-a82b-b81fd32e8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(df,model):\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_id = df[4]\n",
    "    X_test_kamoku = df[5]\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    \n",
    "    df_test=[]\n",
    "    df_test = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_test.loc[:,'スタッフコード']= X_test_id\n",
    "    df_test.loc[:,'科目']= X_test_kamoku\n",
    "    df_test.loc[:,'完全一致率']= y_test\n",
    "    df_test.loc[:,'AI想定完全一致率']= y_pred #上のデータに予測値をマージ\n",
    "    #学習データの同じ学年分野カテゴリの中の基礎統計量\n",
    "    df_train = undummify(X_train)\n",
    "    df_train.loc[:,'完全一致率'] = y_train\n",
    "    df_temp = df_train.groupby(['分野','学年'],as_index=False).agg(\n",
    "        学習データ_N数=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"count\"),\n",
    "        学習データ_平均値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"mean\"),\n",
    "        学習データ_中央値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"median\"),\n",
    "        学習データ_最大値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"max\"),\n",
    "        学習データ_最小値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"min\"))\n",
    "    df_res = pd.merge(df_test, df_temp, on=['分野', '学年'], how='left')\n",
    "    # 実測値_完全一致率をランク分け\n",
    "    x = \"完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'実測一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "\n",
    "        # AI想定完全一致率をランク分け 評価用\n",
    "    x = \"AI想定完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'想定一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4535cce-b753-455a-bcca-adbb764e10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(df,model):\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_id = df[4]\n",
    "    X_test_kamoku = df[5]\n",
    "    X_pred = df[6]\n",
    "    df_pred = df[7]\n",
    "    y_pred  = model.predict(X_pred)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    \n",
    "    df_test=[]\n",
    "    df_test = undummify(df_pred)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_test.loc[:,'AI想定完全一致率']= y_pred #上のデータに予測値をマージ\n",
    "    #学習データの同じ学年分野カテゴリの中の基礎統計量\n",
    "    df_train = undummify(X_train)\n",
    "    df_train.loc[:,'完全一致率'] = y_train\n",
    "    df_temp = df_train.groupby(['分野','学年'],as_index=False).agg(\n",
    "        学習データ_N数=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"count\"),\n",
    "        学習データ_平均値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"mean\"),\n",
    "        学習データ_中央値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"median\"),\n",
    "        学習データ_最大値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"max\"),\n",
    "        学習データ_最小値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"min\"))\n",
    "    df_res = pd.merge(df_test, df_temp, on=['分野', '学年'], how='left')\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d82a09-142a-45d9-b095-acead922ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証用\n",
    "def get_result_test(df_input,case=int):\n",
    "    df = df_input.copy()\n",
    "    df_temp=[]#[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    model = []\n",
    "    pred = []\n",
    "    #新人モデルの結果\n",
    "    if case == 0:\n",
    "        df_temp = make_data_shinjin(df)\n",
    "        model = train_model(df_temp,a=2,b=1,c=None)\n",
    "        pred = get_test(df_temp, model)\n",
    "    #経験者モデルの結果\n",
    "    elif case == 1:\n",
    "        df_temp = make_data_keiken(df)\n",
    "        model = train_model(df_temp,a=2,b=1,c=None)\n",
    "        pred = get_test(df_temp, model)\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6798686f-3190-4a57-8c09-f3025b0347b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測用\n",
    "def get_result_pred(df_input,case=int):\n",
    "    df = df_input.copy()\n",
    "    df_temp=[]#[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    model = []\n",
    "    pred = []\n",
    "    #新人モデルの結果\n",
    "    if case == 0:\n",
    "        df_temp = make_data_shinjin(df)\n",
    "        model = train_model(df_temp,a=2,b=1,c=None)\n",
    "        pred = get_pred(df_temp, model)\n",
    "    #経験者モデルの結果\n",
    "    elif case == 1:\n",
    "        df_temp = make_data_keiken(df)\n",
    "        model = train_model(df_temp,a=2,b=1,c=None)\n",
    "        pred = get_pred(df_temp, model)\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a389adb-dcf0-45ea-b366-fdcd8c6165f7",
   "metadata": {},
   "source": [
    "## 予測値の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd977d-90c8-4d70-b870-a1306a34a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_pred = get_result_pred(df_pret_shinjin, case = 0)#新人モデルの予測結果\n",
    "df2_pred = get_result_pred(df_pret_keiken, case = 1)#経験モデルの予測結果\n",
    "df3_pred = get_result_pred(df_pret_etc, case = 0)#経験（過去データなし）モデルの予測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "79f9dd25-6a06-4010-8b91-a67f8baf5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df_input):\n",
    "    df = df_input.copy()\n",
    "    collist=['スタッフコード','科目', '分野','学年','AI想定完全一致率']\n",
    "    df = df[collist]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f1d6810-69ca-4ecc-9c16-a21668450746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs(df_input):\n",
    "    df1 = select_columns(df_input[0])\n",
    "    df2 = select_columns(df_input[1])\n",
    "    df3 = select_columns(df_input[2])\n",
    "    df_res = df1.append(df2)\n",
    "    df_res = df_res.append(df3)\n",
    "    return df_res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7e940c9-46f0-4cd3-8410-f579de77cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = \"配置最適化_学年分野別予測値リスト_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "75114de7-2084-408c-b101-b44612a9532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = \"配置最適化_学年分野別予測値リスト_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "dfs = [df1_pred, df2_pred, df3_pred]\n",
    "df = get_dfs(dfs)\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df.to_excel(writer, sheet_name='予測値',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e0fe47b1-f8a7-40ae-a6c9-0a9d1a967e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1_pred, df2_pred, df3_pred]\n",
    "df_predlist = get_dfs(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c2dba-387f-4b8d-8285-a7f8107fe4c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 配属優先度と希望人数リストの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a82ca-dae6-4233-9af0-8a44d0dab139",
   "metadata": {},
   "source": [
    "### 希望人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "44a4f457-f803-435d-acff-9fa3658fbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "配置希望人数を読み込み\n",
    "\"\"\"\n",
    "name_file = \"22冬採点者配置希望人数.xlsx\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/rawdata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "#sn_list ['整形済みデータ', '前処理済みデータ', '機械学習用データ_新人', '機械学習用データ_経験者', '機械学習用データ_etc']\n",
    "\n",
    "df_eng = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=[1])#headerを修正 ,usecols = [0,1,2,3,4]\n",
    "df_jpn = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=[1])#headerを修正\n",
    "df_math = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None)#headerを修正\n",
    "df_math['科目'] = df_math['科目'].replace(['数学X', '数学Y', '数学Z','数学X/A\\u3000', '数学Y/B', '数学X/A・Y/B', '数学X/A'], '数学')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9855af72-d179-426c-8c84-2f726de5ea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "分野マスタを読み込み\n",
    "\"\"\"\n",
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/rawdata/分野区分マスタv4.1.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df_bunya = []\n",
    "df_bunya = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=None)#headerを修正\n",
    "df_bunya = df_bunya.drop(['科目コード','ポイント採点', '解答言語'], axis=1)\n",
    "#bunya = bunya.fillna({'解答言語': '日本語'})\n",
    "df_bunya = df_bunya.rename(columns={'分野名':'分野修正前'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cffa2707-29af-4f08-99da-ffc90dd7590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#国語、数学、英語のデータフレームを結合し、分野名を修正し、学年と分野でグループし、配置希望人数を合計したフレームを返す。\n",
    "def make_number(df_jpn, df_math, df_eng, df_bunya):\n",
    "    collist=['年度', '採点回', '学年', '科目', 'ロット番号','分野','配置希望人数']\n",
    "    df1=df_jpn[collist]\n",
    "    df2=df_math[collist]\n",
    "    df3=df_eng[collist]\n",
    "    df =[]\n",
    "    df = df1.append(df2)\n",
    "    df = df.append(df3)\n",
    "    df = df.rename(columns={'分野':'分野修正前','ロット番号':'割当'})\n",
    "    df = df.round({'配置希望人数': 0})\n",
    "    #分野の表記を修正\n",
    "    df_join = pandas_tool.merge(df,df_bunya, key = [\"分野修正前\"],how = 'left')\n",
    "    df_ret = df_join.groupby(['科目','分野','学年'],as_index=False).agg(配置希望人数=pd.NamedAgg(column=\"配置希望人数\", aggfunc=\"sum\"))\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a55284d6-c059-4508-828f-997de2cdb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "36\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:59\n",
      "df2のオブザベーション:164\n",
      "mergeのオブザベーション:59\n"
     ]
    }
   ],
   "source": [
    "df_number = make_number(df_jpn, df_math, df_eng, df_bunya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b244ba62-4ade-48be-b0a0-f7c61c159c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_学年分野配属人数リスト_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = df_number\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664216b-36a7-46cd-b0e2-b3f160d1815e",
   "metadata": {},
   "source": [
    "### 配属優先度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "11b885ba-fb9c-4445-a03a-7798f42fece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_priority(df_input1, df_input2, df_input3):\n",
    "    df1 = df_input1.copy()\n",
    "    df2 = df_input2.copy()\n",
    "    df3 = df_input3.copy()\n",
    "    dfs = df1.append(df2)\n",
    "    dfs = dfs.append(df3)\n",
    "    dfs = dfs[~(dfs['data']==2)]\n",
    "    collist=['スタッフコード','科目', '分野','学年','完全一致率']\n",
    "    dfs=dfs[collist]\n",
    "    dfs['科目'] = dfs['科目'].replace(['数学X', '数学Y', '数学Z','数学X/A\\u3000', '数学Y/B', '数学X/A・Y/B', '数学X/A'], '数学')\n",
    "    #分野の表記を修正\n",
    "    dfs = dfs.rename(columns={'分野':'分野修正前'})\n",
    "    df_join = pandas_tool.merge(dfs,df_bunya, key = [\"分野修正前\"],how = 'left')\n",
    "    #平均値の集計\n",
    "    df_join = df_join.groupby(['科目','分野','学年'],as_index=False).agg(平均完全一致率=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"mean\"))\n",
    "    \n",
    "    #列選択\n",
    "    collist=['科目', '分野','学年','平均完全一致率']\n",
    "    df = df_join[collist]\n",
    "    df_jpn = df[df['科目']=='国語']\n",
    "    df_jpn.loc[:, '優先度_修正前'] = df_jpn['平均完全一致率'].rank(method='min', ascending=True)\n",
    "    df_math = df[df['科目']=='数学']\n",
    "    df_math.loc[:, '優先度_修正前'] = df_math['平均完全一致率'].rank(method='min', ascending=True)\n",
    "    df_eng = df[df['科目']=='英語']\n",
    "    df_eng.loc[:, '優先度_修正前'] = df_eng['平均完全一致率'].rank(method='min', ascending=True)\n",
    "    df_ret = [df, df_jpn, df_math, df_eng]\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "887fae06-11b0-4e2d-89c8-22013538991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "10025\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:10057\n",
      "df2のオブザベーション:164\n",
      "mergeのオブザベーション:10057\n"
     ]
    }
   ],
   "source": [
    "df_priority_bef = make_priority(df_shinjin, df_keiken, df_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "be8eed55-a6cb-4439-a5d8-9f17dde59d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_学年分野優先度リスト_修正前_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = df_priority_bef\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[0].to_excel(writer, sheet_name='全科目',encoding='utf-8-sig', index = False)\n",
    "    df[1].to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df[2].to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c2894-07a0-40a9-9cc1-77f7a33b6da2",
   "metadata": {},
   "source": [
    "### dfの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b759836b-f9de-4e13-ab53-5d92fdf0b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "配属優先度を読み込み\n",
    "\"\"\"\n",
    "name_file = \"配置最適化_学年分野優先度リスト_修正後_v1.xlsx\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df1 = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=None)#国語\n",
    "df2 = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None)#数学\n",
    "df3 = pd.read_excel(path_file, sn_list[3], header=0, index_col=None,skiprows=None)#英語\n",
    "df_priority_aft=[df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "44c38de1-7378-4c35-a3ab-e68889331b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分野の表記を修正\n",
    "def merge_number_priority(df_input1, df_number):\n",
    "    df1 = df_input1.copy()\n",
    "    #優先度と配属人数の結合\n",
    "    df_jpn = pandas_tool.merge(df1[0], df_number, key = [\"科目\",\"分野\",\"学年\"],how = 'left')\n",
    "    df_math = pandas_tool.merge(df1[1], df_number, key = [\"科目\",\"分野\",\"学年\"],how = 'left')\n",
    "    df_eng = pandas_tool.merge(df1[2], df_number, key = [\"科目\",\"分野\",\"学年\"],how = 'left')\n",
    "    #配属人数が空欄の行を削除。つまり今回の設問にない分野を削除\n",
    "    df_jpn = df_jpn.dropna(subset=['配置希望人数'])\n",
    "    df_math = df_math.dropna(subset=['配置希望人数'])\n",
    "    df_eng = df_eng.dropna(subset=['配置希望人数'])\n",
    "    #優先度を修正\n",
    "    df_jpn.loc[:, '優先度'] = df_jpn['優先度_修正後'].rank(method='min', ascending=True)\n",
    "    df_math.loc[:, '優先度'] = df_math['優先度_修正後'].rank(method='min', ascending=True)\n",
    "    df_eng.loc[:, '優先度'] = df_eng['優先度_修正後'].rank(method='min', ascending=True)\n",
    "    #優先度で並び替え\n",
    "    df_jpn= df_jpn.sort_values('優先度', ascending=True).reset_index(drop=True)\n",
    "    df_math= df_math.sort_values('優先度', ascending=True).reset_index(drop=True)\n",
    "    df_eng= df_eng.sort_values('優先度', ascending=True).reset_index(drop=True)\n",
    "    #列選択\n",
    "    collist=['科目', '分野','学年','配置希望人数','優先度']\n",
    "    df_jpn = df_jpn[collist]\n",
    "    df_math = df_math[collist]\n",
    "    df_eng = df_eng[collist]\n",
    "    #データタイプの変換\n",
    "    df_jpn = df_jpn.astype({'配置希望人数': int})\n",
    "    df_math = df_math.astype({'配置希望人数': int})\n",
    "    df_eng = df_eng.astype({'配置希望人数': int})\n",
    "    \n",
    "    return [df_jpn, df_math, df_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "614cc150-ec1c-488d-8004-10cc228493a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:20\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:20\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:29\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:29\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:17\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:17\n"
     ]
    }
   ],
   "source": [
    "df_prilist = merge_number_priority(df_priority_aft, df_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1cd58d4a-03f8-452b-be12-1ad3a48f014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科目         object\n",
       "分野         object\n",
       "学年          int64\n",
       "配置希望人数      int64\n",
       "優先度       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prilist[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "938e87e9-ea07-4b18-88b5-ba8cafc8c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_学年分野優先度配属人数リスト_v2\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = df_prilist\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[0].to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df[1].to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df[2].to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc91744-37e9-4f69-817d-18d07092ec41",
   "metadata": {},
   "source": [
    "# 最適化アルゴリズム構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36f679-7c54-4122-8d61-5e33ad4515f0",
   "metadata": {},
   "source": [
    "## データマートの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f19d4723-02a5-4984-b5c4-ddd3a0792f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "予測値リストを読み込み\n",
    "\"\"\"\n",
    "name_file = \"配置最適化_学年分野別予測値リスト_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=None)\n",
    "df_predlist = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "af771408-31d6-4459-a22a-723a90e26c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "配属優先度を読み込み\n",
    "\"\"\"\n",
    "name_file = \"配置最適化_学年分野優先度配属人数リスト_v2.xlsx\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df1 = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=None)#国語\n",
    "df2 = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=None)#数学\n",
    "df3 = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None)#英語\n",
    "df_prilist=[df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6cf4c248-b858-4ef6-861e-e66aee8bcf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>科目</th>\n",
       "      <th>分野</th>\n",
       "      <th>学年</th>\n",
       "      <th>配置希望人数</th>\n",
       "      <th>優先度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>国語</td>\n",
       "      <td>小説</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>国語</td>\n",
       "      <td>小説</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>国語</td>\n",
       "      <td>古文(内説)</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   科目      分野  学年  配置希望人数  優先度\n",
       "0  国語      評論   2     190    1\n",
       "1  国語      評論   1     205    2\n",
       "2  国語      小説   1     154    3\n",
       "3  国語      小説   2     190    4\n",
       "4  国語  古文(内説)   1      87    5"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#優先度リスト 国語\n",
    "df_prilist[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "77f781e9-880c-464d-8cc2-97fdd2fb5a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>スタッフコード</th>\n",
       "      <th>科目</th>\n",
       "      <th>分野</th>\n",
       "      <th>学年</th>\n",
       "      <th>AI想定完全一致率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1060604673</td>\n",
       "      <td>国語</td>\n",
       "      <td>古文(内説)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1060604673</td>\n",
       "      <td>国語</td>\n",
       "      <td>古文(内説)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060604673</td>\n",
       "      <td>国語</td>\n",
       "      <td>古文(現訳)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1060604673</td>\n",
       "      <td>国語</td>\n",
       "      <td>古文(現訳)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1060604673</td>\n",
       "      <td>国語</td>\n",
       "      <td>小説</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      スタッフコード  科目      分野  学年  AI想定完全一致率\n",
       "0  1060604673  国語  古文(内説)   1   0.833333\n",
       "1  1060604673  国語  古文(内説)   2   0.833333\n",
       "2  1060604673  国語  古文(現訳)   1   0.833333\n",
       "3  1060604673  国語  古文(現訳)   2   0.833333\n",
       "4  1060604673  国語      小説   1   0.821429"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測リスト\n",
    "df_predlist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0cf5f893-326d-4d8e-94f7-79aa4f3d8896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '科目', '分野', '学年', 'AI想定完全一致率'], dtype=object)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測リスト\n",
    "df_predlist.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a62c9-cd34-45cf-9028-70a0b1e23242",
   "metadata": {},
   "source": [
    "## アルゴリズム1\n",
    "優先度の高い分野から必要人数ずつ割当てていくケース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d66e8d15-5365-425f-86aa-9cd1783b6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg1(df_predlist, df_prilist):\n",
    "    \"\"\"\n",
    "    優先度リストから、優先度の高い分野から順に、分野名と人数を参照する for enumerate\n",
    "    予測値リストから、分野名でフィルタリングし、予測値でソートをして、高い順に必要人数を選択\n",
    "    結果を学年分野で集計し、優先度リストに結合\n",
    "    \"\"\"\n",
    "    df_pred = df_predlist.copy()#予測値リスト\n",
    "    df_pri = df_prilist.copy()\n",
    "    df_res = pd.DataFrame(columns=['スタッフコード', '科目', '分野', '学年', 'AI想定完全一致率'])\n",
    "\n",
    "    #科目を選択\n",
    "    kamoku =[0,1,2]\n",
    "    for k in kamoku:#科目を選択\n",
    "        for idx, value in enumerate(df_pri[k]['優先度']):#分野名を選択\n",
    "            # print(idx)\n",
    "            bunya = df_pri[k].at[idx,'分野']#分野\n",
    "            gakunen = df_pri[k].at[idx,'学年']#学年\n",
    "            ninzu = df_pri[k].at[idx,'配置希望人数']#配置希望人数\n",
    "            # print(bunya, gakunen, ninzu)\n",
    "            \n",
    "            #予測値リストを優先度に従って分野名と学年でフィルタ\n",
    "            df_temp = df_pred[(df_pred['分野']==bunya)&(df_pred['学年']==gakunen)]\n",
    "            #予測値を降順で並び替え\n",
    "            df_temp = df_temp.sort_values('AI想定完全一致率', ascending=False)\n",
    "            #配置希望人数を取得\n",
    "            df_temp =df_temp.iloc[:ninzu,:]\n",
    "            #選択結果を結果のデータフレームに保存\n",
    "            df_res = df_res.append(df_temp)\n",
    "            #取得したスタッフコードを削除\n",
    "            selected_staff = pd.Series(df_temp['スタッフコード'].unique())\n",
    "            df_pred = df_pred[~(df_pred['スタッフコード'].isin(selected_staff))]#選択されたスタッフコードを削除\n",
    "    \n",
    "    #結果の集計\n",
    "    col_name = 'AI想定完全一致率'\n",
    "    df_agg = df_res.groupby(['分野','学年'],as_index=False).agg(\n",
    "        AI配置人数=pd.NamedAgg(column = col_name, aggfunc=\"count\"),\n",
    "        AI想定完全一致率_平均値=pd.NamedAgg(column = col_name, aggfunc=\"mean\"),\n",
    "        AI想定完全一致率_中央値=pd.NamedAgg(column = col_name, aggfunc=\"median\"),\n",
    "        AI想定完全一致率_最大値=pd.NamedAgg(column = col_name, aggfunc=\"max\"),\n",
    "        AI想定完全一致率_最小値=pd.NamedAgg(column = col_name, aggfunc=\"min\"))\n",
    "\n",
    "    #優先度と配属人数の結合\n",
    "    df_jpn = pandas_tool.merge(df_pri[0], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_math = pandas_tool.merge(df_pri[1], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_eng = pandas_tool.merge(df_pri[2], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    \n",
    "    return [df_res, df_jpn, df_math, df_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "47ae7627-5dd0-41f6-962e-22ecd476cfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:11\n",
      "df2のオブザベーション:34\n",
      "mergeのオブザベーション:11\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:16\n",
      "df2のオブザベーション:34\n",
      "mergeのオブザベーション:16\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:8\n",
      "df2のオブザベーション:34\n",
      "mergeのオブザベーション:8\n"
     ]
    }
   ],
   "source": [
    "alg1_result = alg1(df_predlist, df_prilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e61d59c1-5f05-4c43-b81e-7125fbcb627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_結果_アルゴリズム_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = alg1_result\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[0].to_excel(writer, sheet_name='alg1',encoding='utf-8-sig', index = False)\n",
    "    df[1].to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df[2].to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10dba0d-4c75-4f5b-a641-14cc4b4715e3",
   "metadata": {},
   "source": [
    "## アルゴリズム2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "5736949f-4c6d-4642-a11e-e91ca982dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "def alg2(df_predlist, df_prilist):\n",
    "    \"\"\"   \n",
    "    学年分野別優先度と人数リストを読み込み\n",
    "    学年分野別予測値リストを読み込んで、科目別に分割してデータフレームに入れる\n",
    "    科目別に選択して回す\n",
    "    分野に希望人数以上配置しないように、処理用の列を作る。\n",
    "    \"\"\"\n",
    "    df_pris = df_prilist.copy()\n",
    "    \n",
    "    #df_predlistを科目別に分割し、df_predsとして、[国語、数学、英語]で作成。リストの中にデータフレーム\n",
    "    df_pred_jpn = df_predlist[df_predlist['科目']=='国語'].copy()#予測値リスト\n",
    "    df_pred_math = df_predlist[df_predlist['科目']=='数学'].copy()#予測値リスト\n",
    "    df_pred_eng = df_predlist[df_predlist['科目']=='英語'].copy()#予測値リスト\n",
    "    df_preds = [df_pred_jpn, df_pred_math, df_pred_eng]\n",
    "    \n",
    "    df_res = pd.DataFrame(columns=['スタッフコード', '科目', '分野', '学年', 'AI想定完全一致率'])\n",
    "    \n",
    "    #for文 0,1,2で国語、数学、英語を科目別に取得して回す\n",
    "    kamoku =[0,1,2]\n",
    "    for k in kamoku:\n",
    "        df_pri = df_pris[k].copy() #優先度リスト\n",
    "        #df_priにAI配置人数_cntという列を追加。初期値は配置希望人数\n",
    "        df_pri['AI配置人数_cnt'] = df_pri['配置希望人数']\n",
    "        df_pred = df_preds[k] #予測値リスト\n",
    "        N = len(df_pred['スタッフコード'].unique())\n",
    "        while N > 0:\n",
    "            #優先度リストから、AI配置人数が0の分野を除外\n",
    "            df_pri = df_pri[df_pri['AI配置人数_cnt'] != 0]\n",
    "            df_pri = df_pri.reset_index(drop=True)\n",
    "            # yusend_list = df_pri['優先度'].unique().tolist().sort(reverse=False)\n",
    "            yusend_list = sorted(df_pri['優先度'].unique().tolist())\n",
    "            for i in yusend_list:\n",
    "                #df_priからランダムに取得した優先度の値を持つレコードの分野と学年の値を取得\n",
    "                idx = df_pri.query('優先度 == @i').index[0]\n",
    "                bunya = df_pri.at[idx,'分野']#分野\n",
    "                gakunen = df_pri.at[idx,'学年']#学年\n",
    "                ninzu = df_pri.at[idx,'AI配置人数_cnt']#配置希望人数\n",
    "                df_pri.at[idx,'AI配置人数_cnt'] = ninzu -1#AI配置人数_cntから1を引く.0になった分野はもう選択しない。\n",
    "                #候補者リストから分野と学年に一致するレコードを取得し、df_tempに追加\n",
    "                df_temp = df_pred[(df_pred['分野']==bunya)&(df_pred['学年']==gakunen)]\n",
    "                #予測値を降順で並び替え\n",
    "                df_temp = df_temp.sort_values('AI想定完全一致率', ascending=False)\n",
    "                #先頭を取得\n",
    "                df_temp = df_temp[0:1]\n",
    "                #選択結果を結果のデータフレームに保存\n",
    "                df_res = df_res.append(df_temp)\n",
    "                #取得したスタッフコードを削除\n",
    "                selected_staff = pd.Series(df_temp['スタッフコード'].unique())\n",
    "                df_pred = df_pred[~(df_pred['スタッフコード'].isin(selected_staff))]#選択されたスタッフコードを削除\n",
    "                if len(df_pred)==0:#候補者全員を配置し終わった\n",
    "                    break\n",
    "            N -= len(yusend_list)\n",
    "            \n",
    "    #結果の集計\n",
    "    col_name = 'AI想定完全一致率'\n",
    "    df_agg = df_res.groupby(['分野','学年'],as_index=False).agg(\n",
    "        AI配置人数=pd.NamedAgg(column = col_name, aggfunc=\"count\"),\n",
    "        予測値_平均値=pd.NamedAgg(column = col_name, aggfunc=\"mean\"),\n",
    "        予測値_中央値=pd.NamedAgg(column = col_name, aggfunc=\"median\"),\n",
    "        予測値_最大値=pd.NamedAgg(column = col_name, aggfunc=\"max\"),\n",
    "        予測値_最小値=pd.NamedAgg(column = col_name, aggfunc=\"min\"))\n",
    "\n",
    "    #優先度と配属人数の結合\n",
    "    df_jpn = pandas_tool.merge(df_pris[0], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_math = pandas_tool.merge(df_pris[1], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_eng = pandas_tool.merge(df_pris[2], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    \n",
    "    return [df_res, df_jpn, df_math, df_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0427c911-cc62-44c0-b34a-f0357b621252",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:11\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:11\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:16\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:16\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:8\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:8\n"
     ]
    }
   ],
   "source": [
    "alg2_result = alg2(df_predlist, df_prilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "a154b624-98ea-4f18-bb0e-8ebcda4642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_結果_アルゴリズム2_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = alg2_result\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[0].to_excel(writer, sheet_name='ctr',encoding='utf-8-sig', index = False)\n",
    "    df[1].to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df[2].to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57c083-4bde-4ece-80a4-d12c40b09b52",
   "metadata": {},
   "source": [
    "## コントロール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "dd14e974-a510-4d13-ad98-9090b198d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "def ctr(df_predlist, df_prilist):\n",
    "    \"\"\"   \n",
    "    \"\"\"\n",
    "    df_pris = df_prilist.copy()\n",
    "    \n",
    "    #df_predlistを科目別に分割し、df_predsとして、[国語、数学、英語]で作成。リストの中にデータフレーム\n",
    "    df_pred_jpn = df_predlist[df_predlist['科目']=='国語'].copy()#予測値リスト\n",
    "    df_pred_math = df_predlist[df_predlist['科目']=='数学'].copy()#予測値リスト\n",
    "    df_pred_eng = df_predlist[df_predlist['科目']=='英語'].copy()#予測値リスト\n",
    "    df_preds = [df_pred_jpn, df_pred_math, df_pred_eng]\n",
    "    \n",
    "    df_res = pd.DataFrame(columns=['スタッフコード', '科目', '分野', '学年', 'AI想定完全一致率'])\n",
    "    \n",
    "    #for文 0,1,2で国語、数学、英語を科目別に取得して回す\n",
    "    kamoku =[0,1,2]\n",
    "    for k in kamoku:\n",
    "        df_pri = df_pris[k].copy() #優先度リスト\n",
    "        #df_priにAI配置人数_cntという列を追加。初期値は配置希望人数で埋める. \n",
    "        df_pri['AI配置人数_cnt'] = df_pri['配置希望人数']\n",
    "        df_pred = df_preds[k] #予測値リスト\n",
    "        list_temp = list(df_pred['スタッフコード'].unique())\n",
    "        random_id = random.sample(list_temp, len(list_temp))#予測値リストが含むスタッフコードをランダムに並べたリスト\n",
    "        #df_random_idに該当するレコード（採点者）をdf_predから順番に取得(df_candidate)\n",
    "        for r in random_id:\n",
    "            df_candidate = df_pred[df_pred['スタッフコード'] == r]#ランダムに選んだ候補者\n",
    "            \n",
    "            #優先度リストから、AI配置人数が0の分野を除外\n",
    "            df_pri = df_pri[df_pri['AI配置人数_cnt'] != 0]\n",
    "            df_pri = df_pri.reset_index(drop=True)\n",
    "            \n",
    "            #df_priからランダムに取得した優先度の値を持つレコードの分野と学年の値を取得\n",
    "            yusendo = random.choice(df_pri['優先度'].unique())\n",
    "            idx = df_pri.query('優先度 == @yusendo').index[0]\n",
    "            bunya = df_pri.at[idx,'分野']#分野\n",
    "            gakunen = df_pri.at[idx,'学年']#学年\n",
    "            ninzu = df_pri.at[idx,'AI配置人数_cnt']#配置希望人数\n",
    "            \n",
    "            #AI配置人数_cntから1を引く.0になった分野はもう選択しない。\n",
    "            df_pri.at[idx,'AI配置人数_cnt'] = ninzu -1\n",
    "            \n",
    "            #候補者リストから分野と学年に一致するレコードを取得し、df_tempに追加\n",
    "            df_temp = df_candidate[(df_candidate['分野']==bunya)&(df_candidate['学年']==gakunen)]\n",
    "            #選択結果を結果のデータフレームに保存\n",
    "            df_res = df_res.append(df_temp)\n",
    "    \n",
    "    #結果の集計\n",
    "    col_name = 'AI想定完全一致率'\n",
    "    df_agg = df_res.groupby(['分野','学年'],as_index=False).agg(\n",
    "        AI配置人数=pd.NamedAgg(column = col_name, aggfunc=\"count\"),\n",
    "        予測値_平均値=pd.NamedAgg(column = col_name, aggfunc=\"mean\"),\n",
    "        予測値_中央値=pd.NamedAgg(column = col_name, aggfunc=\"median\"),\n",
    "        予測値_最大値=pd.NamedAgg(column = col_name, aggfunc=\"max\"),\n",
    "        予測値_最小値=pd.NamedAgg(column = col_name, aggfunc=\"min\"))\n",
    "\n",
    "    #優先度と配属人数の結合\n",
    "    df_jpn = pandas_tool.merge(df_pris[0], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_math = pandas_tool.merge(df_pris[1], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_eng = pandas_tool.merge(df_pris[2], df_agg, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    \n",
    "    return [df_res, df_jpn, df_math, df_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3ee08875-7253-4f7b-a1d6-06f2447d5010",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:11\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:11\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:16\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:16\n",
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:8\n",
      "df2のオブザベーション:35\n",
      "mergeのオブザベーション:8\n"
     ]
    }
   ],
   "source": [
    "ctr_result = ctr(df_predlist, df_prilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "243f59f0-406d-4b03-a616-12ff01be784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "name_file = \"配置最適化_結果_コントロール_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "#結果出力\n",
    "df = ctr_result\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[0].to_excel(writer, sheet_name='ctr',encoding='utf-8-sig', index = False)\n",
    "    df[1].to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df[2].to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbe981-bf15-4be5-b8cb-e80a897efcbe",
   "metadata": {},
   "source": [
    "## 配属人数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "db53dcc1-52af-486d-9d9f-9a769dbc6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#配属される人数 スタッフコードで重複削除\n",
    "df_N = df_predlist.copy().drop_duplicates(subset='スタッフコード')\n",
    "\n",
    "#科目別人数を確認\n",
    "df_N_jpn =df_N[df_N['科目']=='国語']\n",
    "df_N_math =df_N[df_N['科目']=='数学']\n",
    "df_N_eng =df_N[df_N['科目']=='英語']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0ccb797b-92c0-4720-a550-b9533cc965b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3793 1149 902 1742 3793\n"
     ]
    }
   ],
   "source": [
    "#配置した人数\n",
    "print(len(df_N), len(df_N_jpn), len(df_N_math), len(df_N_eng), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "88c26a00-1544-4df0-a188-09cccdda808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "受領データ:3887 エラーデータ：94 国語計画人数:1180 数学計画人数919 英語計画人数1787\n"
     ]
    }
   ],
   "source": [
    "#配置したい人数\n",
    "print('受領データ:3887', 'エラーデータ：94', '国語計画人数:1180', '数学計画人数919', '英語計画人数1787')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617cd7b-9f83-48ee-bc77-9cee8cac3f12",
   "metadata": {},
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "341e7b98-b161-494d-9ada-6907455749fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg1(df_predlist, df_prilist):\n",
    "    \"\"\"\n",
    "    優先度リストから、優先度の高い分野から順に、分野名と人数を参照する for enumerate\n",
    "    予測値リストから、分野名でフィルタリングし、予測値でソートをして、高い順に必要人数を選択\n",
    "    \n",
    "    \"\"\"\n",
    "    df_pred = df_predlist.copy()#予測値リスト\n",
    "    df_pri = df_prilist.copy()\n",
    "    df_res=pd.DataFrame(columns=['スタッフコード', '科目', '分野', '学年', 'AI想定完全一致率'])\n",
    "    \"\"\"\n",
    "    df_jpn = df_prilist[0].copy()#優先度リスト\n",
    "    df_math = df_prilist[1].copy()#優先度リスト\n",
    "    df_eng = df_prilist[2].copy()#優先度リスト\n",
    "    \"\"\"\n",
    "    #科目を選択\n",
    "    kamoku =[0,1,2]\n",
    "    for k in kamoku:#科目を選択\n",
    "        # for i in df_pri[k]['分野']:#分野名を選択\n",
    "        for idx, value in enumerate(df_pri[k]['優先度']):#分野名を選択\n",
    "            # print(idx)\n",
    "            bunya = df_pri[k].at[idx,'分野']#分野\n",
    "            gakunen = df_pri[k].at[idx,'学年']#学年\n",
    "            ninzu = df_pri[k].at[idx,'配置希望人数']#配置希望人数\n",
    "            # print(bunya, gakunen, ninzu)\n",
    "            \n",
    "            #予測値リストを優先度に従って分野名と学年でフィルタ\n",
    "            df_temp = df_pred[(df_pred['分野']==bunya)&(df_pred['学年']==gakunen)]\n",
    "            #予測値を降順で並び替え\n",
    "            df_temp = df_temp.sort_values('AI想定完全一致率', ascending=False)\n",
    "            #配置希望人数を取得\n",
    "            df_temp =df_temp.iloc[:ninzu,:]\n",
    "            #選択結果を結果のデータフレームに保存\n",
    "            df_res = df_res.append(df_temp)\n",
    "            #取得したスタッフコードを削除\n",
    "            selected_staff = pd.Series(df_temp['スタッフコード'].unique())\n",
    "            df_pred = df_pred[~(df_pred['スタッフコード'].isin(selected_staff))]#選択されたスタッフコードを削除\n",
    "            \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "238b7707-b39e-4b08-993f-c58c3958f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学年分野別予測値の集計\n",
    "def make_agg(df_input):\n",
    "    df = df_input.copy()\n",
    "    col_name = 'AI想定完全一致率'\n",
    "    df_ret = df.groupby(['分野','学年'],as_index=False).agg(\n",
    "        AI想定完全一致率_N数=pd.NamedAgg(column = col_name, aggfunc=\"count\"),\n",
    "        AI想定完全一致率_平均値=pd.NamedAgg(column = col_name, aggfunc=\"mean\"),\n",
    "        AI想定完全一致率_中央値=pd.NamedAgg(column = col_name, aggfunc=\"median\"),\n",
    "        AI想定完全一致率_最大値=pd.NamedAgg(column = col_name, aggfunc=\"max\"),\n",
    "        AI想定完全一致率_最小値=pd.NamedAgg(column = col_name, aggfunc=\"min\"))\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e1f23fbd-26d8-4fec-a0ac-6c9b643accb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分野の表記を修正\n",
    "def merge_prilist_aggresult(df_prilist, df_agg):\n",
    "    df1 = df_prilist.copy()\n",
    "    df2 = df_agg\n",
    "    #優先度と配属人数の結合\n",
    "    df_jpn = pandas_tool.merge(df1[0], df2, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_math = pandas_tool.merge(df1[1], df2, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    df_eng = pandas_tool.merge(df1[2], df2, key = [\"分野\",\"学年\"],how = 'left')\n",
    "    return [df_jpn, df_math, df_eng]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
