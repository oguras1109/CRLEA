{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "使用データ：FMT修正版_CRLEAデータ①入力様式_v2_1222.xlsx<br>\n",
    "目的：機械学習に直ぐ使用できる形式に変換する<br>\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 受領データを読み込む\n",
    "2. 受領データを整形する\n",
    "3. 整形データを出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import japanize_matplotlib\n",
    "# import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9a4cd-ddb6-4c9f-a6c8-c39a1e582fa3",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254adaa5-c6ea-46dd-9c03-c414abaf50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エクセルを読み込み、シートごとにデータフレームに入れる\n",
    "\"\"\"\n",
    "path_name = ファイルパス\n",
    "sn_list = エクセルシート名のリスト\n",
    "\"\"\"\n",
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/rawdata/FMT修正版_CRLEAデータ①入力様式_v2_1222.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "#sn_list ['データ入力様式_英語', 'データ入力様式_国語', 'データ入力様式_数学', '空欄埋め方', 'データ入力様式(記入例)']\n",
    "\n",
    "# Excelファイルの読み込み\n",
    "df_eng = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=[1],dtype = {'ロット番号': object})#headerを修正\n",
    "df_jpn = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=[1],dtype = {'ロット番号': object})#headerを修正\n",
    "df_math = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None,dtype = {'ロット番号': object})#headerを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0c2253-0167-4bbf-98ec-591edd915232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分野修正前</th>\n",
       "      <th>分野</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>漢文（現代語訳）</td>\n",
       "      <td>漢文(現訳)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>漢文（内容説明）</td>\n",
       "      <td>漢文(内説)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>現代文・小説</td>\n",
       "      <td>小説</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>現代文・評論</td>\n",
       "      <td>評論</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>現代文・評論（理由説明）</td>\n",
       "      <td>評論</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          分野修正前      分野\n",
       "0      漢文（現代語訳）  漢文(現訳)\n",
       "1      漢文（内容説明）  漢文(内説)\n",
       "2        現代文・小説      小説\n",
       "3        現代文・評論      評論\n",
       "4  現代文・評論（理由説明）      評論"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/rawdata/分野区分マスタv4.1.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "#夏採点を読み込んで、採点回を列に追加する　df_summer\n",
    "\n",
    "bunya = []\n",
    "bunya = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=None)#headerを修正\n",
    "bunya = bunya.drop(['科目コード','ポイント採点', '解答言語'], axis=1)\n",
    "#bunya = bunya.fillna({'解答言語': '日本語'})\n",
    "bunya = bunya.rename(columns={'分野名':'分野修正前'})\n",
    "bunya.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce2b4d-5b81-4166-bb61-74ff95c7dcda",
   "metadata": {},
   "source": [
    "# 変数追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7994eeb5-9c44-4808-be5b-b2dbfa00785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rank(df,x=str):# 在宅勤務のフラグを作るために使用。\n",
    "    # 最終ペースをランク分け\n",
    "    if x == \"最終ペース\":\n",
    "        conditions = [\n",
    "        (df[x] >= 600),\n",
    "        (df[x] >= 500),\n",
    "        (df[x] >= 400),\n",
    "        (df[x] >= 300),\n",
    "        (df[x] >= 200),\n",
    "        (df[x] >= 100),\n",
    "        (df[x] >= 0)\n",
    "         ]\n",
    "        \n",
    "        choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "        df.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    # 在宅勤務のフラグ作成\n",
    "    if x == \"年度\":\n",
    "        conditions = [\n",
    "        (df[x] >= 2020),\n",
    "        (df[x] >= 0)\n",
    "         ]\n",
    "        \n",
    "        choices = [1, 0]\n",
    "        df.loc[:,'在宅勤務'] = np.select(conditions, choices, default = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74bdd5-74db-4831-882f-5b437bd0abba",
   "metadata": {},
   "source": [
    "## 国語科目の前処理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732df2bb-3e63-4612-9312-28e352fc0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_jpn.copy()\n",
    "#グレーアウトした行を削除\n",
    "df = df[df['採点回']!='春']\n",
    "df = df[df['ロット番号']!='基準なし']\n",
    "#len(df) 346->307\n",
    "\n",
    "#列の欠損値を補完\n",
    "df['必須条件の有無'] = df['必須条件の有無'].fillna(0)#必須条件の有無の空白を0に\n",
    "df['配点要素の数'] = df['配点要素の数'].fillna(df['ポイント数'])#配点要素の数の空白をポイント数と同じ数に\n",
    "#最終ペースでランク分け、年度で在宅勤務のフラグ\n",
    "#lst=['最終ペース','年度']\n",
    "#for i in lst:\n",
    "#    df = make_rank(df,i)\n",
    "df = make_rank(df,'年度')\n",
    "\n",
    "#分野の表記揺れを修正\n",
    "df['分野'] = df['分野'].replace('古文（現代語訳）','古文（現訳）')\n",
    "df['分野'] = df['分野'].replace('古文（内容説明）','古文（内説）')\n",
    "df['分野'] = df['分野'].replace('漢文（現代語訳）','漢文（現訳）')\n",
    "df['分野'] = df['分野'].replace('漢文（内容説明）','漢文（内説）')\n",
    "df['最終ペース'] = df['最終ペース'].replace('採点回終了時',np.nan)\n",
    "\n",
    "#列のデータタイプを確認\n",
    "#pandas_tool.type(df_jpn,view=False)\n",
    "#列のデータタイプを変更\n",
    "#分野名を分野マスタで変換\n",
    "#必要な列のみを抽出\n",
    "df = df[['年度', '採点回', '学年', '科目', '分野','ロット番号', 'ポイント採点', '文字数',\n",
    "       'ポイント数', '配点要素の数', '配点',  '必須条件の有無','在宅勤務','企画ペース', '最終ペース']]\n",
    "df_jpn_pretreated = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f939f-1c96-4621-80e7-19c9a8b5fb7f",
   "metadata": {},
   "source": [
    "## 数学科目の前処理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882f6e72-74a6-4f06-865d-505d47e9bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', 'ロット番号', '分野', '（1）実点・立式点', '（1）カッコ点・立式点',\n",
       "       '（1）実点・答え点', '（1）カッコ点・答え点', '（1）実点・その他', '（1）カッコ点・その他',\n",
       "       '（2）実点・立式点', '（2）カッコ点・立式点', '（2）実点・答え点', '（2）カッコ点・答え点',\n",
       "       '（2）実点・その他', '（2）カッコ点・その他', '（3）実点・立式点', '（3）カッコ点・立式点',\n",
       "       '（3）実点・答え点', '（3）カッコ点・答え点', '（3）実点・その他', '（3）カッコ点・その他',\n",
       "       '（1）ポイント数合計', '（2）ポイント数合計', '（3）ポイント数合計', 'ポイント採点', '（1）配点',\n",
       "       '（2）配点', '（3）配点', '企画ペース', '最終ペース', '模範解答の記述行数（１）', '模範解答の記述行数（２）',\n",
       "       '模範解答の記述行数（３）', '補足資料の枚数', '分野（詳細）', '他参照有無', 'Unnamed: 39'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_math.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f8733f-ac5d-4408-8e52-d5c0ee7658ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "499\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:529\n",
      "df2のオブザベーション:159\n",
      "mergeのオブザベーション:529\n"
     ]
    }
   ],
   "source": [
    "df = df_math.copy()\n",
    "#グレーアウトした行を削除\n",
    "df = df[~((df['採点回'] == '春')&(df['年度']==2019))]#2019春を除外\n",
    "df = df[~((df['採点回'] == '夏')&(df['年度']==2018)&(df['学年']!=1))]#2018夏2-3年を除外\n",
    "#len(df) 477->422\n",
    "\n",
    "#列の欠損値を補完\n",
    "df['ポイント採点'] = df['ポイント採点'].fillna(0)\n",
    "df['（1）実点・立式点'] = df['（1）実点・立式点'].fillna(0)\n",
    "df['（1）カッコ点・立式点'] = df['（1）カッコ点・立式点'].fillna(0)\n",
    "df['（1）実点・答え点'] = df['（1）実点・答え点'].fillna(0)\n",
    "df['（1）カッコ点・答え点'] = df['（1）カッコ点・答え点'].fillna(0)\n",
    "df['（1）実点・その他'] = df['（1）実点・その他'].fillna(0)\n",
    "df['（1）カッコ点・その他'] = df['（1）カッコ点・その他'].fillna(0)\n",
    "df['（1）ポイント数合計'] = df['（1）ポイント数合計'].fillna(0)\n",
    "df['（1）配点'] = df['（1）配点'].fillna(0)\n",
    "df['模範解答の記述行数（１）'] = df['模範解答の記述行数（１）'].fillna(0)\n",
    "df['（2）実点・立式点'] = df['（2）実点・立式点'].fillna(0)\n",
    "df['（2）カッコ点・立式点'] = df['（2）カッコ点・立式点'].fillna(0)\n",
    "df['（2）実点・答え点'] = df['（2）実点・答え点'].fillna(0)\n",
    "df['（2）カッコ点・答え点'] = df['（2）カッコ点・答え点'].fillna(0)\n",
    "df['（2）実点・その他'] = df['（2）実点・その他'].fillna(0)\n",
    "df['（2）カッコ点・その他'] = df['（2）カッコ点・その他'].fillna(0)\n",
    "df['（2）ポイント数合計'] = df['（2）ポイント数合計'].fillna(0)\n",
    "df['（2）配点'] = df['（2）配点'].fillna(0)\n",
    "df['模範解答の記述行数（２）'] = df['模範解答の記述行数（２）'].fillna(0)\n",
    "df['（3）実点・立式点'] = df['（3）実点・立式点'].fillna(0)\n",
    "df['（3）カッコ点・立式点'] = df['（3）カッコ点・立式点'].fillna(0)\n",
    "df['（3）実点・答え点'] = df['（3）実点・答え点'].fillna(0)\n",
    "df['（3）カッコ点・答え点'] = df['（3）カッコ点・答え点'].fillna(0)\n",
    "df['（3）実点・その他'] = df['（3）実点・その他'].fillna(0)\n",
    "df['（3）カッコ点・その他'] = df['（3）カッコ点・その他'].fillna(0)\n",
    "df['（3）ポイント数合計'] = df['（3）ポイント数合計'].fillna(0)\n",
    "df['（3）配点'] = df['（3）配点'].fillna(0)\n",
    "df['模範解答の記述行数（３）'] = df['模範解答の記述行数（３）'].fillna(0)\n",
    "\n",
    "\n",
    "#補足資料の枚数列の例外を修正\n",
    "df['補足資料の枚数'] = df['補足資料の枚数'].replace('補足なし',0)\n",
    "df['補足資料の枚数'] = df['補足資料の枚数'].replace('補足基準発行後',np.nan)\n",
    "\n",
    "\n",
    "df['科目'] = df['科目'].replace('数学X/A\\u3000','数学X/A')#0905に修正\n",
    "#最終ペースを空欄に\n",
    "df['最終ペース'] = df['最終ペース'].replace('採点回終了時',np.nan)\n",
    "#在宅勤務フラグ作成\n",
    "df = make_rank(df,'年度')\n",
    "\n",
    "#分野名を分野マスタで変換\n",
    "df = df.rename(columns={'分野':'分野修正前'})\n",
    "df1 = df\n",
    "df2 = bunya\n",
    "df = pandas_tool.merge(df1,df2, key = [\"分野修正前\"],how = 'left')\n",
    "#不要な列を削除\n",
    "df = df.drop(['分野（詳細）', '他参照有無', '分野修正前','Unnamed: 39'], axis=1)\n",
    "df_math_pretreated = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bed9bc-485b-4dfd-ab14-56c286663889",
   "metadata": {},
   "source": [
    "## 英語科目の前処理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b39668d-b3f9-4b53-a3de-257930289dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', 'ロット番号', '大問', '小問', '分野', '解答言語',\n",
       "       '文字/単語数', '配点', 'ポイント採点', 'ポイント・ランク・パート数', '減点要素の数', '企画ペース',\n",
       "       '最終ペース', 'パターン数'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6205f3bb-2ff3-4484-be98-8c03dcecfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns(df):\n",
    "    #文字数に数値が入っている場合、そのまま代入\n",
    "    if str(df).isdigit() == True: #簡単な例から場合分けする。 文字列か、数値か判定\n",
    "        return float(df)\n",
    "    elif '+' in str(df):\n",
    "        x = str(df).split('+')\n",
    "        return sum(list(map(float, x)))\n",
    "    elif '-' in str(df):\n",
    "        x = str(df).split('-')\n",
    "        return sum(list(map(float, x)))\n",
    "    elif '‐' in str(df):\n",
    "        x = str(df).split('‐')\n",
    "        return sum(list(map(float, x)))\n",
    "    else:\n",
    "        return float(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ced051-bcc3-4b94-badd-c2f1c04883ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_eng.copy()\n",
    "#グレーアウトした行を削除\n",
    "df = df[df['分野'] != '英単語']#英単語を除外\n",
    "#len(df) 333->321\n",
    "\n",
    "#合計列の追加\n",
    "df['配点合計'] = df['配点'].apply(split_columns)\n",
    "df['文字数合計'] = df['文字/単語数'].apply(split_columns)\n",
    "df['ポイント数合計'] = df['ポイント・ランク・パート数'].apply(split_columns)\n",
    "df['減点要素の数合計'] = df['減点要素の数'].apply(split_columns)\n",
    "\n",
    "#列の欠損値を補完\n",
    "#df = df.fillna(0)#最終ペースの空白もゼロにしているので、修正\n",
    "df['パターン数'] = df['パターン数'].fillna(0)\n",
    "df['減点要素の数合計'] = df['減点要素の数合計'].fillna(0)\n",
    "df['ポイント採点'] = df['ポイント採点'].fillna(0)\n",
    "df['ポイント数合計'] = df['ポイント数合計'].fillna(0)\n",
    "\n",
    "#年度で在宅勤務のフラグ\n",
    "df = make_rank(df,'年度')\n",
    "\n",
    "#最終ペースを空欄に\n",
    "df['最終ペース'] = df['最終ペース'].replace('採点回終了時',np.nan)\n",
    "\n",
    "#必要な列のみを抽出\n",
    "df = df.drop(['小問','文字/単語数', '配点', 'ポイント・ランク・パート数', '減点要素の数',], axis=1)\n",
    "df_eng_pretreated = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "131d0982-9a80-466b-8ef4-904e93dab8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し 集計用データマート\n",
    "\"\"\"\n",
    "\n",
    "name = \"FMT修正版_CRLEAデータ①入力様式_v2_1222_pretreated_v1\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "\n",
    "df1 = df_jpn_pretreated\n",
    "df2 = df_math_pretreated\n",
    "df3 = df_eng_pretreated\n",
    "\n",
    "#csv\n",
    "df1.to_csv('{}/{}.csv'.format(path_folder,\"{}_{}\".format(name,'jpn')),encoding='utf-8-sig',index=False)\n",
    "df2.to_csv('{}/{}.csv'.format(path_folder,\"{}_{}\".format(name,'math')),encoding='utf-8-sig',index=False)\n",
    "df3.to_csv('{}/{}.csv'.format(path_folder,\"{}_{}\".format(name,'eng')),encoding='utf-8-sig',index=False)\n",
    "\n",
    "#Excel\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name)) as writer:\n",
    "    df1.to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df2.to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df3.to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c992ef6-f502-4f61-b7f0-81ca191e30bf",
   "metadata": {},
   "source": [
    "## 数学の分野修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef6a9a48-d25e-4683-872f-f3dd2cfb9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "552\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:584\n",
      "df2のオブザベーション:159\n",
      "mergeのオブザベーション:584\n"
     ]
    }
   ],
   "source": [
    "df = df_math.copy()\n",
    "#グレーアウトした行を削除\n",
    "# df = df[~((df['採点回'] == '春')&(df['年度']==2019))]#2019春を除外\n",
    "# df = df[~((df['採点回'] == '夏')&(df['年度']==2018)&(df['学年']!=1))]#2018夏2-3年を除外\n",
    "#len(df) 477->422\n",
    "\n",
    "#列の欠損値を補完\n",
    "df['ポイント採点'] = df['ポイント採点'].fillna(0)\n",
    "df['（1）実点・立式点'] = df['（1）実点・立式点'].fillna(0)\n",
    "df['（1）カッコ点・立式点'] = df['（1）カッコ点・立式点'].fillna(0)\n",
    "df['（1）実点・答え点'] = df['（1）実点・答え点'].fillna(0)\n",
    "df['（1）カッコ点・答え点'] = df['（1）カッコ点・答え点'].fillna(0)\n",
    "df['（1）実点・その他'] = df['（1）実点・その他'].fillna(0)\n",
    "df['（1）カッコ点・その他'] = df['（1）カッコ点・その他'].fillna(0)\n",
    "df['（1）ポイント数合計'] = df['（1）ポイント数合計'].fillna(0)\n",
    "df['（1）配点'] = df['（1）配点'].fillna(0)\n",
    "df['模範解答の記述行数（１）'] = df['模範解答の記述行数（１）'].fillna(0)\n",
    "df['（2）実点・立式点'] = df['（2）実点・立式点'].fillna(0)\n",
    "df['（2）カッコ点・立式点'] = df['（2）カッコ点・立式点'].fillna(0)\n",
    "df['（2）実点・答え点'] = df['（2）実点・答え点'].fillna(0)\n",
    "df['（2）カッコ点・答え点'] = df['（2）カッコ点・答え点'].fillna(0)\n",
    "df['（2）実点・その他'] = df['（2）実点・その他'].fillna(0)\n",
    "df['（2）カッコ点・その他'] = df['（2）カッコ点・その他'].fillna(0)\n",
    "df['（2）ポイント数合計'] = df['（2）ポイント数合計'].fillna(0)\n",
    "df['（2）配点'] = df['（2）配点'].fillna(0)\n",
    "df['模範解答の記述行数（２）'] = df['模範解答の記述行数（２）'].fillna(0)\n",
    "df['（3）実点・立式点'] = df['（3）実点・立式点'].fillna(0)\n",
    "df['（3）カッコ点・立式点'] = df['（3）カッコ点・立式点'].fillna(0)\n",
    "df['（3）実点・答え点'] = df['（3）実点・答え点'].fillna(0)\n",
    "df['（3）カッコ点・答え点'] = df['（3）カッコ点・答え点'].fillna(0)\n",
    "df['（3）実点・その他'] = df['（3）実点・その他'].fillna(0)\n",
    "df['（3）カッコ点・その他'] = df['（3）カッコ点・その他'].fillna(0)\n",
    "df['（3）ポイント数合計'] = df['（3）ポイント数合計'].fillna(0)\n",
    "df['（3）配点'] = df['（3）配点'].fillna(0)\n",
    "df['模範解答の記述行数（３）'] = df['模範解答の記述行数（３）'].fillna(0)\n",
    "\n",
    "\n",
    "#補足資料の枚数列の例外を修正\n",
    "df['補足資料の枚数'] = df['補足資料の枚数'].replace('補足なし',0)\n",
    "df['補足資料の枚数'] = df['補足資料の枚数'].replace('補足基準発行後',np.nan)\n",
    "\n",
    "\n",
    "df['科目'] = df['科目'].replace('数学X/A\\u3000','数学X/A')#0905に修正\n",
    "#最終ペースを空欄に\n",
    "df['最終ペース'] = df['最終ペース'].replace('採点回終了時',np.nan)\n",
    "#在宅勤務フラグ作成\n",
    "df = make_rank(df,'年度')\n",
    "\n",
    "#分野名を分野マスタで変換\n",
    "df = df.rename(columns={'分野':'分野修正前'})\n",
    "df1 = df\n",
    "df2 = bunya\n",
    "df = pandas_tool.merge(df1,df2, key = [\"分野修正前\"],how = 'left')\n",
    "#不要な列を削除\n",
    "df = df.drop(['分野（詳細）', '他参照有無', '分野修正前','Unnamed: 39'], axis=1)\n",
    "df_math_bunya = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9e92d55-2f73-472d-9af0-8a7774862b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "書き出し\n",
    "\"\"\"\n",
    "\n",
    "name = \"FMT修正版_CRLEAデータ①入力様式_v2_1222_数学分野修正_v1\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df1 = df_math_bunya\n",
    "\n",
    "#csv\n",
    "df1.to_csv('{}/{}.csv'.format(path_folder,\"{}_{}\".format(name,'math')),encoding='utf-8-sig',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
