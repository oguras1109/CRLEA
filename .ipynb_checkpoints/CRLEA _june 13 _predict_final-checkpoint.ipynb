{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 過去データを読み込む\n",
    "2. 過去データを整形する\n",
    "3. 過去データを学習してモデルを作る \n",
    "4. 設問データを読み込む\n",
    "5. 設問データをモデルに読み込ませ、予測値を出す\n",
    "6. 予測値を設問データに追加する\n",
    "7. 6のデータに、分野別最終ペースの最大値、最小値、平均値を追加する\n",
    "8. データを出力し、納品する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e8ee8-5729-48bf-ad0d-944ea382a941",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 過去データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c7e7ba-881a-48b4-abe1-fb54ccea1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "path_name = ファイルパス\n",
    "sn_list = エクセルシート名のリスト\n",
    "\"\"\"\n",
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/rawdata/①設問情報_20.21_0613欠損値更新_DAcheck_CR.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "#配列ループ\n",
    "df = [] #空のリスト\n",
    "for i in (0,1): #21冬\n",
    "\n",
    "    # Excelファイルの読み込み\n",
    "    ret = pd.read_excel(path_file, sn_list[i], header=0, index_col=None,skiprows=[1])#headerを修正\n",
    "    ret = ret.rename(columns={'企画ペース\\n完成版': '企画ペース',\n",
    "                             '文字数\\nＳ枠数': '文字数',\n",
    "                             'S枠（数字）': '割当ごとのS枠数',\n",
    "                             '割当単位':'割当'})#冬だけ\n",
    "    ret[\"年度\"]= sn_list[i][0:2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"採点回\"]= sn_list[i][2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"学年\"]= sn_list[i][3]#sn_listのiつ目の要素から4番目の文字    \n",
    "    # Excel sheetsを空のリストの各要素に追加\n",
    "    df.append(ret)\n",
    "    \n",
    "for i in (2,3,4): #21秋\n",
    "    # Excelファイルの読み込み\n",
    "    ret = pd.read_excel(path_file, sn_list[i], header=4,skiprows=[5], index_col=None)#headerを修正　,skiprows=[0,1,2,3,5]\n",
    "    ret[\"年度\"]= sn_list[i][0:2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"採点回\"]= sn_list[i][2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"学年\"]= sn_list[i][3]#sn_listのiつ目の要素から4番目の文字    \n",
    "    # Excel sheetsを空のリストの各要素に追加\n",
    "    df.append(ret)    \n",
    "\n",
    "for i in (5,6): #21夏1〜2\n",
    "    # Excelファイルの読み込み\n",
    "    ret = pd.read_excel(path_file, sn_list[i],header = 1, index_col=None)#headerを修正\n",
    "    ret[\"年度\"]= sn_list[i][0:2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"採点回\"]= sn_list[i][2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"学年\"]= sn_list[i][3]#sn_listのiつ目の要素から4番目の文字    \n",
    "    # Excel sheetsを空のリストの各要素に追加\n",
    "    df.append(ret)\n",
    "    \n",
    "for i in range(7,len(sn_list)): #21夏3〜\n",
    "    # Excelファイルの読み込み\n",
    "    ret = pd.read_excel(path_file, sn_list[i],header = 1, index_col=None)#headerを修正\n",
    "    ret[\"年度\"]= sn_list[i][0:2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"採点回\"]= sn_list[i][2]#sn_listのiつ目の要素から3番目の文字\n",
    "    ret[\"学年\"]= sn_list[i][3]#sn_listのiつ目の要素から4番目の文字    \n",
    "    # Excel sheetsを空のリストの各要素に追加\n",
    "    df.append(ret)\n",
    "\n",
    "\"\"\"集計したデータを縦に結合する\"\"\"\n",
    "\n",
    "dfs = df[0] #集計結果を一つのDFに結合\n",
    "for i in df[1:]:\n",
    "    dfs = dfs.append(i)\n",
    "\n",
    "# rename    \n",
    "dfs = dfs.rename(columns={'科目分類名': '科目',\n",
    "                         '割当':'割当1'})\n",
    "\n",
    "#データ型の変更\n",
    "dfs['割当1'] = dfs.loc[:, \"割当1\"].astype('str')#下のfor文でKを除くために文字列型の必要あり\n",
    "dfs['学年'] = dfs.loc[:, \"学年\"].astype('int')\n",
    "dfs['年度'] = dfs.loc[:, \"年度\"].astype('int')\n",
    "\n",
    "\n",
    "#置換\n",
    "map_dictionary ={\"国語\" : 10, \"数学\" :20, \"英語\" : 30} \n",
    "dfs['科目コード'] = dfs['科目'].map(map_dictionary) \n",
    "\n",
    "dfs = dfs.replace({'最終ペース': {'ー':np.nan}})\n",
    "dfs['最終ペース'] = dfs.loc[:, \"最終ペース\"].astype('float64')\n",
    "\n",
    "#空白行の削除\n",
    "dfs= dfs[~dfs[\"科目コード\"].isna()]\n",
    "\n",
    "#割当から客観とnanを削除\n",
    "df = []\n",
    "for i in dfs['割当1']:\n",
    "    if 'K' in i:\n",
    "        i = np.nan\n",
    "    df.append(i)\n",
    "dfs['割当1'] = df\n",
    "dfs =dfs[dfs['割当1'] != \"nan\"]\n",
    "dfs= dfs[~dfs[\"割当1\"].isna()]\n",
    "\n",
    "df_1 = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2d279d-b29f-4ee4-9d63-fcd42f3f1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分野マスターは分野の表記揺れを統一したもの。 CRLEA様から修正版が送られてきたら、csvにして再度使用\n",
    "\"\"\"\n",
    "data1から分野を抜き出したcsvファイルを読み込む\n",
    "2つのテーブルを結合させる\n",
    "df_1:過去データを読み込んで一つのデータフレームにしたもの\n",
    "bunya:分野の表記揺れをなおした列（分野名（修正））がある\n",
    "\"\"\"\n",
    "\n",
    "name_csv = \"bunyamaster_v3.3.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/rawdata\"#Excelが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "bunya = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")\n",
    "bunya = bunya.rename(columns={'分野名':'分野'})\n",
    "bunya = bunya.fillna({'解答言語': '日本語'})\n",
    "# merge\n",
    "df_1b = pd.merge(df_1,bunya, on = [\"分野\",\"科目コード\"],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ac6937-7e4e-4b21-938b-439043265aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_33943/4218709829.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ret[j] =ret[j].fillna(ret[j].mean())\n"
     ]
    }
   ],
   "source": [
    "df = df_1b\n",
    "\n",
    "\"\"\"文字数　あとで数学の文字数を編集する必要あり。\"\"\"\n",
    "\n",
    "def make_sum(input_str):\n",
    "    if input_str ==\"\":\n",
    "        return np.nan\n",
    "    elif '+' in input_str:\n",
    "        input_list = input_str.split('+')#+が半角か全角か異なる場合もあり。\n",
    "        input_list_num = [int(s) for s in input_list] #リスト内包表記　復習\n",
    "        return sum(input_list_num)\n",
    "    else:\n",
    "        input_list = input_str.split('＋')#+が半角か全角か異なる場合もあり。\n",
    "        input_list_num = [int(s) for s in input_list] #リスト内包表記　復習\n",
    "        return sum(input_list_num)\n",
    "\n",
    "\n",
    "#一行に対するルールを定義する 上から順に作成して、順次テストする\n",
    "\n",
    "def make_mojisu(df):\n",
    "    name_col = \"文字数\"\n",
    "    #行を含む場合は行数の文字列を代入\n",
    "    if '行' in str(df[name_col]):\n",
    "        return df['行の文字数']\n",
    "    \n",
    "    #文字数に数値が入っている場合、そのまま代入\n",
    "    elif str(df[name_col]).isdigit() == True: #簡単な例から場合分けする。 文字列か、数値か判定\n",
    "        return int(df[name_col])\n",
    "\n",
    "    #ルール分けが難しい場合は直接数字で返す\n",
    "    if '5語程度×2枠' in str(df[name_col]):#ここも語数だから直す\n",
    "        return int(df[name_col].replace('5語程度×2枠','10'))\n",
    "    if '50字以上60字以内（日本語）' in str(df[name_col]):\n",
    "        return int(df[name_col].replace('50字以上60字以内（日本語）','50'))\n",
    "    if '30字以上40字以内' in str(df[name_col]):\n",
    "        return int(df[name_col].replace('30字以上40字以内','30'))\n",
    "    if '30～45語' in str(df[name_col]):#ここも語数だから直す\n",
    "        return int(df[name_col].replace('30～45語','30'))\n",
    "    if '5～10語' in str(df[name_col]):#ここも語数だから直す\n",
    "        return int(df[name_col].replace('5～10語','5'))\n",
    "    #+で分けて合計するのが上手くいかないので応急処置\n",
    "    if '25+25' in str(df[name_col]):\n",
    "        return int(df[name_col].replace('25+25','50'))\n",
    "    if '10+20' in str(df[name_col]):\n",
    "        return int(df[name_col].replace('10+20','30'))\n",
    "    if '15+20' in str(df[name_col]):\n",
    "        return int(df[name_col].replace('15+20','35'))\n",
    "\n",
    "\n",
    "    #数値に文字列を含む場合は文字列を除外し数値だけ返す。また意味不明は空白で返す\n",
    "    x = ['文字程度','文字（説明）','字程度（日本語）','文字','※解答枠６。まとめて10点', '単語？','太枠', 'ポ採\\u30001枠', 'ポ採\\u30003枠','\\u3000','小枠2つ','2枠', '1枠', '3枠',\"字\"]\n",
    "    y = [\"語程度\",\"語\"]\n",
    "    for i in x:\n",
    "        if i in str(df[name_col]):\n",
    "            return make_sum(df[name_col].replace(i,\"\"))\n",
    "    #「語」表記は5倍して返す。ただし、そのうち分野区分マスタに英文か和文かを示すダミー変数を作成して試したいので、ここは後で直す予定。\n",
    "    for i in y:\n",
    "        if i in str(df[name_col]):\n",
    "            return int(df[name_col].replace(i,\"\"))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "#定義したルールをapplyでdfの全てに対して一行ずつ適応している。applyはよく使う。\n",
    "df['置換後の文字数']=df.apply(make_mojisu,axis = 1)\n",
    "\n",
    "\n",
    "\"\"\"解答言語が英語の場合、文字数を5倍にする\"\"\"\n",
    "#5倍するラムダ関数\n",
    "def times_five(df):\n",
    "    if df[\"解答言語\"]== \"英語\":\n",
    "        return df[\"置換後の文字数\"]*5\n",
    "    else:\n",
    "        return df[\"置換後の文字数\"]\n",
    "#定義したルールをapplyでdfの全てに対して一行ずつ適応している。applyはよく使う。\n",
    "df['置換後の文字数5']=df.apply(times_five,axis = 1)\n",
    "\n",
    "\"\"\"ポイント数の修正\"\"\"\n",
    "\n",
    "name_col = \"ポイント数\"\n",
    "lst = []\n",
    "df[name_col] = df[name_col].replace('\\u3000',np.nan)\n",
    "df[name_col] = df[name_col].replace('',np.nan)\n",
    "df[name_col] = df[name_col].replace('2+7+8(ポ5)',\"2+7+8\")\n",
    "df[name_col] = df[name_col].replace('2+4+6（ポ3）',\"2+4+6\")\n",
    "                             \n",
    "for i in df[name_col]:\n",
    "    if type(i) == str:\n",
    "        x = i.split('+')\n",
    "        y = list(map(int, x))\n",
    "        i = sum(y)\n",
    "    lst.append(i)\n",
    "\n",
    "df['置換後のポイント数'] = lst\n",
    "\n",
    "\"\"\"配点の修正\"\"\"\n",
    "# df = raw_df\n",
    "name_col = \"配点\"\n",
    "lst = []\n",
    "df[name_col] = df[name_col].replace('\\u3000',np.nan)\n",
    "df[name_col] = df[name_col].replace('',np.nan)\n",
    "df[name_col] = df[name_col].replace('5(2+2+1)+5',10)\n",
    "df[name_col] = df[name_col].replace('2*2',4)\n",
    "                             \n",
    "for i in df[name_col]:\n",
    "    if type(i) == str:\n",
    "        if '+' in i:\n",
    "            x = i.split('+')\n",
    "        elif '＋' in i:\n",
    "            x = i.split('＋')\n",
    "        y = list(map(int, x))\n",
    "        i = sum(y)\n",
    "    lst.append(i)\n",
    "\n",
    "df['置換後の配点'] = lst\n",
    "\n",
    "df_1b_cleaned = df #読み込んだデータに分野を足してデータクレンジングしたもの\n",
    "\n",
    "\"\"\"\n",
    "欠損値を分野別、科目別平均値で補完\n",
    "1.　pandasでDFの形でデータを読み込む\n",
    "2.　df.queryで分野2を条件に、カテゴリごとのDFに分ける\n",
    "3.　分けたDFで、平均値で欠損値を埋める\n",
    "4.　df.appendで分けたDFを結合\n",
    "\"\"\"\n",
    "df = df_1b_cleaned.copy()\n",
    "list_bunya = df['分野名_修正v2'].unique()\n",
    "list_fillna = ['置換後の文字数','置換後の文字数5','置換後のポイント数','置換後の配点']\n",
    "\n",
    "df_ret=[]\n",
    "for i in list_bunya:\n",
    "    ret = df[df['分野名_修正v2'] == i]\n",
    "    for j in list_fillna:\n",
    "        ret[j] =ret[j].fillna(ret[j].mean())\n",
    "    df_ret.append(ret)\n",
    "\n",
    "dfs = df_ret[0] #集計結果を一つのDFに結合\n",
    "for i in df_ret[1:]:\n",
    "    dfs = dfs.append(i)\n",
    "\n",
    "df_1b_cleaned_filled = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f053292-34c9-43bf-b363-7519be2d6a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = \"25+25\"\n",
    "# x = temp.split('+')\n",
    "# y = list(map(int, temp.split('+')))\n",
    "# ans = sum(list(map(int, temp.split('+'))))\n",
    "# ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba70bc70-0a08-4cfe-b0e0-75aaac4d9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "20,21年の加工したデータのExcelへの書き出し \n",
    "\"\"\"\n",
    "\n",
    "df = df_1b_cleaned\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df.to_csv('{}/{}'.format(path_folder,name_excel_output),encoding='utf-8-sig',index=False)\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)\n",
    "    \n",
    "df = df_1b_cleaned_filled\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613_filled.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df.to_csv('{}/{}'.format(path_folder,name_excel_output),encoding='utf-8-sig',index=False)\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613_filled.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f8f5e-c319-4e63-8814-18c1325b5d80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c91fbf6-d45e-4246-9cf9-470f834c2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"データ選択\"\"\"\n",
    "\n",
    "def select_data(df):\n",
    "    df = df[['科目',\n",
    "        '分野名_修正v1',\n",
    "        '分野名_修正v2',\n",
    "        'ポイント採点',\n",
    "        '年度',\n",
    "        '採点回',\n",
    "        '学年',\n",
    "        '置換後のポイント数',\n",
    "        '置換後の文字数',\n",
    "        '置換後の文字数5',\n",
    "         '解答言語',\n",
    "        '置換後の配点',\n",
    "        '企画ペース',\n",
    "        '最終ペース']]\n",
    "    df = df.rename(columns={'分野名_修正v1':'分野1',\n",
    "                        '分野名_修正v2':'分野2',\n",
    "                        '置換後のポイント数':'ポイント数',\n",
    "                        '置換後の文字数':'文字数',#英語1単語も1文字として数えた\n",
    "                        '置換後の文字数5':'文字数5',#英語１単語を5文字とした。前の分析ではこっち。精度を比較する。\n",
    "                        '置換後の配点':'配点'})\n",
    "    return df\n",
    "\n",
    "df_ml = select_data(df_1b_cleaned)\n",
    "df_ml_filled = select_data(df_1b_cleaned_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1cd74-2b99-44c8-8bab-6d91faa9653c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9115482-7b20-4f68-8ea8-45b367e2f4e4",
   "metadata": {},
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b81a0-3fe3-4721-815b-04fd8f09c98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3552c909-a157-4efb-9e30-22b75977912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def make_train(df,kamoku = str):\n",
    "    \"\"\"\n",
    "    df:使用するデータ\n",
    "    str:抽出する科目\n",
    "    1.選択した科目を抽出\n",
    "    2.one hot encoding\n",
    "    3.説明変数、目的変数でデータフレームを分離\n",
    "    4.訓練用、検証用にデータフレームを分離\n",
    "    5.説明変数から採点回を削除 \n",
    "    \"\"\"\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df.loc[:,'文字数5'] = df.loc[:,'文字数5'].round(0).astype(int)\n",
    "    #1.科目を抽出し、科目と分野1の列を削除\n",
    "    df = df[df['科目']== kamoku].drop(columns = [\"科目\",\"分野1\",\"文字数\",\"解答言語\"])#解答言語を考慮せず、１単語5文字で変換。分野は2の方。\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = \"最終ペース\")#目的変数を除外した（説明変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回_夏','学年','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21))]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21))]\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)]\n",
    "   \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    # rem_cols_xb = [\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    rem_cols_y = [\"採点回_夏\",\"年度\",\"学年\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    y_kikaku =X_test['企画ペース']\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,y_kikaku]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4f56e3-afa1-4494-947c-01e779ddfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
    "ダミー変数を元に戻す。エクセル出力用\n",
    "\"\"\"\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf90acc7-4703-4991-9b15-46d4ba274f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def predict_model_check(df,a=2,b=1,c=None):#過去データで検証\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    kikaku = df[4]\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_res = df_res.rename(columns={\"文字数5\":\"文字数\"})\n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'企画ペース']= kikaku\n",
    "    # df_res.loc[:,'科目']= kamoku\n",
    "    df_res.loc[:,'誤差']= df_res['AI想定ペース']-df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI想定ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "            \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04731d-161c-47f6-93b4-48e3fe78f334",
   "metadata": {},
   "source": [
    "# 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b50fea8-e821-47eb-8c5d-6ad4eddc7fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#過去データでモデル検証\n",
    "df_v = predict_model_check(make_train(df_ml_filled,kamoku = \"国語\"))\n",
    "select_cols = ['最終ペース','AI乖離度','元の乖離度']\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,select_cols])[0]\n",
    "\n",
    "\n",
    "name_file = \"crlea_June13_欠損値補完_国語\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c149bca8-2b98-41c9-bf7e-84c84c763b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#過去データでモデル検証\n",
    "df_v = predict_model_check(make_train(df_ml_filled,kamoku = \"英語\"))\n",
    "select_cols = ['最終ペース','AI乖離度','元の乖離度']\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,select_cols])[0]\n",
    "\n",
    "\n",
    "name_file = \"crlea_June13_英語_欠損値補完\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d90f56-5fd5-4884-af6c-5d480049b50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['採点回_夏'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_33943/960089625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#過去データでモデル検証\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ml_filled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkamoku\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"数学\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mselect_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'最終ペース'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AI乖離度'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'元の乖離度'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselect_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_33943/1576896715.py\u001b[0m in \u001b[0;36mmake_train\u001b[0;34m(df, kamoku)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#3.上記のデータセットを説明変数と目的変数で分ける\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"最終ペース\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#目的変数を除外した（説明変数だけ含む）データフレーム\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdf_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年度'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'採点回_夏'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'学年'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'最終ペース'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#目的変数と選択用変数だけ含むデータフレーム\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#4.データフレームの分離\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['採点回_夏'] not in index\""
     ]
    }
   ],
   "source": [
    "#過去データでモデル検証\n",
    "df_v = predict_model_check(make_train(df_ml_filled,kamoku = \"数学\"))\n",
    "select_cols = ['最終ペース','AI乖離度','元の乖離度']\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,select_cols])[0]\n",
    "\n",
    "\n",
    "name_file = \"crlea_June13_数学_欠損値補完\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847558a-3727-46f8-a494-09d868c1370e",
   "metadata": {},
   "source": [
    "# 予測値の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9389563c-af93-44e5-8441-cef4f7517e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#データ読み込み マークダウンにしてあるから必要ならコードセルにする\n",
    "\"\"\"\n",
    "予測する設問csvファイルを読み込む　\n",
    "\"\"\"\n",
    "\n",
    "name_csv = \"①設問情報_22夏_0613.csv\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/rawdata\"#データが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "df = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")#,\n",
    "                 # usecols=['科目',\n",
    "                 #          '分野名_修正v1',\n",
    "                 #          '分野名_修正v2',\n",
    "                 #          'ポイント採点',\n",
    "                 #          '年度',\n",
    "                 #          '採点回',\n",
    "                 #          '学年',\n",
    "                 #          '置換後のポイント数',\n",
    "                 #          '置換後の文字数',\n",
    "                 #          '置換後の文字数5',\n",
    "                 #          '解答言語',\n",
    "                 #          '置換後の配点',\n",
    "                 #          '企画ペース',\n",
    "                 #          '最終ペース'])\n",
    "#列のリネーム\n",
    "# df = df.rename(columns={'分野名_修正v1':'分野1',\n",
    "#                         '分野名_修正v2':'分野2',\n",
    "#                         '置換後のポイント数':'ポイント数',\n",
    "#                         '置換後の文字数':'文字数',#英語1単語も1文字として数えた\n",
    "#                         '置換後の文字数5':'文字数5',#英語１単語を5文字とした。前の分析ではこっち。精度を比較する。\n",
    "#                         '置換後の配点':'配点'})\n",
    "\n",
    "map_dictionary ={\"国語\" : 10, \"数学\" :20, \"英語\" : 30} \n",
    "df['科目コード'] = df['科目'].map(map_dictionary) \n",
    "\n",
    "name_csv = \"bunyamaster_v3.3.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/rawdata\"#Excelが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "bunya = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")\n",
    "bunya = bunya.rename(columns={'分野名':'分野'})\n",
    "bunya = bunya.fillna({'解答言語': '日本語'})\n",
    "# merge\n",
    "df = pd.merge(df,bunya, on = [\"分野\",\"科目コード\"],how = 'left')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "読み込んだ生データを加工する\n",
    "1. いる列だけ選択\n",
    "2.　ポイント採点の空欄を0で埋める\n",
    "3.　ポイント数を合計して数値型にする\n",
    "4.　配点を合計して数値型にする\n",
    "\"\"\"\n",
    "df = df[['科目', '文字数', 'ポイント数', 'ポイント採点_x', '配点', '年度', '採点回', '学年','分野名_修正v1', '解答言語']]\n",
    "df = df.rename(columns={'分野名_修正v1':'分野','ポイント採点_x':'ポイント採点'})\n",
    "df['ポイント採点'] = df['ポイント採点'].fillna(0)\n",
    "df['文字数'] = df['文字数'].fillna(0)\n",
    "\n",
    "\"\"\"ポイント数の修正\"\"\"\n",
    "\n",
    "name_col = \"ポイント数\"\n",
    "lst = []\n",
    "for i in df[name_col]:\n",
    "    if type(i) == str:\n",
    "        x = i.split('-')\n",
    "        y = list(map(float, x))\n",
    "        i = sum(y)\n",
    "    lst.append(i)\n",
    "\n",
    "df['置換後のポイント数'] = lst\n",
    "\n",
    "\"\"\"配点の修正\"\"\"\n",
    "\n",
    "name_col = \"配点\"\n",
    "lst = []\n",
    "for i in df[name_col]:\n",
    "    if '+' in i:\n",
    "        x = i.split('+')\n",
    "        y = list(map(float, x))\n",
    "        i = sum(y)\n",
    "    elif '-' in i:\n",
    "        x = i.split('-')\n",
    "        y = list(map(float, x))\n",
    "        i = sum(y)\n",
    "        \n",
    "    lst.append(i)\n",
    "\n",
    "df['置換後の配点'] = lst\n",
    "\n",
    "df.loc[:,'置換後のポイント数'] = df.loc[:,'置換後のポイント数'].astype(int)\n",
    "df.loc[:,'置換後の配点'] = df.loc[:,'置換後の配点'].astype(int)\n",
    "\n",
    "\"\"\"解答言語が英語の場合、文字数を5倍にする\"\"\"\n",
    "#5倍するラムダ関数\n",
    "def times_five(df):\n",
    "    if df[\"解答言語\"]== \"英語\":\n",
    "        return df[\"文字数\"]*5\n",
    "    else:\n",
    "        return df[\"文字数\"]\n",
    "#定義したルールをapplyでdfの全てに対して一行ずつ適応している。applyはよく使う。\n",
    "df['置換後の文字数5']=df.apply(times_five,axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "設問情報のExcelの書き出し 中間確認\n",
    "\"\"\"\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613_setsumon_check.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df.to_csv('{}/{}'.format(path_folder,name_excel_output),encoding='utf-8-sig',index=False)\n",
    "\n",
    "name_excel_output = \"crlea_datamart_0613_setsumon_check.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)\n",
    "    \n",
    "\"\"\"\n",
    "設問情報のExcelの書き出し 機械学習用のみ\n",
    "\"\"\"    \n",
    "    \n",
    "\n",
    "df = df.drop(columns = {\"採点回\",\"年度\",\"文字数\",\"ポイント数\",\"配点\",\"解答言語\"})\n",
    "df = df.rename(columns={'置換後の文字数5':'文字数5',\n",
    "                        '置換後のポイント数':'ポイント数',\n",
    "                        '置換後の配点':'配点'})\n",
    "\n",
    "name = \"crlea_datamart_0613_setsumon.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "\n",
    "df.to_csv('{}/{}'.format(path_folder,name),encoding='utf-8-sig',index=False)\n",
    "\n",
    "name = \"crlea_datamart_0613_setsumon.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)\n",
    "\n",
    "df_setsumon = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813e75be-0c79-42af-a9e3-566998a2ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "df[3]:21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def make_test(df,kamoku = str):\n",
    "    \"\"\"\n",
    "    df:使用するデータ\n",
    "    str:抽出する科目\n",
    "    1.選択した科目を抽出\n",
    "    2.one hot encoding\n",
    "    \"\"\"\n",
    "    #1.科目を抽出し、科目と分野1の列を削除\n",
    "    df = df[df['科目']== kamoku].drop(columns = [\"科目\"])\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "    #並び替え\n",
    "    if kamoku ==\"国語\":\n",
    "        df = df.reindex(columns=['ポイント採点', '学年', 'ポイント数','文字数5','配点','分野_古文','分野_小説','分野_漢文','分野_評論','分野_随筆'])\n",
    "    if kamoku ==\"英語\":\n",
    "        df['分野_リスニング']=0\n",
    "        df = df.reindex(columns=['ポイント採点', '学年', 'ポイント数', '文字数5', '配点', '分野_リスニング', '分野_内容説明',\n",
    "       '分野_和文英訳', '分野_自由英作文', '分野_英作文', '分野_英文和訳','分野_英文補完'])\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954f8a63-9407-4acc-b571-f0873bc17f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def predict_model(df1,df2,kamoku = str,a=2,b=1,c=None):#本番用\n",
    "    X_train= df1[0]\n",
    "        \n",
    "    #並び替え\n",
    "    if kamoku ==\"国語\":\n",
    "        X_train = X_train.reindex(columns=['ポイント採点', '学年', 'ポイント数','文字数5','配点','分野2_古文','分野2_小説','分野2_漢文','分野2_評論','分野2_随筆'])\n",
    "    if kamoku ==\"英語\":\n",
    "        X_train['分野2_英文補完']=0\n",
    "        X_train = X_train.reindex(columns=['ポイント採点', '学年', 'ポイント数', '文字数5', '配点', '分野2_リスニング', '分野2_内容説明',\n",
    "       '分野2_和文英訳', '分野2_自由英作文', '分野2_英作文', '分野2_英文和訳','分野2_英文補完'])\n",
    "        \n",
    "    y_train= df1[1]\n",
    "    X_test = df2\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test).round(1)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_res = df_res.rename(columns={\"文字数5\":\"文字数\"})\n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449a2093-194e-401d-9716-5595642bfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_past_summary(df = df_ml_filled,category =str): #categoryで分野1か分野2か指定する\n",
    "    \"\"\"\n",
    "    categoryで指定した文字列で集計した\n",
    "    \"\"\"\n",
    "    #0.　生データのNAを削除\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "\n",
    "    #訓練用説明変数\n",
    "    df = df[~((df['採点回'] == \"夏\")&(df['年度']==21))]\n",
    "\n",
    "    group_df1 = df[[category,'最終ペース']].groupby(category).mean().round(1).rename(columns={\"最終ペース\":\"平均値\"})\n",
    "    group_df1.reset_index(inplace=True)\n",
    "\n",
    "    group_df2 = df[[category,'最終ペース']].groupby(category).max().round(1).rename(columns={\"最終ペース\":\"最大値\"})\n",
    "    group_df2.reset_index(inplace=True)\n",
    "\n",
    "    group_df3 = df[[category,'最終ペース']].groupby(category).min().round(1).rename(columns={\"最終ペース\":\"最小値\"})\n",
    "    group_df3.reset_index(inplace=True)\n",
    "\n",
    "    group_df4 = df[[category,'最終ペース']].groupby(category).median().round(1).rename(columns={\"最終ペース\":\"中央値\"})\n",
    "    group_df4.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    # merge\n",
    "    group_df = pd.merge(group_df1,group_df2, on = [category],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df3, on = [category],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df4, on = [category],how = 'left')\n",
    "    group_df = group_df.rename(columns={category:\"分野\"})\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "657b3660-429d-4dba-b224-6ab360542cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数5</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野2_古文</th>\n",
       "      <th>分野2_小説</th>\n",
       "      <th>分野2_漢文</th>\n",
       "      <th>分野2_評論</th>\n",
       "      <th>分野2_随筆</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ポイント採点  学年  ポイント数  文字数5  配点  分野2_古文  分野2_小説  分野2_漢文  分野2_評論  分野2_随筆\n",
       "0      0.0   1      3    60   6       0       0       0       1       0\n",
       "1      0.0   1      2    40   5       0       0       0       1       0\n",
       "27     0.0   2      2    20  10       0       0       0       1       0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_trainの並び確認\n",
    "temp1 = make_train(df_ml_filled,kamoku = \"国語\")[0]\n",
    "temp1.head(3)#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fba59a96-941c-4077-9ff3-0d4fc132d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数5</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野_古文</th>\n",
       "      <th>分野_小説</th>\n",
       "      <th>分野_漢文</th>\n",
       "      <th>分野_評論</th>\n",
       "      <th>分野_随筆</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ポイント採点  学年  ポイント数   文字数5  配点  分野_古文  分野_小説  分野_漢文  分野_評論  分野_随筆\n",
       "0     0.0   3      3   60.0  10      0      0      0      1      0\n",
       "1     0.0   3      2   70.0  12      0      0      0      1      0\n",
       "2     1.0   3      3  100.0  14      0      0      0      1      0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_testの並び確認\n",
    "make_test(df_setsumon,\"国語\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bc5aa43-3d5e-4393-8d83-bb95ccb7ceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数5</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野2_リスニング</th>\n",
       "      <th>分野2_内容説明</th>\n",
       "      <th>分野2_和文英訳</th>\n",
       "      <th>分野2_自由英作文</th>\n",
       "      <th>分野2_英作文</th>\n",
       "      <th>分野2_英文和訳</th>\n",
       "      <th>分野2_英文補完</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ポイント採点  学年  ポイント数  文字数5  配点  分野2_リスニング  分野2_内容説明  分野2_和文英訳  分野2_自由英作文  \\\n",
       "18     0.0   1      2    30   5          0         1         0          0   \n",
       "19     0.0   1      1    15   4          0         1         0          0   \n",
       "22     0.0   1      2    39   5          0         1         0          0   \n",
       "\n",
       "    分野2_英作文  分野2_英文和訳  分野2_英文補完  \n",
       "18        0         0         0  \n",
       "19        0         0         0  \n",
       "22        0         0         0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_trainの並び確認\n",
    "temp1 = make_train(df_ml_filled,kamoku = \"英語\")[0]\n",
    "\n",
    "# temp1[0].colum\n",
    "temp1['分野2_英文補完']=0\n",
    "temp1 = temp1.reindex(columns=['ポイント採点', '学年', 'ポイント数', '文字数5', '配点', '分野2_リスニング', '分野2_内容説明',\n",
    "       '分野2_和文英訳', '分野2_自由英作文', '分野2_英作文', '分野2_英文和訳','分野2_英文補完'])\n",
    "temp1.head(3)#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09ffa9e3-62bd-413e-9d38-2d8007034dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数5</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野_リスニング</th>\n",
       "      <th>分野_内容説明</th>\n",
       "      <th>分野_和文英訳</th>\n",
       "      <th>分野_自由英作文</th>\n",
       "      <th>分野_英作文</th>\n",
       "      <th>分野_英文和訳</th>\n",
       "      <th>分野_英文補完</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ポイント採点  学年  ポイント数  文字数5  配点  分野_リスニング  分野_内容説明  分野_和文英訳  分野_自由英作文  分野_英作文  \\\n",
       "36     0.0   3      1  25.0   5         0        0        0         0       0   \n",
       "37     0.0   3      1  25.0   5         0        0        0         0       0   \n",
       "38     0.0   3      1  50.0   8         0        0        0         0       1   \n",
       "\n",
       "    分野_英文和訳  分野_英文補完  \n",
       "36        0        1  \n",
       "37        0        1  \n",
       "38        0        0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_testの並び確認\n",
    "make_test(df_setsumon,\"英語\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d3cfa67-39d0-4be9-8fde-9bfc1e7567a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "予測値を算出し、過去の集計データと共に出力\n",
    "国語\n",
    "\"\"\"\n",
    "kamoku = '国語'\n",
    "df_train=make_train(df_ml_filled,kamoku)\n",
    "df_test=make_test(df_setsumon,kamoku)\n",
    "df_pred = predict_model(df_train, df_test,kamoku)\n",
    "df_ref = make_past_summary(df_ml_filled,\"分野2\")#20-21の過去集計データ\n",
    "df_res = pd.merge(df_pred,df_ref, on = [\"分野\"],how = 'left')\n",
    "df_res.loc[:,'ポイント採点'] =df_res.loc[:,'ポイント採点'].round(0).astype(int)\n",
    "df_res.head(3)\n",
    "\n",
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "\n",
    "df = df_res\n",
    "\n",
    "name_excel_output = \"crlea_predict_June15_国語.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60366397-dc37-493e-900e-714e144dc8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "予測値を算出し、過去の集計データと共に出力\n",
    "英語\n",
    "\"\"\"\n",
    "kamoku = '英語'\n",
    "df_train=make_train(df_ml_filled,kamoku)\n",
    "df_test=make_test(df_setsumon,kamoku)\n",
    "df_pred = predict_model(df_train, df_test,kamoku)\n",
    "df_ref = make_past_summary(df_ml_filled,\"分野2\")#20-21の過去集計データ\n",
    "df_res = pd.merge(df_pred,df_ref, on = [\"分野\"],how = 'left')\n",
    "df_res.loc[:,'ポイント採点'] =df_res.loc[:,'ポイント採点'].round(0).astype(int)\n",
    "df_res.head(3)\n",
    "\n",
    "df = df_res\n",
    "\n",
    "name_excel_output = \"crlea_predict_June15_英語.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cebcc8a-0162-4e1b-8129-5feb90289aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_33943/4071173708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0mkamoku\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'数学'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ml_filled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkamoku\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_setsumon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkamoku\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkamoku\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_train' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "予測値を算出し、過去の集計データと共に出力\n",
    "英語\n",
    "\"\"\"\n",
    "kamoku = '数学'\n",
    "df_train=make_train(df_ml_filled,kamoku)\n",
    "df_test=make_test(df_setsumon,kamoku)\n",
    "df_pred = predict_model(df_train, df_test,kamoku)\n",
    "df_ref = make_past_summary(df_ml_filled,\"分野2\")#20-21の過去集計データ\n",
    "df_res = pd.merge(df_pred,df_ref, on = [\"分野\"],how = 'left')\n",
    "df_res.loc[:,'ポイント採点'] =df_res.loc[:,'ポイント採点'].round(0).astype(int)\n",
    "df_res.head(3)\n",
    "\n",
    "df = df_res\n",
    "\n",
    "name_excel_output = \"crlea_predict_June15_数学.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
