{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 過去データを読み込む\n",
    "2. 過去データを整形する\n",
    "3. 過去データを学習してモデルを作る \n",
    "4. 設問データを読み込む\n",
    "5. 設問データをモデルに読み込ませ、予測値を出す\n",
    "6. 予測値を設問データに追加する\n",
    "7. 6のデータに、分野別最終ペースの最大値、最小値、平均値を追加する\n",
    "8. データを出力し、納品する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "#ライブラリの読み込み\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f8f5e-c319-4e63-8814-18c1325b5d80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1cd74-2b99-44c8-8bab-6d91faa9653c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9115482-7b20-4f68-8ea8-45b367e2f4e4",
   "metadata": {},
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b81a0-3fe3-4721-815b-04fd8f09c98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f678ab-13d6-4106-b6b0-f63da9b3ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "df[0]:21夏1年生モデル：検証データ ＝ 21年夏1学年\n",
    "df[1]:21夏2年生モデル：検証データ ＝ 21年夏2学年\n",
    "df[2]:21夏3年生モデル：検証データ ＝ 21年夏3学年\n",
    "df[3]:21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def make_mldata(df,str):\n",
    "    \"\"\"\n",
    "    df:使用するデータ\n",
    "    str:抽出する科目\n",
    "    1.選択した科目を抽出\n",
    "    2.one hot encoding\n",
    "    3.説明変数、目的変数でデータフレームを分離\n",
    "    4.訓練用、検証用にデータフレームを分離\n",
    "        1.21夏1年生モデル：検証データ ＝ 21年夏1学年\n",
    "        2.21夏2年生モデル：検証データ ＝ 21年夏2学年\n",
    "        3.21夏3年生モデル：検証データ ＝ 21年夏3学年\n",
    "        4.21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "    5.説明変数から採点回を削除 \n",
    "    \"\"\"\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df.loc[:,'文字数5'] = df.loc[:,'文字数5'].round(0).astype(int)\n",
    "    #1.科目を抽出し、科目と分野1の列を削除\n",
    "    df = df[df['科目']== str].drop(columns = [\"科目\",\"分野1\",\"文字数\",\"解答言語\"])#解答言語を考慮しない\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = \"最終ペース\")#目的変数を除外した（説明変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回_夏','学年','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離 不恰好なのをどうにかしたい\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train_1 = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==1))]\n",
    "    X_train_2 = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==2))]\n",
    "    X_train_3 = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==3))]\n",
    "    X_train_4 = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21))]\n",
    "    #訓練用目的変数\n",
    "    y_train_1 = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==1))]\n",
    "    y_train_2 = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==2))]\n",
    "    y_train_3 = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==3))]\n",
    "    y_train_4 = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21))]\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test_1 = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==1)]\n",
    "    X_test_2 = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==2)]\n",
    "    X_test_3 = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)&(df_X['学年']==3)]\n",
    "    X_test_4 = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)]\n",
    "    #訓練用目的変数\n",
    "    y_test_1 = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==1)]\n",
    "    y_test_2 = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==2)]\n",
    "    y_test_3 = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)&(df_y['学年']==3)]\n",
    "    y_test_4 = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)]\n",
    "   \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    rem_cols_xb = [\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    rem_cols_y = [\"採点回_夏\",\"年度\",\"学年\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train_1 = X_train_1.drop(columns = rem_cols_x)\n",
    "    X_train_2 = X_train_2.drop(columns = rem_cols_x)\n",
    "    X_train_3 = X_train_3.drop(columns = rem_cols_x)\n",
    "    X_train_4 = X_train_4.drop(columns = rem_cols_x)\n",
    "\n",
    "    #出力用に企画ペースを残している\n",
    "    X_test_1b = X_test_1.drop(columns = rem_cols_xb)\n",
    "    X_test_2b = X_test_2.drop(columns = rem_cols_xb)\n",
    "    X_test_3b = X_test_3.drop(columns = rem_cols_xb)\n",
    "    X_test_4b = X_test_4.drop(columns = rem_cols_xb)    \n",
    "    \n",
    "    X_test_1 = X_test_1.drop(columns = rem_cols_x)\n",
    "    X_test_2 = X_test_2.drop(columns = rem_cols_x)\n",
    "    X_test_3 = X_test_3.drop(columns = rem_cols_x)\n",
    "    X_test_4 = X_test_4.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train_1 = y_train_1.drop(columns = rem_cols_y)\n",
    "    y_train_2 = y_train_2.drop(columns = rem_cols_y)\n",
    "    y_train_3 = y_train_3.drop(columns = rem_cols_y)\n",
    "    y_train_4 = y_train_4.drop(columns = rem_cols_y)\n",
    "\n",
    "    y_test_1 = y_test_1.drop(columns = rem_cols_y)\n",
    "    y_test_2 = y_test_2.drop(columns = rem_cols_y)\n",
    "    y_test_3 = y_test_3.drop(columns = rem_cols_y)\n",
    "    y_test_4 = y_test_4.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[]\n",
    "    data1=[X_train_1,y_train_1,X_test_1,y_test_1,X_test_1b]#1年生モデルデータ なぜかdata1はリストとして入っていて、X_trainとかはdf。\n",
    "    data2=[X_train_2,y_train_2,X_test_2,y_test_2,X_test_2b]#2年生モデルデータ\n",
    "    data3=[X_train_3,y_train_3,X_test_3,y_test_3,X_test_3b]#3年生モデルデータ\n",
    "    data4=[X_train_4,y_train_4,X_test_4,y_test_4,X_test_4b]#学年混合モデルデータ\n",
    "    df_res = [data1, data2, data3, data4]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3552c909-a157-4efb-9e30-22b75977912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def make_train(df,kamoku = str):\n",
    "    \"\"\"\n",
    "    df:使用するデータ\n",
    "    str:抽出する科目\n",
    "    1.選択した科目を抽出\n",
    "    2.one hot encoding\n",
    "    3.説明変数、目的変数でデータフレームを分離\n",
    "    4.訓練用、検証用にデータフレームを分離\n",
    "    5.説明変数から採点回を削除 \n",
    "    \"\"\"\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df.loc[:,'文字数5'] = df.loc[:,'文字数5'].round(0).astype(int)\n",
    "    #1.科目を抽出し、科目と分野1の列を削除\n",
    "    df = df[df['科目']== kamoku].drop(columns = [\"科目\",\"分野1\",\"文字数\",\"解答言語\"])#解答言語を考慮せず、１単語5文字で変換。分野は2の方。\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = \"最終ペース\")#目的変数を除外した（説明変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回_夏','学年','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回_夏'] == 1)&(df_X['年度']==21))]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回_夏'] == 1)&(df_y['年度']==21))]\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回_夏'] == 1)&(df_X['年度']==21)]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回_夏'] == 1)&(df_y['年度']==21)]\n",
    "   \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    # rem_cols_xb = [\"採点回_夏\",\"採点回_秋\",\"採点回_冬\",\"年度\"]\n",
    "    rem_cols_y = [\"採点回_夏\",\"年度\",\"学年\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "813e75be-0c79-42af-a9e3-566998a2ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "df[3]:21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def make_Xtest(df,kamoku = str):\n",
    "    \"\"\"\n",
    "    df:使用するデータ\n",
    "    str:抽出する科目\n",
    "    1.選択した科目を抽出\n",
    "    2.one hot encoding\n",
    "    3.説明変数、目的変数でデータフレームを分離\n",
    "    4.訓練用、検証用にデータフレームを分離\n",
    "    5.説明変数から採点回を削除 \n",
    "    \"\"\"\n",
    "    #0.NAN remove 追加した\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df = df.drop(columns = \"採点回\",\"年度\")#目的変数を除外した（説明変数だけ含む）データフレーム\n",
    "    #1.科目を抽出し、科目と分野1の列を削除\n",
    "    df = df[df['科目']== kamoku].drop(columns = [\"科目\"])\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4f56e3-afa1-4494-947c-01e779ddfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
    "ダミー変数を元に戻す。エクセル出力用\n",
    "\"\"\"\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "954f8a63-9407-4acc-b571-f0873bc17f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def predict_model(df1,df2,a=2,b=1,c=None):#本番用\n",
    "    X_train= df1[0]\n",
    "    y_train= df1[1]\n",
    "    X_test = df2\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_res = df_res.rename(columns={\"文字数5\":\"文字数\"})\n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf90acc7-4703-4991-9b15-46d4ba274f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def predict_model_proto(df,a=2,b=1,c=None):#練習用\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_res = df_res.rename(columns={\"文字数5\":\"文字数\"})\n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "449a2093-194e-401d-9716-5595642bfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_past_summary(df = df_ml_filled,category =str):\n",
    "    \"\"\"\n",
    "    categoryで指定した文字列で集計した\n",
    "    \"\"\"\n",
    "    #0.　生データのNAを削除\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "\n",
    "    #訓練用説明変数\n",
    "    df = df[~((df['採点回'] == \"夏\")&(df['年度']==21))]\n",
    "\n",
    "    group_df1 = df[[category,'最終ペース']].groupby(category).mean().rename(columns={\"最終ペース\":\"平均値\"})\n",
    "    group_df1.reset_index(inplace=True)\n",
    "\n",
    "    group_df2 = df[[category,'最終ペース']].groupby(category).max().rename(columns={\"最終ペース\":\"最大値\"})\n",
    "    group_df2.reset_index(inplace=True)\n",
    "\n",
    "    group_df3 = df[[category,'最終ペース']].groupby(category).min().rename(columns={\"最終ペース\":\"最小値\"})\n",
    "    group_df3.reset_index(inplace=True)\n",
    "\n",
    "    group_df4 = df[[category,'最終ペース']].groupby(category).median().rename(columns={\"最終ペース\":\"中央値\"})\n",
    "    group_df4.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    # merge\n",
    "    group_df = pd.merge(group_df1,group_df2, on = [category],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df3, on = [category],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df4, on = [category],how = 'left')\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5b2ce-35ef-4d8f-8463-cfe1aac48499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6552b818-9c06-4fd6-9b40-f3aa7491454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科目          0\n",
       "企画ペース     149\n",
       "最終ペース       0\n",
       "年度          0\n",
       "採点回         0\n",
       "学年          0\n",
       "分野1         0\n",
       "分野2         0\n",
       "ポイント採点      0\n",
       "文字数         0\n",
       "ポイント数       0\n",
       "配点          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ読み込み マークダウンにしてあるから必要ならコードセルにする\n",
    "\"\"\"\n",
    "data1を加工したcsvファイルを読み込む場合　\n",
    "\"\"\"\n",
    "\n",
    "name_csv = \"crlea_bunya_dm_0613received_0613cleaned_filled_test.csv\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#データが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "df = pd.read_csv(filepath_or_buffer = path_file, sep=\",\",\n",
    "                 usecols=['科目',\n",
    "                          '分野名_修正v1',\n",
    "                          '分野名_修正v2',\n",
    "                          'ポイント採点',\n",
    "                          '年度',\n",
    "                          '採点回',\n",
    "                          '学年',\n",
    "                          '置換後のポイント数',\n",
    "                          # '置換後の文字数',\n",
    "                          '置換後の文字数5',\n",
    "                          # '解答言語',\n",
    "                          '置換後の配点',\n",
    "                          '企画ペース',\n",
    "                          '最終ペース'])\n",
    "#列のリネーム\n",
    "df = df.rename(columns={'分野名_修正v1':'分野1',\n",
    "                        '分野名_修正v2':'分野2',\n",
    "                        '置換後のポイント数':'ポイント数',\n",
    "                        # '置換後の文字数':'文字数',#英語1単語も1文字として数えた\n",
    "                        '置換後の文字数5':'文字数',#英語１単語を5文字とした。前の分析ではこっち。精度を比較する。\n",
    "                        '置換後の配点':'配点'})\n",
    "df_raw = df\n",
    "\n",
    "df1 = df_raw\n",
    "df1 = df1.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f690a6c-ed8d-453e-92fd-5e69ff079875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "holdout検証用の学習データと検証データを分割\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def sep_train_test(df):\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    # df_X = df.drop(columns = \"最終ペース\")#目的変数を除外した（説明変数だけ含む）データフレーム\n",
    "    # df_y = df.loc[:,['年度','採点回','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    train = df[~((df['採点回'] == \"夏\")&(df['年度']==21))]\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df[(df['採点回'] == \"夏\")&(df['年度']==21)]\n",
    "   \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\"]\n",
    "\n",
    "    train = train.drop(columns = rem_cols)#.reset_index(inplace=True)\n",
    "    test = test.drop(columns = rem_cols)#.reset_index(inplace=True)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[train,test]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6a2a1b-ed6a-4f46-b9b6-c4742d4d81d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_80408/355231003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msep_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"訓練用データは\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"テスト用データは\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#目的変数の割合が等しくなるようにデータセットを分割\n",
    "df = df1\n",
    "df2 = sep_train_test(df)\n",
    "print(\"訓練用データは\" + str(len(df2[0])))\n",
    "print(\"テスト用データは\" + str(len(df2[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e859f944-c0c9-4635-b249-772f70f695af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>科目</th>\n",
       "      <th>最終ペース</th>\n",
       "      <th>学年</th>\n",
       "      <th>分野1</th>\n",
       "      <th>分野2</th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>文字数</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>配点</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>国語</td>\n",
       "      <td>143.4</td>\n",
       "      <td>1</td>\n",
       "      <td>評論</td>\n",
       "      <td>評論</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>国語</td>\n",
       "      <td>449.8</td>\n",
       "      <td>1</td>\n",
       "      <td>評論</td>\n",
       "      <td>評論</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>国語</td>\n",
       "      <td>693.1</td>\n",
       "      <td>2</td>\n",
       "      <td>評論</td>\n",
       "      <td>評論</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>国語</td>\n",
       "      <td>118.8</td>\n",
       "      <td>2</td>\n",
       "      <td>評論</td>\n",
       "      <td>評論</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>国語</td>\n",
       "      <td>149.7</td>\n",
       "      <td>1</td>\n",
       "      <td>評論</td>\n",
       "      <td>評論</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   科目  最終ペース  学年 分野1 分野2  ポイント採点  文字数  ポイント数  配点\n",
       "0  国語  143.4   1  評論  評論       1   60      3   6\n",
       "1  国語  449.8   1  評論  評論       0   40      3   5\n",
       "2  国語  693.1   2  評論  評論       0   20      3  10\n",
       "3  国語  118.8   2  評論  評論       0   70      3   8\n",
       "4  国語  149.7   1  評論  評論       1   70      3   6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6734ac4d-1c55-4475-a72d-ff22f1debf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "分野1\n",
       "いろいろな式          271.453236\n",
       "データの分析          255.561402\n",
       "ベクトル            202.479027\n",
       "三角関数            238.187761\n",
       "二次関数            255.855063\n",
       "内容説明            374.870704\n",
       "古文              415.605457\n",
       "和文英訳             89.146906\n",
       "図形と方程式          205.809042\n",
       "図形と計量           295.068118\n",
       "図形の性質           226.375317\n",
       "場合の数と確率         257.894166\n",
       "小説              196.792118\n",
       "平面上の曲線と複素数平面    122.250953\n",
       "微分法・積分法         154.875283\n",
       "指数関数・対数関数       177.285844\n",
       "数と式             283.565098\n",
       "数列              195.060909\n",
       "数列の極限           143.206546\n",
       "整数の性質           189.500000\n",
       "漢文              414.567555\n",
       "自由英作文            54.158907\n",
       "英作文             464.375432\n",
       "英文和訳            260.326921\n",
       "評論              257.580017\n",
       "随筆              158.970513\n",
       "Name: 最終ペース, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Holdout Target Encodingの関数定義\n",
    "#Kfoldの定義\n",
    "df= df1\n",
    "column = \"分野1\"\n",
    "target = \"最終ペース\"\n",
    "kf = KFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "#仮の箱を用意\n",
    "box = np.zeros(len(df))\n",
    "#Nanで埋めておく\n",
    "box[:] = np.nan\n",
    "#繰り返しながらTarget Encodingを行う\n",
    "for train_index, test_index in kf.split(df):\n",
    "    #２分割　訓練データと検証データ\n",
    "    train_cv = df.iloc[train_index]\n",
    "    # print(train_cv)\n",
    "    test_cv = df[column].iloc[test_index]# dataframe columnのtest_index行目\n",
    "    # print(test_cv)\n",
    "    #column別のtarget平均をtraimで計算\n",
    "    mean = train_cv.groupby(column)[target].mean()\n",
    "    #boxにcolumn別のtarget平均を入れる\n",
    "\n",
    "    \n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d0b520-1bb2-4fbf-b63a-93c232baad7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 479 is out of bounds for axis 0 with size 479",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_80408/4148057768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHoldout_te\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"分野1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"最終ペース\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHoldout_te\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"分野2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"最終ペース\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_80408/4148057768.py\u001b[0m in \u001b[0;36mHoldout_te\u001b[0;34m(df, column, target)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#indexとvalueかな。enumerateと同じ感じ。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#testのインデックスを一つずつ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m#新たな列に挿入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 479 is out of bounds for axis 0 with size 479"
     ]
    }
   ],
   "source": [
    "#Holdout Target Encodingの関数定義\n",
    "def Holdout_te(df,column,target):\n",
    "    #Kfoldの定義\n",
    "    kf = KFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "    #仮の箱を用意\n",
    "    box = np.zeros(len(df))\n",
    "    #Nanで埋めておく\n",
    "    box[:] = np.nan\n",
    "    #繰り返しながらTarget Encodingを行う\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        #２分割　訓練データと検証データ\n",
    "        train_cv = df.iloc[train_index]\n",
    "        # print(train_cv)\n",
    "        test_cv = df[column].iloc[test_index]# dataframe columnのtest_index行目\n",
    "        # print(test_cv)\n",
    "        #column別のtarget平均をtraimで計算\n",
    "        mean = train_cv.groupby(column)[target].mean()\n",
    "        #boxにcolumn別のtarget平均を入れる\n",
    "        for i,m in mean.iteritems():#column名とvalueが入っている\n",
    "            for v in test_cv.index:#testの行のインデックスを一つずつ\n",
    "                if test_cv[v] == i: #columnmの変数名が\n",
    "                    box[v] = m\n",
    "    #新たな列に挿入\n",
    "    df[column + \"_target\"] = box\n",
    "    return df\n",
    "\n",
    "df=Holdout_te(df1, \"分野1\", \"最終ペース\")\n",
    "df=Holdout_te(df1, \"分野2\", \"最終ペース\")\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44b41f0-6602-424a-9ae4-5f0e485b68b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  column1 column2  target  column1_target  column2_target\n",
      "2       A       D       0        0.333333        0.250000\n",
      "3       A       D       1        0.333333        0.250000\n",
      "6       B       D       1        0.500000        0.333333\n",
      "7       B       D       1        0.500000        0.250000\n",
      "8       B       E       0        0.500000             NaN\n",
      "9       B       E       1        0.500000             NaN\n",
      "  column1 column2  target  column1_target  column2_target\n",
      "0       A       C       1            0.50             NaN\n",
      "1       A       D       0            0.50        0.750000\n",
      "4       A       D       0            0.50        0.750000\n",
      "5       B       D       0            0.75        0.750000\n",
      "6       B       D       1            0.50        0.333333\n",
      "8       B       E       0            0.50             NaN\n",
      "9       B       E       1            0.50             NaN\n",
      "  column1 column2  target  column1_target  column2_target\n",
      "0       A       C       1        0.500000             NaN\n",
      "1       A       D       0        0.500000            0.75\n",
      "2       A       D       0        0.333333            0.25\n",
      "3       A       D       1        0.333333            0.25\n",
      "4       A       D       0        0.500000            0.75\n",
      "5       B       D       0        0.750000            0.75\n",
      "7       B       D       1        0.500000            0.25\n",
      "  column1 column2  target  column1_target  column2_target\n",
      "2       A       D       0        0.333333        0.250000\n",
      "3       A       D       1        0.333333        0.250000\n",
      "6       B       D       1        0.500000        0.333333\n",
      "7       B       D       1        0.500000        0.250000\n",
      "8       B       E       0        0.500000             NaN\n",
      "9       B       E       1        0.500000             NaN\n",
      "  column1 column2  target  column1_target  column2_target\n",
      "0       A       C       1            0.50             NaN\n",
      "1       A       D       0            0.50        0.750000\n",
      "4       A       D       0            0.50        0.750000\n",
      "5       B       D       0            0.75        0.750000\n",
      "6       B       D       1            0.50        0.333333\n",
      "8       B       E       0            0.50             NaN\n",
      "9       B       E       1            0.50             NaN\n",
      "  column1 column2  target  column1_target  column2_target\n",
      "0       A       C       1        0.500000             NaN\n",
      "1       A       D       0        0.500000            0.75\n",
      "2       A       D       0        0.333333            0.25\n",
      "3       A       D       1        0.333333            0.25\n",
      "4       A       D       0        0.500000            0.75\n",
      "5       B       D       0        0.750000            0.75\n",
      "7       B       D       1        0.500000            0.25\n"
     ]
    }
   ],
   "source": [
    "#[IN]:\n",
    "#Holdout Target Encodingの関数定義\n",
    "def Holdout_te(df,column,target):\n",
    "    #Kfoldの定義\n",
    "    kf = KFold(n_splits = 3, shuffle = True, random_state = 2)\n",
    "    #仮の箱を用意\n",
    "    box = np.zeros(len(df))\n",
    "    #Nanで埋めておく\n",
    "    box[:] = np.nan\n",
    "    #繰り返しながらTarget Encodingを行う\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        #２分割　訓練データと検証データ\n",
    "        train = df.iloc[train_index]\n",
    "        print(train)\n",
    "        test = df[column].iloc[test_index]\n",
    "        # print(test)\n",
    "        #column別のtarget平均をtraimで計算\n",
    "        mean = train.groupby(column)[target].mean()\n",
    "        #boxにcolumn別のtarget平均を入れる\n",
    "        for i,m in mean.iteritems():#indexとvalueかな。enumerateと同じ感じ。\n",
    "            for v in test.index:#testのインデックスを一つずつ\n",
    "                if test[v] == i: box[v] = m\n",
    "    #新たな列に挿入\n",
    "    df[column + \"_target\"] = box\n",
    "    return df\n",
    "df=Holdout_te(df, \"column1\", \"target\")\n",
    "df=Holdout_te(df, \"column2\", \"target\")\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04731d-161c-47f6-93b4-48e3fe78f334",
   "metadata": {},
   "source": [
    "# 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d38c7ec-1e1e-49d7-aa46-2432805320f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数5</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野2_古文</th>\n",
       "      <th>分野2_小説</th>\n",
       "      <th>分野2_漢文</th>\n",
       "      <th>分野2_評論</th>\n",
       "      <th>分野2_随筆</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ポイント採点  学年  ポイント数  文字数5  配点  分野2_古文  分野2_小説  分野2_漢文  分野2_評論  分野2_随筆\n",
       "165       0   1      2    30   4       0       0       0       1       0\n",
       "166       1   1      3    60   6       0       0       0       1       0\n",
       "187       0   2      3    60   5       0       0       0       1       0\n",
       "188       1   2      3    70   8       0       0       0       1       0\n",
       "216       0   3      3    50   9       0       0       0       1       0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "予測値を算出し、過去の集計データと共に出力\n",
    "国語\n",
    "\"\"\"\n",
    "\n",
    "df1 = make_train(df_past,\"国語\")#20&21の過去データを入力\n",
    "df2 = make_Xtest(df_setsumon,\"国語\")#22夏の設問データを入力\n",
    "df3 = predict_model(df1,df2)#df1のデータで訓練、df2のデータで予測した値\n",
    "df4 = make_past_summary(df_past,\"分野2\")#20&21の過去データを入力\n",
    "df_res = pd.merge(df3,df4, on = [\"分野2\"],how = 'left')#予測値に過去の集計データをマージ\n",
    "df_res =df_res.rename(columns={\"分野2\":\"分野\"})\n",
    "df_res['科目']=\"国語\"\n",
    "df_res.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f7af6ca9-9c76-43d7-b360-64ad9d51a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "\n",
    "df = df_res\n",
    "\n",
    "name_excel_output = \"crlea_predict_June15.csv\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "df.to_csv('{}/{}'.format(path_folder,name_excel_output),encoding='utf-8-sig',index=False)\n",
    "\n",
    "name_excel_output = \"crlea_predict_June15.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df.to_excel(writer, sheet_name='data1',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d3cfa67-39d0-4be9-8fde-9bfc1e7567a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ポイント採点</th>\n",
       "      <th>学年</th>\n",
       "      <th>ポイント数</th>\n",
       "      <th>文字数</th>\n",
       "      <th>配点</th>\n",
       "      <th>分野2</th>\n",
       "      <th>AI想定ペース</th>\n",
       "      <th>平均値</th>\n",
       "      <th>最大値</th>\n",
       "      <th>最小値</th>\n",
       "      <th>中央値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>評論</td>\n",
       "      <td>375.100000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>評論</td>\n",
       "      <td>143.400000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>評論</td>\n",
       "      <td>118.800000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>評論</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>評論</td>\n",
       "      <td>171.800000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>評論</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>評論</td>\n",
       "      <td>255.313191</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>評論</td>\n",
       "      <td>255.313191</td>\n",
       "      <td>258.680738</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>79.4</td>\n",
       "      <td>192.914205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>小説</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>185.280962</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>100.5</td>\n",
       "      <td>174.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>小説</td>\n",
       "      <td>125.800000</td>\n",
       "      <td>185.280962</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>100.5</td>\n",
       "      <td>174.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>小説</td>\n",
       "      <td>171.800000</td>\n",
       "      <td>185.280962</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>100.5</td>\n",
       "      <td>174.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>小説</td>\n",
       "      <td>155.100000</td>\n",
       "      <td>185.280962</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>100.5</td>\n",
       "      <td>174.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>古文</td>\n",
       "      <td>467.600000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>古文</td>\n",
       "      <td>192.800000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>古文</td>\n",
       "      <td>323.124320</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>古文</td>\n",
       "      <td>248.600000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>古文</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>古文</td>\n",
       "      <td>654.500000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>古文</td>\n",
       "      <td>230.418294</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>古文</td>\n",
       "      <td>155.100000</td>\n",
       "      <td>391.273542</td>\n",
       "      <td>1374.213109</td>\n",
       "      <td>131.1</td>\n",
       "      <td>321.312160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>漢文</td>\n",
       "      <td>474.228571</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>漢文</td>\n",
       "      <td>509.775861</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>漢文</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>漢文</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>漢文</td>\n",
       "      <td>452.594104</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>漢文</td>\n",
       "      <td>328.800000</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>漢文</td>\n",
       "      <td>463.100000</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>漢文</td>\n",
       "      <td>231.367818</td>\n",
       "      <td>444.658897</td>\n",
       "      <td>1699.600000</td>\n",
       "      <td>110.9</td>\n",
       "      <td>364.365699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>随筆</td>\n",
       "      <td>157.300000</td>\n",
       "      <td>260.022102</td>\n",
       "      <td>757.980047</td>\n",
       "      <td>132.6</td>\n",
       "      <td>166.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>随筆</td>\n",
       "      <td>188.600000</td>\n",
       "      <td>260.022102</td>\n",
       "      <td>757.980047</td>\n",
       "      <td>132.6</td>\n",
       "      <td>166.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ポイント採点  学年  ポイント数  文字数  配点 分野2     AI想定ペース         平均値          最大値  \\\n",
       "0        0   1      2   30   4  評論  375.100000  258.680738  1042.000000   \n",
       "1        1   1      3   60   6  評論  143.400000  258.680738  1042.000000   \n",
       "2        0   2      3   60   5  評論  118.800000  258.680738  1042.000000   \n",
       "3        1   2      3   70   8  評論  131.000000  258.680738  1042.000000   \n",
       "4        0   3      3   50   9  評論  171.800000  258.680738  1042.000000   \n",
       "5        0   3      3   90  14  評論  138.000000  258.680738  1042.000000   \n",
       "6        0   3      3   90  13  評論  255.313191  258.680738  1042.000000   \n",
       "7        0   3      3   90  12  評論  255.313191  258.680738  1042.000000   \n",
       "8        1   1      3   60   6  小説  138.500000  185.280962   363.700000   \n",
       "9        1   2      3   60   5  小説  125.800000  185.280962   363.700000   \n",
       "10       0   3      3   50   8  小説  171.800000  185.280962   363.700000   \n",
       "11       0   3      4  100  11  小説  155.100000  185.280962   363.700000   \n",
       "12       0   1      2   25   5  古文  467.600000  391.273542  1374.213109   \n",
       "13       0   1      3   40   6  古文  192.800000  391.273542  1374.213109   \n",
       "14       0   1      2   30   3  古文  323.124320  391.273542  1374.213109   \n",
       "15       0   1      2   40   5  古文  248.600000  391.273542  1374.213109   \n",
       "16       0   2      3   70   8  古文  117.500000  391.273542  1374.213109   \n",
       "17       0   2      3   17   5  古文  654.500000  391.273542  1374.213109   \n",
       "18       0   3      3   29  11  古文  230.418294  391.273542  1374.213109   \n",
       "19       0   3      4   70  14  古文  155.100000  391.273542  1374.213109   \n",
       "20       0   1      2   35   5  漢文  474.228571  444.658897  1699.600000   \n",
       "21       0   1      2   13   2  漢文  509.775861  444.658897  1699.600000   \n",
       "22       0   1      2   24   2  漢文  166.600000  444.658897  1699.600000   \n",
       "23       0   2      3   20   4  漢文  491.000000  444.658897  1699.600000   \n",
       "24       0   2      2   23   3  漢文  452.594104  444.658897  1699.600000   \n",
       "25       0   2      3   30   5  漢文  328.800000  444.658897  1699.600000   \n",
       "26       0   3      3   45   7  漢文  463.100000  444.658897  1699.600000   \n",
       "27       0   3      3   60   9  漢文  231.367818  444.658897  1699.600000   \n",
       "28       0   3      2   60  16  随筆  157.300000  260.022102   757.980047   \n",
       "29       0   3      2   90  10  随筆  188.600000  260.022102   757.980047   \n",
       "\n",
       "      最小値         中央値  \n",
       "0    79.4  192.914205  \n",
       "1    79.4  192.914205  \n",
       "2    79.4  192.914205  \n",
       "3    79.4  192.914205  \n",
       "4    79.4  192.914205  \n",
       "5    79.4  192.914205  \n",
       "6    79.4  192.914205  \n",
       "7    79.4  192.914205  \n",
       "8   100.5  174.350000  \n",
       "9   100.5  174.350000  \n",
       "10  100.5  174.350000  \n",
       "11  100.5  174.350000  \n",
       "12  131.1  321.312160  \n",
       "13  131.1  321.312160  \n",
       "14  131.1  321.312160  \n",
       "15  131.1  321.312160  \n",
       "16  131.1  321.312160  \n",
       "17  131.1  321.312160  \n",
       "18  131.1  321.312160  \n",
       "19  131.1  321.312160  \n",
       "20  110.9  364.365699  \n",
       "21  110.9  364.365699  \n",
       "22  110.9  364.365699  \n",
       "23  110.9  364.365699  \n",
       "24  110.9  364.365699  \n",
       "25  110.9  364.365699  \n",
       "26  110.9  364.365699  \n",
       "27  110.9  364.365699  \n",
       "28  132.6  166.500000  \n",
       "29  132.6  166.500000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_ml_filled\n",
    "df1 = predict_model(make_mldata(df,\"国語\")[3])\n",
    "df2 = make_past_summary(df,\"分野2\")\n",
    "df_res = pd.merge(df1,df2, on = [\"分野2\"],how = 'left')\n",
    "df_res.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74ac379b-f639-4c34-9c7a-9ca4b7cc491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"欠損値を補完したデータの予測値\"\"\"\n",
    "#予測値と統計値を各科目のモデルごとにエクセルシートに出力\n",
    "\n",
    "\n",
    "kamoku=[\"国語\",\"英語\",\"数学\"]#,\"数学\"は文字数がないため、dropnaで除外してしまっている。前処理で変更する必要あり。\n",
    "model=[\"1年\",\"2年\",\"3年\",\"学年混合\"]\n",
    "\n",
    "mss= 2#min sample split\n",
    "msl= 1#min sample leaf\n",
    "md=None #max depth\n",
    "test_num=\"June3\"\n",
    "\n",
    "name_file = \"DTs_{}_mss{}_msl{}_md{}.xlsx\".format(str(test_num),str(mss),str(msl),str(md)) #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "# path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "# 入力データ\n",
    "df = df_ml_filled\n",
    "df1=[[[],[],[],[]],[[],[],[],[]],[[],[],[],[]]]\n",
    "df2=[[[],[],[],[]],[[],[],[],[]],[[],[],[],[]]]\n",
    "for i,n in enumerate(kamoku):\n",
    "    for j,m in enumerate(model):\n",
    "        df1[i][j] = test_model2(make_mldata(df,kamoku[i])[j],mss,msl,md)\n",
    "        df2[i][j] = pandas_tool.summary(df1[i][j].loc[:,['最終ペース','企画ペース','AI想定ペース','誤差','AI乖離度','元の乖離度']])[0]\n",
    "        \n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_file)) as writer:\n",
    "    for i,n in enumerate(kamoku):\n",
    "        for j,m in enumerate(model):\n",
    "            s_names=['{}_{}_values'.format(kamoku[i],model[j]),'{}_{}_stats'.format(kamoku[i],model[j])]\n",
    "            df1[i][j].to_excel(writer, sheet_name='{}'.format(s_names[0]))\n",
    "            df2[i][j].to_excel(writer, sheet_name='{}'.format(s_names[1]))\n",
    "            \n",
    "            \n",
    "# =IFS(M2>=600,6,M2>=500,5,M2>=400,4,M2>=300,3,M2>=200,2,M2>=100,1,TRUE,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
