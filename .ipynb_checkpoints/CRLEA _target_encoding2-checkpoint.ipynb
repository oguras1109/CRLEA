{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 過去データを読み込む\n",
    "2. 過去データを整形する\n",
    "3. 過去データを学習してモデルを作る \n",
    "4. 設問データを読み込む\n",
    "5. 設問データをモデルに読み込ませ、予測値を出す\n",
    "6. 予測値を設問データに追加する\n",
    "7. 6のデータに、分野別最終ペースの最大値、最小値、平均値を追加する\n",
    "8. データを出力し、納品する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "#ライブラリの読み込み\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f8f5e-c319-4e63-8814-18c1325b5d80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6552b818-9c06-4fd6-9b40-f3aa7491454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科目          0\n",
       "企画ペース     171\n",
       "最終ペース       0\n",
       "年度          0\n",
       "採点回         0\n",
       "学年          0\n",
       "分野1         0\n",
       "分野2         0\n",
       "ポイント採点      0\n",
       "文字数         0\n",
       "ポイント数       0\n",
       "配点          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ読み込み マークダウンにしてあるから必要ならコードセルにする\n",
    "\"\"\"\n",
    "data1を加工したcsvファイルを読み込む場合　\n",
    "\"\"\"\n",
    "\n",
    "name_csv = \"crlea_bunya_dm_0613received_0613cleaned_filled_test.csv\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#データが置いてあるフォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "df = pd.read_csv(filepath_or_buffer = path_file, sep=\",\",\n",
    "                 usecols=['科目',\n",
    "                          '分野名_修正v1',\n",
    "                          '分野名_修正v2',\n",
    "                          'ポイント採点',\n",
    "                          '年度',\n",
    "                          '採点回',\n",
    "                          '学年',\n",
    "                          '置換後のポイント数',\n",
    "                          # '置換後の文字数',\n",
    "                          '置換後の文字数5',\n",
    "                          # '解答言語',\n",
    "                          '置換後の配点',\n",
    "                          '企画ペース',\n",
    "                          '最終ペース'])\n",
    "#列のリネーム\n",
    "df = df.rename(columns={'分野名_修正v1':'分野1',\n",
    "                        '分野名_修正v2':'分野2',\n",
    "                        '置換後のポイント数':'ポイント数',\n",
    "                        # '置換後の文字数':'文字数',#英語1単語も1文字として数えた\n",
    "                        '置換後の文字数5':'文字数',#英語１単語を5文字とした。前の分析ではこっち。精度を比較する。\n",
    "                        '置換後の配点':'配点'})\n",
    "df_raw = df\n",
    "\n",
    "df1 = df_raw\n",
    "df1 = df1.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1cd74-2b99-44c8-8bab-6d91faa9653c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9115482-7b20-4f68-8ea8-45b367e2f4e4",
   "metadata": {},
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b81a0-3fe3-4721-815b-04fd8f09c98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f54609d-bcf8-4526-8f09-8f10be8bb204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n作業方針\\n20年と２１年で分ける\\n２０年の分野別最終ペース平均を作る\\n２１年にマージする\\n２１年の夏とそれ以外で機械学習を実施\\n結果を検証する\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "作業方針\n",
    "20年と２１年で分ける\n",
    "２０年の分野別最終ペース平均を作る\n",
    "２１年にマージする\n",
    "２１年の夏とそれ以外で機械学習を実施\n",
    "結果を検証する\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f690a6c-ed8d-453e-92fd-5e69ff079875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "holdout検証用の学習データと検証データを分割\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def te_20to21(df):\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    \n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "    \n",
    "    #Target encording\n",
    "    #20年のデータで分野別平均値をとる\n",
    "    bunya1 = df1.groupby('分野1', as_index=False)['最終ペース'].mean()\n",
    "    bunya1= bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya2 = df1.groupby('分野2', as_index=False)['最終ペース'].mean()\n",
    "    bunya2= bunya2.rename(columns = {\"最終ペース\":\"分野2TS\"})\n",
    "    \n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key='分野1')\n",
    "    df2 = pandas_tool.merge(df2,bunya2, how='left', key='分野2')\n",
    "\n",
    "    \n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1e1301c7-f00c-40b1-94d1-24d054f92caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数学科目だけ選択\n",
    "holdout検証用の学習データと検証データを分割\n",
    "1単語を文字数5で数える\n",
    "機械学習用データを準備する関数\n",
    "21夏学年混合モデル：検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def te_20to21_math(df):\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df = df[df['科目']==\"数学\"]\n",
    "    \n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "    \n",
    "    #Target encording\n",
    "    #20年のデータで分野別平均値をとる\n",
    "    bunya1 = df1.groupby('分野1', as_index=False)['最終ペース'].mean()\n",
    "    bunya1= bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya2 = df1.groupby('分野2', as_index=False)['最終ペース'].mean()\n",
    "    bunya2= bunya2.rename(columns = {\"最終ペース\":\"分野2TS\"})\n",
    "    \n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key='分野1')\n",
    "    df2 = pandas_tool.merge(df2,bunya2, how='left', key='分野2')\n",
    "\n",
    "    \n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e67dff20-5dd5-489f-bcba-f0e76738c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数学科目だけ選択\n",
    "target encording = 分野1を、20年の学年分野別最終ペースの平均値で代用\n",
    "holdout検証用の学習データと検証データを分割\n",
    "学習データ　＝21年秋冬全学年\n",
    "検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def te_20to21_math_gakunenbunya(df):#target_encordingを20年のデータで行い、21年のデータに適応。mathのみのデータで。\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    df = df[df['科目']==\"数学\"]\n",
    "    \n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "    \n",
    "    #Target encording\n",
    "    #20年のデータで学年分野別平均値をとる\n",
    "    bunya1 = df1.groupby(['学年','分野1'], as_index=False)['最終ペース'].mean()\n",
    "    bunya1 = bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya2 = df1.groupby(['学年','分野2'], as_index=False)['最終ペース'].mean()\n",
    "    bunya2 = bunya2.rename(columns = {\"最終ペース\":\"分野2TS\"})\n",
    "    #20年のデータで学年別平均値をとる\n",
    "    gakunen = df1.groupby('学年', as_index=False)['最終ペース'].mean()\n",
    "    gakunen = gakunen.rename(columns = {\"最終ペース\":\"学年平均\"})\n",
    "\n",
    "\n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key=['学年','分野1'])\n",
    "    df2 = pandas_tool.merge(df2,bunya2, how='left', key=['学年','分野2'])\n",
    "    df2 = pandas_tool.merge(df2,gakunen, how='left', key='学年')\n",
    "\n",
    "    df2['分野1TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2['分野2TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2 = df2.drop(columns = [\"学年平均\"])\n",
    "\n",
    "    \n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a389fce-37a1-4c1a-9d04-de47768f5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数学科目だけ選択\n",
    "target encording = 分野1を、20年の2年かそれ以外の学年かの分野別最終ペースの平均値で代用\n",
    "holdout検証用の学習データと検証データを分割\n",
    "学習データ　＝21年秋冬全学年\n",
    "検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def te_20to21_math_2nenbunya(df):#target_encordingを20年のデータで行い、21年のデータに適応。mathのみのデータで。\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    #2年なら1、それ以外なら0\n",
    "    conditions = [df['学年'] ==2]\n",
    "    choices = [1]\n",
    "    df['label2'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "    #数学だけ\n",
    "    df = df[df['科目']==\"数学\"]\n",
    "\n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "\n",
    "    #Target encording\n",
    "    #20年のデータで学年分野別平均値をとる\n",
    "    bunya1 = df1.groupby(['label2','分野1'], as_index=False)['最終ペース'].mean()\n",
    "    bunya1 = bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya2 = df1.groupby(['label2','分野2'], as_index=False)['最終ペース'].mean()\n",
    "    bunya2 = bunya2.rename(columns = {\"最終ペース\":\"分野2TS\"})\n",
    "    #20年のデータで学年別平均値をとる\n",
    "    gakunen = df1.groupby('label2', as_index=False)['最終ペース'].mean()\n",
    "    gakunen = gakunen.rename(columns = {\"最終ペース\":\"学年平均\"})\n",
    "\n",
    "\n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key=['label2','分野1'])\n",
    "    df2 = pandas_tool.merge(df2,bunya2, how='left', key=['label2','分野2'])\n",
    "    df2 = pandas_tool.merge(df2,gakunen, how='left', key='label2')\n",
    "\n",
    "    df2['分野1TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2['分野2TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2 = df2.drop(columns = [\"学年平均\"])\n",
    "\n",
    "    \n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\",\"学年\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\",\"学年\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "    y_gakunen = test['学年']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku, y_gakunen]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5d80c3-caaf-4816-b762-cef3241b4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数学科目だけ選択\n",
    "target encording = 分野1を、20年の2年かそれ以外の学年かの分野別最終ペースの平均値で代用\n",
    "holdout検証用の学習データと検証データを分割\n",
    "学習データ　＝21年秋冬全学年\n",
    "検証データ ＝ 21年夏全学年\n",
    "\"\"\"\n",
    "\n",
    "def te_20to21_math_2nenbunya_gakunenbunya(df):#target_encordingを20年のデータで行い、21年のデータに適応。mathのみのデータで。\n",
    "    #0.NAN remove 追加した\n",
    "    df = df.dropna(subset=['ポイント数', '配点', '文字数'])\n",
    "    df.loc[:,'ポイント数'] =df.loc[:,'ポイント数'].round(0).astype(int)\n",
    "    df.loc[:,'配点'] = df.loc[:,'配点'].round(0).astype(int)\n",
    "    df.loc[:,'文字数'] = df.loc[:,'文字数'].round(0).astype(int)\n",
    "    #2年なら1、それ以外なら0\n",
    "    conditions = [df['学年'] ==2]\n",
    "    choices = [1]\n",
    "    df['label2'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "    #数学だけ\n",
    "    df = df[df['科目']==\"数学\"]\n",
    "\n",
    "    #データフレームの分離\n",
    "    df1 = df[df['年度']==20] #20年のデータ。target encording\n",
    "    df2 = df[df['年度']==21] #21年のデータ。機械学習用\n",
    "\n",
    "    #Target encording\n",
    "    #20年のデータで学年分野別平均値をとる\n",
    "    bunya1 = df1.groupby(['学年','分野1'], as_index=False)['最終ペース'].mean()\n",
    "    bunya1 = bunya1.rename(columns = {\"最終ペース\":\"分野1TS\"})\n",
    "    bunya2 = df1.groupby(['学年','分野2'], as_index=False)['最終ペース'].mean()\n",
    "    bunya2 = bunya2.rename(columns = {\"最終ペース\":\"分野2TS\"})\n",
    "    #20年のデータで学年別平均値をとる\n",
    "    gakunen = df1.groupby('学年', as_index=False)['最終ペース'].mean()\n",
    "    gakunen = gakunen.rename(columns = {\"最終ペース\":\"学年平均\"})\n",
    "\n",
    "\n",
    "    df2 = pandas_tool.merge(df2,bunya1, how='left', key=['学年','分野1'])\n",
    "    df2 = pandas_tool.merge(df2,bunya2, how='left', key=['学年','分野2'])\n",
    "    df2 = pandas_tool.merge(df2,gakunen, how='left', key='学年')\n",
    "    \n",
    "    df2['分野1TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2['分野2TS'].fillna(df2['学年平均'], inplace=True)\n",
    "    df2 = df2.drop(columns = [\"学年平均\"])\n",
    "\n",
    "    \n",
    "    #機械学習の訓練と検証\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    rem_cols= [\"企画ペース\",\"採点回\",\"年度\",\"学年\"]\n",
    "    train = df2[~(df2['採点回'] == \"夏\")]\n",
    "    train = train.drop(columns = rem_cols)\n",
    "    \n",
    "    X_train =train.drop('最終ペース', axis=1)\n",
    "    y_train =train['最終ペース']\n",
    "\n",
    "    \"\"\"夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    test = df2[(df2['採点回'] == \"夏\")]\n",
    "    X_test =test.drop(columns=['最終ペース',\"企画ペース\",\"採点回\",\"年度\",\"学年\"])\n",
    "    y_test =test['最終ペース']\n",
    "    y_kikaku =test['企画ペース']\n",
    "    y_kamoku = test['科目']\n",
    "    y_gakunen = test['学年']\n",
    "\n",
    "    df_res=[X_train, y_train, X_test,  y_test, y_kikaku, y_kamoku, y_gakunen]#学年混合モデルデータ\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b6a2a1b-ed6a-4f46-b9b6-c4742d4d81d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "74\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:32\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "92\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:14\n",
      "mergeのオブザベーション:106\n",
      "X_train66\n",
      "X_testは66\n",
      "y_trainは40\n",
      "y_testは40\n"
     ]
    }
   ],
   "source": [
    "#データ数のチェック\n",
    "df2 = te_20to21_gakunenbunya_math(df_raw)\n",
    "print(\"X_train\" + str(len(df2[0])))\n",
    "print(\"X_testは\" + str(len(df2[1])))\n",
    "print(\"y_trainは\" + str(len(df2[2])))\n",
    "print(\"y_testは\" + str(len(df2[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb78947-b274-4a34-9dbc-de9daa6349d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def test_model1(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    kikaku = df[4]\n",
    "    kamoku = df[5]\n",
    "    rem_cols= [\"科目\",\"分野1\",\"分野2\",\"分野2TS\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    \n",
    "    X_test_excel = df[2]\n",
    "    rem_cols= [\"科目\",\"分野2\",\"分野2TS\"]\n",
    "    X_test_excel = X_test_excel.drop(columns = rem_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    #得た結果の樹形図を表示する\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    \n",
    "    #検証に使った説明変数データのダミー変数を元に戻す\n",
    "    df_res = X_test_excel \n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'企画ペース']= kikaku\n",
    "    df_res.loc[:,'科目']= kamoku\n",
    "    df_res.loc[:,'誤差']= df_res['AI想定ペース']-df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI想定ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "            \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22566a8-f0df-4837-a6eb-c2efd77c1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def test_model1_2(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    kikaku = df[4]\n",
    "    kamoku = df[5]\n",
    "    gakunen=df[6]\n",
    "    rem_cols= [\"科目\",\"分野1\",\"分野2\",\"分野2TS\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    \n",
    "    X_test_excel = df[2]\n",
    "    rem_cols= [\"科目\",\"分野2\",\"分野2TS\"]\n",
    "    X_test_excel = X_test_excel.drop(columns = rem_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    #得た結果の樹形図を表示する\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    \n",
    "    #検証に使った説明変数データのダミー変数を元に戻す\n",
    "    df_res = X_test_excel \n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'企画ペース']= kikaku\n",
    "    df_res.loc[:,'科目']= kamoku\n",
    "    df_res.loc[:,'学年']= gakunen\n",
    "    df_res.loc[:,'誤差']= df_res['AI想定ペース']-df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI想定ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "            \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ea5f596-61d3-4cd5-9d66-a67ef670b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_mldataのseriesを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "\"\"\"\n",
    "def test_model2(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    kikaku = df[4]\n",
    "    kamoku = df[5]\n",
    "    rem_cols= [\"科目\",\"分野2\",\"分野1\",\"分野1TS\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    \n",
    "    X_test_excel = df[2]\n",
    "    rem_cols= [\"科目\",\"分野1\",\"分野1TS\"]\n",
    "    X_test_excel = X_test_excel.drop(columns = rem_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_test)\n",
    "    #得た結果の樹形図を表示する\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    \n",
    "    #検証に使った説明変数データのダミー変数を元に戻す\n",
    "    df_res = X_test_excel \n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'企画ペース']= kikaku\n",
    "    df_res.loc[:,'科目']= kamoku\n",
    "    df_res.loc[:,'誤差']= df_res['AI想定ペース']-df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI想定ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の差分を列に追加 \n",
    "            \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24250a9-ed53-4c15-b7cc-95fb9b10f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_leaf1(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    rem_cols= [\"科目\",\"分野1\",\"分野2\",\"分野2TS\"]\n",
    "    X_train = X_train.drop(columns = rem_cols)\n",
    "    X_test = X_test.drop(columns = rem_cols)\n",
    "    X_train_feature_names = X_train.columns.values.tolist() \n",
    "  \n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=None, \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "                                feature_names= X_train_feature_names,\n",
    "                                # class_names=iris.target_names,\n",
    "                                filled=True, rounded=True, special_characters=True\n",
    "                               ) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04731d-161c-47f6-93b4-48e3fe78f334",
   "metadata": {},
   "source": [
    "# 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33028f8a-78bc-4c5f-8e4f-df8639377bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "78\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:27\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "94\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:12\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "104\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:2\n",
      "mergeのオブザベーション:106\n"
     ]
    }
   ],
   "source": [
    "df=te_20to21_math_2nenbunya(df_raw)\n",
    "df_v = test_model1_2(df)\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','誤差','AI乖離度','元の乖離度']\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,select_cols])[0]\n",
    "name_excel_output = \"2年生か否か分野別ペース_20target_21機械学習_分野1TS.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)\n",
    "\n",
    "fig = make_leaf1(df)\n",
    "\n",
    "name_file = \"2年生か否か分野別ペース_20target_21機械学習_分野1TS\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "fig.render(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade84fb0-b5be-4574-ba79-3f069b75ee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "74\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:32\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "92\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:14\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "103\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:3\n",
      "mergeのオブザベーション:106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/s.ogura/Documents/CRLEA/data/output/学年分野別ペース_20target_21機械学習_分野1TS_2学年か否か.pdf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=te_20to21_math_2nenbunya_gakunenbunya(df_raw)\n",
    "df_v = test_model1_2(df)\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','誤差','AI乖離度','元の乖離度']\n",
    "df_sum = pandas_tool.summary(df_v.loc[:,select_cols])[0]\n",
    "name_excel_output = \"学年分野別ペース_20target_21機械学習_分野1TS_2学年か否か.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df_v.to_excel(writer, sheet_name='value',encoding='utf-8-sig', index = False)\n",
    "    df_sum.to_excel(writer, sheet_name='summary',encoding='utf-8-sig', index = True)\n",
    "\n",
    "fig = make_leaf1(df)\n",
    "\n",
    "name_file = \"学年分野別ペース_20target_21機械学習_分野1TS_2学年か否か\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "fig.render(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1d7814c8-10fe-4a73-b9d1-507393f3561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "227\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:253\n",
      "df2のオブザベーション:26\n",
      "mergeのオブザベーション:253\n",
      "df1のキー重複\n",
      "237\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:253\n",
      "df2のオブザベーション:16\n",
      "mergeのオブザベーション:253\n",
      "df1のキー重複\n",
      "90\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:16\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "100\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:6\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "74\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:32\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "92\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:14\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "103\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:3\n",
      "mergeのオブザベーション:106\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し\n",
    "\"\"\"\n",
    "\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','誤差','AI乖離度','元の乖離度']\n",
    "df1=te_20to21(df_raw)\n",
    "df2=te_20to21_math(df_raw)\n",
    "df3=te_20to21_math_gakunenbunya(df_raw)\n",
    "\n",
    "#\n",
    "df1_v_1 = test_model1(df1)\n",
    "df1_sum_1 = pandas_tool.summary(df1_v_1.loc[:,select_cols])[0]\n",
    "df1_v_2 = test_model2(df1)\n",
    "df1_sum_2 = pandas_tool.summary(df1_v_2.loc[:,select_cols])[0]\n",
    "\n",
    "#\n",
    "df2_v_1m = test_model1(df2)\n",
    "df2_sum_1m = pandas_tool.summary(df2_v_1m.loc[:,select_cols])[0]\n",
    "df2_v_2m = test_model2(df2)\n",
    "df2_sum_2m = pandas_tool.summary(df2_v_2m.loc[:,select_cols])[0]\n",
    "\n",
    "#分野1の特徴量として、20年の最終ペースの学年分野別平均値を21年の学習、検証データに代入。数学科目のみ入力\n",
    "df3_v_1m = test_model1(df3)\n",
    "df3_sum_1m = pandas_tool.summary(df3_v_1m.loc[:,select_cols])[0]\n",
    "df3_v_2m = test_model2(df3)\n",
    "df3_sum_2m = pandas_tool.summary(df3_v_2m.loc[:,select_cols])[0]\n",
    "\n",
    "\n",
    "name_excel_output = \"分野別ペース_20target_21機械学習_分野TS_v2.xlsx\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#Excelが置いてあるフォルダパス\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}'.format(path_folder,name_excel_output)) as writer:\n",
    "    df1_v_1.to_excel(writer, sheet_name='value_1TS',encoding='utf-8-sig', index = False)\n",
    "    df1_sum_1.to_excel(writer, sheet_name='summary_1TS',encoding='utf-8-sig', index = True)\n",
    "    df1_v_2.to_excel(writer, sheet_name='value_2TS',encoding='utf-8-sig', index = False)\n",
    "    df1_sum_2.to_excel(writer, sheet_name='summary_2TS',encoding='utf-8-sig', index = True)\n",
    "    df2_v_1m.to_excel(writer, sheet_name='value_1TS_math',encoding='utf-8-sig', index = False)\n",
    "    df2_sum_1m.to_excel(writer, sheet_name='summary_1TS_math',encoding='utf-8-sig', index = True)\n",
    "    df2_v_2m.to_excel(writer, sheet_name='value_2TS_math',encoding='utf-8-sig', index = False)\n",
    "    df2_sum_2m.to_excel(writer, sheet_name='summary_2TS_math',encoding='utf-8-sig', index = True)\n",
    "    df3_v_1m.to_excel(writer, sheet_name='value_1m_学年分野',encoding='utf-8-sig', index = False)\n",
    "    df3_sum_1m.to_excel(writer, sheet_name='summary_1m_学年分野',encoding='utf-8-sig', index = True)\n",
    "    df3_v_2m.to_excel(writer, sheet_name='value_2m_学年分野',encoding='utf-8-sig', index = False)\n",
    "    df3_sum_2m.to_excel(writer, sheet_name='summary_2m_学年分野',encoding='utf-8-sig', index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9f3db2d-0f8a-4398-b3a3-083f0c8c98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "74\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:32\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "92\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:14\n",
      "mergeのオブザベーション:106\n",
      "df1のキー重複\n",
      "103\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:106\n",
      "df2のオブザベーション:3\n",
      "mergeのオブザベーション:106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/s.ogura/Documents/CRLEA/data/output/分野別ペース_20gakunentarget_21機械学習_分野1TS_math.pdf'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = te_20to21_math_gakunenbunya(df_raw)\n",
    "fig = make_leaf1(df)\n",
    "\n",
    "name_file = \"分野別ペース_20gakunentarget_21機械学習_分野1TS_math\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "fig.render(path_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
