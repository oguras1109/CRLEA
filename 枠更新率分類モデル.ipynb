{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34299237-834a-4bae-96b9-9cde2f6a019f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "2023.1.5作成<br>\n",
    "1. 受領データ（21、22夏）を結合\n",
    "    参考：採点者品質予測_22秋後半納品_前処理_1025_v1.ipynb\n",
    "2. 参加回数を修正\n",
    "3. 欠損値を削除\n",
    "4. 枠更新率を閾値（0.99）で01にしたフラグ追加\n",
    "\n",
    "### DecisionTreeRegressorの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "\n",
    "### DecisionTreeClassifierの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "### GradientBoostingRegressorの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "### GradientBoostingClassifierの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "### 混合行列（confusion matrix）\n",
    "URL https://note.nkmk.me/python-sklearn-confusion-matrix-score/<br>\n",
    "公式 https://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap<br>\n",
    "seaborn https://evaluelog.com/post-122/#i-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d27ed-a92d-4eae-bd55-a983cd465604",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ライブラリ追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "62e779c9-55b0-4ae8-a14c-001773a492bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "# import seaborn as sns\n",
    "# import re \n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report #2値分類評価指標を出力\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "from sklearn.tree import DecisionTreeClassifier #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fb326f-45eb-4113-9a0b-957dbb183c7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79dae9-dcd8-4ed1-99f1-fe1de7b245b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# データマートの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4dc705-5d5b-431c-a2dc-95b51183e747",
   "metadata": {},
   "source": [
    "## 受領データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43cf84cd-ccc1-467a-81fd-10a04cae1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (13,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#過去データ読み込み \n",
    "\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#データが置いてあるフォルダパス\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "name_csv = \"採点者情報0720+0818_pretreated_v2_jpn.csv\" #ファイル名\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "df_jpn = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "name_csv = \"採点者情報0720+0818_pretreated_v2_math.csv\" #ファイル名\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "df_math = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")\n",
    "\n",
    "# csvファイルの読み込みと空のリストに追加\n",
    "name_csv = \"採点者情報0720+0818_pretreated_v2_eng.csv\" #ファイル名\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_csv)#ファイルパスとファイル名\n",
    "df_eng = pd.read_csv(filepath_or_buffer = path_file, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befd047f-a63e-490a-83ad-e0045b0eebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設問情報を加えない、全科目の結合df\n",
    "collist=['スタッフコード', '年度', '採点回','学年', '科目','分野','割当', '身分', '年齢','大学',\n",
    "       '学部', '登録試験点数','採否時登録時間','依頼枚数', '参加回数', '等級','最終シール',  '完全一致率','偏差値','枠更新率']\n",
    "df1=df_jpn[collist]\n",
    "df2=df_math[collist]\n",
    "df3=df_eng[collist]\n",
    "df_raw =[]\n",
    "df_raw = df1.append(df2)\n",
    "df_raw = df_raw.append(df3)\n",
    "\n",
    "#等級を除外するなどの処理を行う関数を実行\n",
    "def rem_tokyu(df_input):\n",
    "    df = df_input.copy()\n",
    "    #等級を選別する。\n",
    "    colname='等級'\n",
    "    df[colname] = df[colname].astype(str)\n",
    "    df = df[df[colname].isin([\"1\",\"2\",'01','02'])]\n",
    "    #等級の列を除外する\n",
    "    df = df.drop(columns = colname)\n",
    "    return df\n",
    "df_raw = rem_tokyu(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd25700-6af2-4e91-8091-f87756ff8c8e",
   "metadata": {},
   "source": [
    "## データクレンジング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bf914-2396-4ab0-862f-94d6de20b91e",
   "metadata": {},
   "source": [
    "### 偏差値更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200c77e7-182e-46e6-967e-b111e3499d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#偏差値更新\n",
    "\n",
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/rawdata/CRLEA採点者情報入力様式_v1.1_大学追加_秋後半.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df = []\n",
    "df = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=None,usecols=['大学', '学部', '偏差値'])#headerを修正\n",
    "df = df.rename(columns = {'過去参加回数':'参加回数'})\n",
    "df_hensa = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b03f1ce-f28a-4bca-b0fb-fed3ab37bcf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "20317\n",
      "df2のキー重複\n",
      "104\n",
      "df1のオブザベーション:22296\n",
      "df2のオブザベーション:2837\n",
      "mergeのオブザベーション:22738\n"
     ]
    }
   ],
   "source": [
    "#分野情報を割り当て、採点回、年度をキーにして結合する\n",
    "df1 = df_raw\n",
    "df2 = df_hensa\n",
    "df = pandas_tool.merge(df1,df2, key = ['大学', '学部'],how = 'left')\n",
    "df['偏差値_y'] = df['偏差値_y'].fillna(df['偏差値_x'], inplace=False)\n",
    "df = df.rename(columns = {'偏差値_y':'偏差値'})\n",
    "colname='偏差値'\n",
    "df[colname] = df[colname].replace({'-':np.nan,\n",
    "                                    '空白':np.nan,\n",
    "                                    '短大':np.nan,\n",
    "                                    '不明':np.nan,\n",
    "                                    \"大学不明\":np.nan,\n",
    "                                    '専門':np.nan,\n",
    "                                    'なし':np.nan,\n",
    "                                    '該当なし':np.nan})\n",
    "df[colname] = df[colname].astype(float)\n",
    "df = df.drop(['偏差値_x'], axis=1)\n",
    "df = df.drop_duplicates(keep='last')\n",
    "df_raw_hensa = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c6c827-7c54-4862-b7cf-35abe1ea66b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '割当', '身分', '年齢', '大学',\n",
       "       '学部', '登録試験点数', '採否時登録時間', '依頼枚数', '参加回数', '最終シール', '完全一致率',\n",
       "       '枠更新率', '偏差値'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_hensa.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db88059-e87f-4aa0-bb22-93d7f9b52cc6",
   "metadata": {},
   "source": [
    "### エラー値にフラグ追加する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01597140-e290-4b4d-8343-a5f20fed48a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "表記揺れや異常値の削除などのデータ前処理\n",
    "\"\"\"\n",
    "#naを判定してフラグをつくる関数\n",
    "def make_errorlabel(df_input):\n",
    "    df = df_input.copy()\n",
    "    #枠更新率の例外をnanに変換して0に変換\n",
    "    colname='枠更新率'\n",
    "    df[colname] = df[colname].replace({'-':np.nan,\n",
    "                                    '不参加':np.nan,\n",
    "                                  0:np.nan})\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].astype(float)\n",
    "    \n",
    "    #偏差値の例外をnanに変換して0に変換\n",
    "    colname='偏差値'\n",
    "    df[colname] = df[colname].replace({'-':np.nan,\n",
    "                                    '空白':np.nan,\n",
    "                                    '短大':np.nan,\n",
    "                                    '不明':np.nan,\n",
    "                                    \"大学不明\":np.nan,\n",
    "                                    '専門':np.nan,\n",
    "                                    'なし':np.nan,\n",
    "                                    '該当なし':np.nan})\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].astype(float)\n",
    "\n",
    "    #登録試験点数の例外をnanに変換して0に変換\n",
    "    colname='登録試験点数'\n",
    "    df[colname] = df[colname].replace({999:np.nan,\n",
    "                                  0:np.nan})\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].astype(float)\n",
    "\n",
    "    #完全一致率の例外をnanに変換して0に変換\n",
    "    colname='完全一致率'\n",
    "    df[colname] = df[colname].replace({'-':np.nan,\n",
    "                                   'NG':np.nan,\n",
    "                                   '不参加':np.nan,\n",
    "                                  0:np.nan})\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].astype(float)\n",
    "\n",
    "    #身分の例外をnanに変換して0に変換\n",
    "    colname='身分'\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    # df = df.dropna(subset=[colname])\n",
    "    \n",
    "    #例外を1と判定\n",
    "    w = '枠更新率'\n",
    "    x = \"登録試験点数\"\n",
    "    y = \"偏差値\"\n",
    "    z = \"完全一致率\"\n",
    "    zz= \"身分\"\n",
    "    conditions = [\n",
    "        (df[w] == 0),\n",
    "        (df[x] == 0),\n",
    "        (df[y] == 0),\n",
    "        (df[z] == 0),\n",
    "        (df[zz] == 0)\n",
    "         ]\n",
    "    choices = [1, 1, 1, 1, 1]\n",
    "    df.loc[:,'Error'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "    #科目の例外をnanに変換して0に変換\n",
    "    colname='科目'\n",
    "    df[colname] = df[colname].replace({'数学X/A\\u3000':'数学X/A'})\n",
    "    # df[colname] = df[colname].fillna(0)\n",
    "    df = df.dropna(subset=[colname])\n",
    "    \n",
    "    #データ型の変換\n",
    "    colname='学年'\n",
    "    df[colname] = df[colname].astype(float)\n",
    "    colname='採否時登録時間'\n",
    "    df[colname] = df[colname].astype(float)\n",
    "    colname='依頼枚数'\n",
    "    df[colname] = df[colname].replace({'-':np.nan,\n",
    "                                       0:np.nan})\n",
    "    df[colname] = df[colname].fillna(0)\n",
    "    df[colname] = df[colname].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07593e47-ea7d-4cfe-a9c8-bfdf984a6a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5982', '8591', '8711', ..., '3221', '9221', '3593'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_hensa['依頼枚数'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739a6e3-a1a6-4b40-a7dc-890f1e924fc3",
   "metadata": {},
   "source": [
    "### 枠更新率分類関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8ca69d-1f9f-4904-949e-d047adc2e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#枠更新率分類ラベル 閾値以下が1、閾値以上が0\n",
    "def make_wakulabel(df_input, threshold = float):\n",
    "    df = df_input.copy()\n",
    "    x = \"枠更新率\"\n",
    "    conditions = [\n",
    "        df[x] < threshold]\n",
    "    choices = [1]\n",
    "    df.loc[:,'waku'] = np.select(conditions, choices, default = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d78d0-f626-4bdf-9dbd-fa3e063c82d6",
   "metadata": {},
   "source": [
    "### 学習データ、検証データのフラグ作成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c389d7-6076-4782-b56e-5cd84f9f767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test,predのデータ分類ラベル\n",
    "def make_datalabel(df_input):\n",
    "    df = df_input.copy()\n",
    "    #x = \"偏差値\"\n",
    "    conditions = [\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '夏'),\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '冬')]#予測用。修正箇所\n",
    "    choices = [1,2]\n",
    "    df.loc[:,'data'] = np.select(conditions, choices, default = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77085d49-ab72-46a4-b646-8dfb556d3807",
   "metadata": {},
   "source": [
    "### 参加回数の修正関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83370ede-5548-483b-9b32-64e389c9b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_sanka(df_input):\n",
    "    \"\"\"\n",
    "    同一採点者を取得\n",
    "    map関数で、年度、採点回、学年を基準にして番号を振る\n",
    "    例：\n",
    "    2022、秋、3年　202233\n",
    "    2022、秋、2年 202232\n",
    "    番号順に降順で並びかえる\n",
    "    参加回数が記入されている、最も古いレコードの参加回数を取得\n",
    "    それ以外のレコードに番号をふる\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df = df.dropna(subset=['参加回数'])\n",
    "    df['学年'] = df['学年'].fillna(0)\n",
    "    temp=[]\n",
    "    s = list(sorted(df['スタッフコード'].unique().astype(int)))#スタッフコード単位で繰り返す\n",
    "    for i in s:\n",
    "        df1 = df[df['スタッフコード']==i]\n",
    "        x = \"採点回\"\n",
    "        y = \"学年\"\n",
    "        conditions = [\n",
    "            (df1[x] == '春'),\n",
    "            (df1[x] == '夏'),\n",
    "            (df1[x] == '秋'),\n",
    "            (df1[x] == '冬')]\n",
    "        choices = ['1','2','3','4']\n",
    "        df1.loc[:,'採点回_no'] = np.select(conditions, choices, default = 0)\n",
    "        conditions = [\n",
    "            (df1[y] == 1),\n",
    "            (df1[y] == 2),\n",
    "            (df1[y] == 3)]\n",
    "        choices = ['2','2','1']#秋は前半後半があるため\n",
    "        df1.loc[:,'学年_no'] = np.select(conditions, choices, default = 0)\n",
    "        df1 = df1.astype({'年度': 'str', '学年': 'str'})\n",
    "        df1['No'] = df1['年度'] + df1['採点回_no'] + df1['学年_no']\n",
    "        df1 = df1.astype({'No': 'float'})\n",
    "        df1 = df1.sort_values('No', ascending=True)#番号を使って古いものを上に並びかえる\n",
    "        df1['No']= range(0, len(df1))#同一スタッフコードの人の、完全一致率をもつレコードに連番をふる\n",
    "        temp_no = df1.iat[0, 14]#同一スタッフコードの参加回数の一番古い値を代入。列の番号でハードコーディングしてあるため、列が増減するとここを修正\n",
    "        df1['参加回数_修正']= temp_no + df1['No']\n",
    "        df1 = df1.rename(columns = {'参加回数':'参加回数_修正前',\n",
    "                               '参加回数_修正':'参加回数'})\n",
    "        temp.append(df1)\n",
    "    dfs = temp[0] #集計結果を一つのDFに結合\n",
    "    for i in temp[1:]:\n",
    "        dfs = dfs.append(i)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402762fd-2623-427d-9f02-fcab1539aff3",
   "metadata": {},
   "source": [
    "### 列選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a45e4a5-209b-4ec7-b43e-85765c678412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df_input):\n",
    "    df = df_input.copy()\n",
    "    collist=['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '割当', '身分', '年齢', '大学',\n",
    "           '学部', '偏差値','採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '参加回数_修正前', '完全一致率','枠更新率', 'Error','data','waku']\n",
    "    df = df[collist]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fecc5-ba8b-4dd2-8830-0164e63ed813",
   "metadata": {},
   "source": [
    "### 重複削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "326c5c8b-8b0d-4e32-a76b-2bc2b7d15f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test,predのデータ分類ラベル\n",
    "def rem_dup(df_input):\n",
    "    df = df_input.copy()\n",
    "    df = df.drop_duplicates(keep='last')\n",
    "    # df = df.drop_duplicates(subset=['スタッフコード', '参加回数'],keep='last')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc009ad-1657-4f22-b547-423153304a28",
   "metadata": {},
   "source": [
    "### エラーフラグ、参加回数修正、枠更新率フラグ、データフラグ追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d816127c-e77e-49d0-bf98-3db16a9026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_def(df_input):\n",
    "    df = df_input.copy()\n",
    "    df = rem_dup(df)\n",
    "    df = make_errorlabel(df)\n",
    "    df = make_wakulabel(df,0.99)\n",
    "    df = make_datalabel(df)\n",
    "    df = revise_sanka(df)\n",
    "    df = select_columns(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c04e4673-a415-4691-8128-713530808db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pret = apply_def(df_raw_hensa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3cf1807-dbb6-47ae-95c1-6ddded8d5b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '割当', '身分', '年齢', '大学',\n",
       "       '学部', '偏差値', '採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '参加回数_修正前',\n",
       "       '完全一致率', '枠更新率', 'Error', 'data', 'waku'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pret.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5893d35f-f28d-455a-a3cb-74680fe2619a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>スタッフコード</th>\n",
       "      <th>年度</th>\n",
       "      <th>採点回</th>\n",
       "      <th>学年</th>\n",
       "      <th>科目</th>\n",
       "      <th>分野</th>\n",
       "      <th>割当</th>\n",
       "      <th>身分</th>\n",
       "      <th>年齢</th>\n",
       "      <th>大学</th>\n",
       "      <th>...</th>\n",
       "      <th>採否時登録時間</th>\n",
       "      <th>依頼枚数</th>\n",
       "      <th>登録試験点数</th>\n",
       "      <th>参加回数</th>\n",
       "      <th>参加回数_修正前</th>\n",
       "      <th>完全一致率</th>\n",
       "      <th>枠更新率</th>\n",
       "      <th>Error</th>\n",
       "      <th>data</th>\n",
       "      <th>waku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1050015912</td>\n",
       "      <td>2021</td>\n",
       "      <td>夏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>01</td>\n",
       "      <td>社会人</td>\n",
       "      <td>58.0</td>\n",
       "      <td>東北大学医療技術短期大学部</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>7115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.018412</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1050015912</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>3.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>01</td>\n",
       "      <td>社会人</td>\n",
       "      <td>58.0</td>\n",
       "      <td>東北大学医療技術短期大学部</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.007493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>1050015912</td>\n",
       "      <td>2022</td>\n",
       "      <td>夏</td>\n",
       "      <td>2.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>01</td>\n",
       "      <td>社会人</td>\n",
       "      <td>58.0</td>\n",
       "      <td>東北大学医療技術短期大学部</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9865.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.610745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1050727415</td>\n",
       "      <td>2021</td>\n",
       "      <td>夏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>01</td>\n",
       "      <td>社会人</td>\n",
       "      <td>59.0</td>\n",
       "      <td>聖心女子大学</td>\n",
       "      <td>...</td>\n",
       "      <td>80.5</td>\n",
       "      <td>7623.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>1050740209</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>3.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>01</td>\n",
       "      <td>社会人</td>\n",
       "      <td>35.0</td>\n",
       "      <td>上智大学</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.006926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         スタッフコード    年度 採点回   学年  科目  分野  割当   身分    年齢             大学  ...  \\\n",
       "61    1050015912  2021   夏  1.0  国語  評論  01  社会人  58.0  東北大学医療技術短期大学部  ...   \n",
       "1589  1050015912  2021   秋  3.0  国語  評論  01  社会人  58.0  東北大学医療技術短期大学部  ...   \n",
       "6032  1050015912  2022   夏  2.0  国語  評論  01  社会人  58.0  東北大学医療技術短期大学部  ...   \n",
       "7     1050727415  2021   夏  1.0  国語  評論  01  社会人  59.0         聖心女子大学  ...   \n",
       "2231  1050740209  2021   秋  3.0  国語  評論  01  社会人  35.0           上智大学  ...   \n",
       "\n",
       "     採否時登録時間    依頼枚数  登録試験点数  参加回数  参加回数_修正前     完全一致率      枠更新率  Error  data  \\\n",
       "61      77.0  7115.0    70.0   9.0       9.0  0.000000  1.018412      1     0   \n",
       "1589    40.0  2936.0    70.0  10.0      10.0  1.000000  1.007493      1     0   \n",
       "6032    60.0  9865.0    70.0  11.0      11.0  0.994012  0.610745      1     1   \n",
       "7       80.5  7623.0    27.0  13.0      13.0  0.000000  1.024400      1     0   \n",
       "2231    40.0  3754.0    79.0  20.0      20.0  0.965517  1.006926      0     0   \n",
       "\n",
       "      waku  \n",
       "61       0  \n",
       "1589     0  \n",
       "6032     1  \n",
       "7        0  \n",
       "2231     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96177f4f-63e0-4d9f-85dc-a3571984c878",
   "metadata": {},
   "source": [
    "## データマート出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c832a8bf-8487-4884-abb6-d1dc05276b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pathの設定 \n",
    "\"\"\"\n",
    "#ファイル名\n",
    "name = \"枠更新率分類モデル_21~22夏_v1\"\n",
    "#保存先フォルダ\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/intermediatedata\"#フォルダパス\n",
    "#保存するパス\n",
    "path_file = '{}/{}_datamart.xlsx'.format(path_folder,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b486f07e-79ed-4912-ab48-c908dd207293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "df = df_pret\n",
    "#Excel\n",
    "with pd.ExcelWriter(path_file) as writer:\n",
    "    df.to_excel(writer, sheet_name='data',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565b540-3e2e-488d-88b6-a74a15d834be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 機械学習モデル予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f64ab8-4986-4577-a352-2ea2703035f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データマート読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c6d365-2a9a-47bd-9393-6b27271451e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#整形済みデータの読み込み \n",
    "# path_name = \"/Users/s.ogura/Documents/CRLEA/data/intermediatedata/採点者品質予測_22冬納品_整形済み学習データ_参加回数修正済み_v1.xlsx\"\n",
    "# path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "\n",
    "df = []\n",
    "df = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=None,\n",
    "                   usecols=['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '割当', '身分', '年齢', '大学',\n",
    "       '学部', '偏差値', '採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '参加回数_修正前',\n",
    "       '完全一致率', '枠更新率', 'Error', 'data', 'waku'])#\n",
    "df_datamart = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406a4c6-874d-49fc-9944-6ea97d597777",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83601223-bd06-42b9-aeab-6bca4ad168ec",
   "metadata": {},
   "source": [
    "### データマートからエラー値の削除および不要な列の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3984b48-da00-4231-9df8-85e8788536d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '割当', '身分', '年齢', '大学',\n",
       "       '学部', '偏差値', '採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '参加回数_修正前',\n",
       "       '完全一致率', '枠更新率', 'Error', 'data', 'waku'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datamart.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e23198-cf21-4296-8256-b37607e0de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_error(df_input):\n",
    "    df = df_input.copy()\n",
    "    colname='Error'\n",
    "    df = df[df[colname]==0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc6b02b-d392-435b-9bb3-fadf72e1be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_datamart(df_input):\n",
    "    df = df_input.copy()\n",
    "    collist=['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '身分', '年齢',\n",
    "           '偏差値','採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '完全一致率','枠更新率', 'data','waku']\n",
    "    df = df[collist]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "960036bb-64ea-49fd-aac6-bfb7e41a254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pret_data_renshu(df_input):#経験者だが、過去データに前回のデータがない採点者\n",
    "    \"\"\"\n",
    "    経験者だが、過去データに前回のデータがない採点者を抽出\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df = df.loc[:,['学年', '科目', '分野', '身分', '年齢', '偏差値', '採否時登録時間',\n",
    "       '依頼枚数', '登録試験点数', '参加回数', 'data', 'waku']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "295e2e6b-9f64-4f99-8dbb-f9bf2757d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pret_data_shinjin(df_input):#修正\n",
    "    \"\"\"\n",
    "    新人のデータだけ抽出\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df = df[df['参加回数']==0] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da4e7c1d-f5b7-491b-b916-bbc08a7959c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pret_data_keiken(df_input):\n",
    "    \"\"\"\n",
    "    同一採点者を取得\n",
    "    完全一致率の欠けているレコードを削除\n",
    "    一つ前の参加回数に、今回の参加回数を結合\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    temp=[]\n",
    "    s = list(sorted(df['スタッフコード'].unique().astype(int)))#スタッフコード単位で繰り返す\n",
    "    for h in s:\n",
    "        df1 = df[df['スタッフコード']==h]\n",
    "        df1 = df1.sort_values('参加回数', ascending=True)#参加回数で並びかえる\n",
    "        df1['No']= range(1, len(df1) + 1)#同一スタッフコードの人の、完全一致率をもつレコードに連番をふる\n",
    "    \n",
    "        n = list(sorted(df1['No'].unique().astype(int)))#スタッフコードの連番をリストにしている\n",
    "    \n",
    "        for i in n:\n",
    "            #前回のレコード\n",
    "            df2 = df1.loc[:,['スタッフコード','参加回数','分野','完全一致率','枠更新率','No']]\n",
    "            df2 = df2[df2['No']== i]\n",
    "            df2 = df2.rename(columns = {'参加回数':'前回の参加回数',\n",
    "                                    '分野':'前回の分野',\n",
    "                                    '完全一致率':'前回の完全一致率',\n",
    "                                    '枠更新率':'前回の枠更新率'})\n",
    "            df2['前回の参加回数'] = df2['前回の参加回数'].astype(int)\n",
    "            df2 = df2.drop(columns = 'No')\n",
    "            \n",
    "            #今回のレコード        \n",
    "            df3 = df1\n",
    "            df3 = df3[df3['No']== (i+1)]\n",
    "            df3 = df3.rename(columns = {'参加回数':'今回の参加回数',\n",
    "                                    '分野':'今回の分野',                                    \n",
    "                                    '採点回':'今回の採点回',\n",
    "                                    '年度':'今回の年度',\n",
    "                                    '完全一致率':'今回の完全一致率',\n",
    "                                    '枠更新率':'今回の枠更新率'})\n",
    "            df3['今回の参加回数'] = df3['今回の参加回数'].astype(int)\n",
    "            df3 = df3.drop(columns = 'No')\n",
    "        \n",
    "            ret = pd.merge(df2,df3,on = 'スタッフコード',how = 'inner')\n",
    "            temp.append(ret)\n",
    "    dfs = temp[0] #集計結果を一つのDFに結合\n",
    "    for i in temp[1:]:\n",
    "        dfs = dfs.append(i)\n",
    "    dfs = dfs.dropna(subset=['前回の完全一致率','前回の枠更新率'])\n",
    "    #df = []\n",
    "    #df = dfs.drop_duplicates()\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cf7aaf5-f1bf-4759-9491-fe1e96d1d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pret_data_etc(df_input):#経験者だが、過去データに前回のデータがない採点者\n",
    "    \"\"\"\n",
    "    経験者だが、過去データに前回のデータがない採点者を抽出\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    #スタッフコードの重複があるデータを全て削除。つまり参照する過去データが無い人。\n",
    "    df = df.drop_duplicates(subset='スタッフコード',keep=False)\n",
    "    #新人データを削除\n",
    "    df = df[~(df['参加回数']==0)] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91f05203-189a-40b6-bc2f-7746ab58934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreatment(df_input):\n",
    "    #データマートからエラー値を除いた、前処理する前のデータ\n",
    "    df = df_input.copy()\n",
    "    df = rem_error(df)\n",
    "    df = select_columns_datamart(df)\n",
    "    \n",
    "    #機械学習に使うデータ_新人用\n",
    "    df_shinjin = pret_data_shinjin(df)\n",
    "    #機械学習に使うデータ_経験者用\n",
    "    df_keiken = pret_data_keiken(df)\n",
    "    #機械学習に使うデータ_経験者だが過去データがない\n",
    "    df_etc = pret_data_etc(df)\n",
    "    \n",
    "    df_res = [df, df_shinjin, df_keiken, df_etc]\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28506d-9af4-43d3-88f5-d1bba08b298b",
   "metadata": {},
   "source": [
    "### 前処理済みデータの出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3206bd58-2ec7-4f8b-a785-b7a8ff1c5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.23644971847534\n"
     ]
    }
   ],
   "source": [
    "# 時間計測開始\n",
    "time_sta = time.time()\n",
    "\n",
    "# 処理開始\n",
    "\n",
    "df = df_datamart\n",
    "\n",
    "df_prets = pretreatment(df)\n",
    "\n",
    "# 時間計測終了\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "print(time_end- time_sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94c740a6-7c3e-4d9a-920c-ce34ca37aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データマートのN数:18952\n",
      "エラー値を除いたN数:12535\n",
      "エラー値を除いたN数_新人:3108\n",
      "エラー値を除いたN数_経験者:5863\n",
      "エラー値を除いたN数_過去データのない経験者:1291\n",
      "エラー値を除いたN数_合計:10262\n"
     ]
    }
   ],
   "source": [
    "#N数を確認\n",
    "df = df_prets\n",
    "print('データマートのN数:{}'.format(len(df_datamart)))\n",
    "print('エラー値を除いたN数:{}'.format(len(df[0])))\n",
    "print('エラー値を除いたN数_新人:{}'.format(len(df[1])))\n",
    "print('エラー値を除いたN数_経験者:{}'.format(len(df[2])))\n",
    "print('エラー値を除いたN数_過去データのない経験者:{}'.format(len(df[3])))\n",
    "print('エラー値を除いたN数_合計:{}'.format(len(df[1])+len(df[2])+len(df[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9423dd1c-35c4-41db-b935-8d9f22215a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>スタッフコード</th>\n",
       "      <th>年度</th>\n",
       "      <th>採点回</th>\n",
       "      <th>学年</th>\n",
       "      <th>科目</th>\n",
       "      <th>分野</th>\n",
       "      <th>身分</th>\n",
       "      <th>年齢</th>\n",
       "      <th>偏差値</th>\n",
       "      <th>採否時登録時間</th>\n",
       "      <th>依頼枚数</th>\n",
       "      <th>登録試験点数</th>\n",
       "      <th>参加回数</th>\n",
       "      <th>完全一致率</th>\n",
       "      <th>枠更新率</th>\n",
       "      <th>data</th>\n",
       "      <th>waku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1050740209</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>3.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>社会人</td>\n",
       "      <td>35.0</td>\n",
       "      <td>69.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3754</td>\n",
       "      <td>79</td>\n",
       "      <td>20</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.006926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1050740209</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>2.0</td>\n",
       "      <td>国語</td>\n",
       "      <td>評論</td>\n",
       "      <td>社会人</td>\n",
       "      <td>35.0</td>\n",
       "      <td>69.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11029</td>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.672296</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1050742436</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>3.0</td>\n",
       "      <td>英語</td>\n",
       "      <td>内容説明</td>\n",
       "      <td>社会人</td>\n",
       "      <td>53.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>40.5</td>\n",
       "      <td>3582</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.856226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1050742436</td>\n",
       "      <td>2021</td>\n",
       "      <td>秋</td>\n",
       "      <td>2.0</td>\n",
       "      <td>英語</td>\n",
       "      <td>英作文</td>\n",
       "      <td>社会人</td>\n",
       "      <td>53.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6770</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>1.010294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1060247639</td>\n",
       "      <td>2021</td>\n",
       "      <td>夏</td>\n",
       "      <td>2.0</td>\n",
       "      <td>英語</td>\n",
       "      <td>英作文</td>\n",
       "      <td>社会人</td>\n",
       "      <td>27.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9185</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>1.013609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       スタッフコード    年度 採点回   学年  科目    分野   身分    年齢   偏差値  採否時登録時間   依頼枚数  \\\n",
       "4   1050740209  2021   秋  3.0  国語    評論  社会人  35.0  69.6     40.0   3754   \n",
       "5   1050740209  2021   秋  2.0  国語    評論  社会人  35.0  69.6     85.0  11029   \n",
       "7   1050742436  2021   秋  3.0  英語  内容説明  社会人  53.0  59.6     40.5   3582   \n",
       "8   1050742436  2021   秋  2.0  英語   英作文  社会人  53.0  59.6     85.0   6770   \n",
       "16  1060247639  2021   夏  2.0  英語   英作文  社会人  27.0  57.1     82.0   9185   \n",
       "\n",
       "    登録試験点数  参加回数     完全一致率      枠更新率  data  waku  \n",
       "4       79    20  0.965517  1.006926     0     0  \n",
       "5       79    21  0.985714  0.672296     0     1  \n",
       "7       60    16  0.708861  0.856226     0     1  \n",
       "8       60    17  0.793651  1.010294     0     0  \n",
       "16      54     2  0.912409  1.013609     0     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d7cfb7-f0eb-4471-b359-a31a6506b261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '身分', '年齢', '偏差値', '採否時登録時間',\n",
       "       '依頼枚数', '登録試験点数', '参加回数', '完全一致率', '枠更新率', 'data', 'waku'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prets[0].columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a711da-70c0-4c0f-9ca0-1952837a3afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12535 0 0\n"
     ]
    }
   ],
   "source": [
    "#0が無いか確認\n",
    "df = df_prets[0]\n",
    "print(len(df),len(df[df['枠更新率']==0]),len(df[df['完全一致率']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "784322d5-03b0-4b84-93b5-e7aa8782ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "csvの書き出し\n",
    "\"\"\"\n",
    "df = df_prets[0]\n",
    "\n",
    "name = \"枠更新率分析モデルDM_v1\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "#csv\n",
    "df.to_csv('{}/{}.csv'.format(path_folder,\"{}\".format(name)),encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9584eaf-1f60-409d-8839-d49a342990dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## モデル編集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435f1d2-306d-412f-b044-adc9ba13542b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2bfb-b692-492c-98f5-3bd6d7379141",
   "metadata": {
    "tags": []
   },
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5fe42-7bab-4ad1-98a0-64e091eedf53",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifierの概要\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3902c15-fc4f-4f1c-b8b8-f5226c0ff729",
   "metadata": {
    "tags": []
   },
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘gini’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb3f19-6d38-4b96-aa82-8702967ed816",
   "metadata": {
    "tags": []
   },
   "source": [
    "### モデル訓練用にデータを加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "804f342b-d969-4fcb-83f6-41dd13e85bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
    "ダミー変数を元に戻す。エクセル出力用\n",
    "\"\"\"\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aca26f0-ae8a-47b7-ae04-8ed018456444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '年度', '採点回', '学年', '科目', '分野', '身分', '年齢', '偏差値',\n",
       "       '採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '完全一致率', '枠更新率', 'data',\n",
       "       'waku'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#機械学習に使うデータ 新人\n",
    "df_prets[1].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0eb1671e-5c75-4607-aad7-326e9516e92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_shinjin_reg(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    # df_pred = df[df['data']==2].copy()\n",
    "    \n",
    "    rem_value = ['完全一致率', 'waku']\n",
    "    use_y = '枠更新率'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_value)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    # X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    # rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_x = ['スタッフコード', '年度', '採点回', 'data']\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "912f677a-3f67-49e5-9d65-f5ddee4bd489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_shinjin_clf(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    # df_pred = df[df['data']==2].copy()\n",
    "    \n",
    "    rem_value = ['完全一致率', '枠更新率']\n",
    "    use_y = 'waku'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_value)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    # X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    # rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_x = ['スタッフコード', '年度', '採点回', 'data']\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a326952f-81ea-4ecb-8f49-925f3fc19d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_shinjin_clf2(df_input):#科目、分野を変数から除外\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    # df_pred = df[df['data']==2].copy()\n",
    "    \n",
    "    rem_value = ['完全一致率', '枠更新率','科目','分野']\n",
    "    use_y = 'waku'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_value)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    # X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    # rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_x = ['スタッフコード', '年度', '採点回', 'data']\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a20c389a-77bf-488f-a947-d90fb6bbabaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['スタッフコード', '前回の参加回数', '前回の分野', '前回の完全一致率', '前回の枠更新率', '今回の年度',\n",
       "       '今回の採点回', '学年', '科目', '今回の分野', '身分', '年齢', '偏差値', '採否時登録時間',\n",
       "       '依頼枚数', '登録試験点数', '今回の参加回数', '今回の完全一致率', '今回の枠更新率', 'data', 'waku'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#機械学習に使うデータ　経験者\n",
    "df_prets[2].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5d44657-feef-4590-aa56-bad74ee51f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_keiken_reg(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df = df.rename(columns = {'今回の採点回':'採点回',#0始まりで数えているため、\n",
    "                             '今回の年度':'年度',\n",
    "                             '今回の参加回数':'参加回数',\n",
    "                             '今回の分野':'分野'})\n",
    "    \n",
    "    rem_val = ['前回の分野','前回の参加回数','今回の完全一致率','waku']\n",
    "    use_y = '今回の枠更新率'#目的変数の設定\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_val)\n",
    "\n",
    "    \"\"\"\n",
    "    df_pred = df[df['data']==2].copy()\n",
    "    \"\"\"\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['data',use_y]]#目的変数と選択用変数だけ含むデータフレーム　#秋に変更するところ\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    \"\"\"\n",
    "    #説明変数\n",
    "    X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \"\"\"\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"data\"]\n",
    "    rem_cols_y = [\"data\"]#秋に変更するところ\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']] #ダミー変数化しているため、これだとエラーになる。\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "58e29d5f-adf8-4eef-aefc-109117807b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_keiken_clf(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    df = df.rename(columns = {'今回の採点回':'採点回',#0始まりで数えているため、\n",
    "                             '今回の年度':'年度',\n",
    "                             '今回の参加回数':'参加回数',\n",
    "                             '今回の分野':'分野'})\n",
    "    \n",
    "    #1.不要な変数を削除\n",
    "    rem_val = ['前回の分野','前回の参加回数','今回の完全一致率','今回の枠更新率']\n",
    "    df = df.drop(columns = rem_val)\n",
    "\n",
    "    \"\"\"\n",
    "    df_pred = df[df['data']==2].copy()\n",
    "    \"\"\"\n",
    "    \n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    use_y = 'waku'#目的変数の設定\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['data',use_y]]#目的変数と選択用変数だけ含むデータフレーム　#秋に変更するところ\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    \"\"\"\n",
    "    #説明変数\n",
    "    X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \"\"\"\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"data\"]\n",
    "    rem_cols_y = [\"data\"]#秋に変更するところ\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']] #ダミー変数化しているため、これだとエラーになる。\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3648fe61-143c-4c98-892d-124103571ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data(df_input):\n",
    "    \n",
    "    \"\"\"\n",
    "    学習,検証,予測データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    # df_pred = df[df['data']==2].copy()\n",
    "    \n",
    "    rem_value = ['完全一致率', '枠更新率']\n",
    "    use_y = 'waku'\n",
    "\n",
    "    #1.不要な変数を削除\n",
    "    df = df.drop(columns = rem_value)\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野','身分'])\n",
    "    \n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = use_y)#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,[use_y,'data']]#目的変数と選択用変数だけ含むデータフレーム　\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[df_X['data']==0]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[df_y['data']==0]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #説明変数\n",
    "    X_test = df_X[df_X['data']==1]\n",
    "    #目的変数\n",
    "    y_test = df_y[df_y['data']==1]\n",
    "\n",
    "    \"\"\"予測用\"\"\"\n",
    "    #説明変数\n",
    "    # X_pred = df_X[df_X['data']==2]#秋に変更するところ\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    # rem_cols_x = [\"スタッフコード\",\"採点回\",\"年度\",\"科目\",\"参加回数\",\"data\"]\n",
    "    rem_cols_x = ['スタッフコード', '年度', '採点回', 'data']\n",
    "    rem_cols_y = [\"data\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_id =X_test.loc[:,['スタッフコード']]\n",
    "    # X_test_kamoku =X_test.loc[:,['科目']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "    # X_pred = X_pred.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku, X_pred, df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_id]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7046f-964c-432d-8228-06e301db1809",
   "metadata": {},
   "source": [
    "### 使用するモデルの選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c9c21b7c-2004-4e35-9aea-e76bf20b21c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　分類の場合 light GBM\n",
    "\"\"\"\n",
    "import lightgbm as lgb\n",
    "def train_model_clf(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators=10000)\n",
    "    # model = lgb.LGBMRegressor(n_estimators=10000)\n",
    "    #各ラウンドでの予測精度などを格納する辞書\n",
    "    evals_result = {}\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "        eval_metric='logloss',\n",
    "        # eval_metric='mse',\n",
    "        early_stopping_rounds=10,\n",
    "        callbacks=[lgb.callback.record_evaluation(evals_result)],\n",
    "        )\n",
    "    \"\"\"\n",
    "    # 予測時には先ほど決めた学習回数を用いる。\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    #これでもできる\n",
    "    y_pred = model.predict(X_test) \n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "eca77b42-3260-408e-a20f-8eb0e1454775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　回帰の場合 light GBM\n",
    "\"\"\"\n",
    "import lightgbm as lgb\n",
    "def train_model_reg(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    \n",
    "    # model = lgb.LGBMClassifier(n_estimators=10000)\n",
    "    model = lgb.LGBMRegressor(n_estimators=10000)\n",
    "    #各ラウンドでの予測精度などを格納する辞書\n",
    "    evals_result = {}\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "        # eval_metric='logloss',\n",
    "        eval_metric='mse',\n",
    "        early_stopping_rounds=10,\n",
    "        callbacks=[lgb.callback.record_evaluation(evals_result)],\n",
    "        )\n",
    "    \"\"\"\n",
    "    # 予測時には先ほど決めた学習回数を用いる。\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    #これでもできる\n",
    "    y_pred = model.predict(X_test) \n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "67a7df1e-5474-46d6-a576-18ca3b7ef4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　分類の場合 勾配ブースティング\n",
    "\"\"\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def train_model_clf(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = GradientBoostingClassifier(random_state=0)\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "675928ce-fc2c-4ae6-a00a-fbe1d60ed9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　回帰の場合 勾配ブースティング\n",
    "\"\"\"\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def train_model_reg(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = GradientBoostingRegressor(random_state=0)\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a062adf5-251a-4347-8979-db12b00e6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　分類の場合 決定木\n",
    "\"\"\"\n",
    "def train_model_clf(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = DecisionTreeClassifier(criterion='gini', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=0,#出力結果の固定のため \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "df24ae33-9f86-405d-8d2f-cd0cb5bbcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成　回帰の場合　決定木\n",
    "\"\"\"\n",
    "def train_model_reg(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=0,#出力結果の固定のため \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "25bd4d9a-7fed-40f4-ba7b-61d68892ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "確信度をndarrayとして取得する関数\n",
    "\"\"\"\n",
    "def get_prob(X_test, model):\n",
    "    probs = model.predict_proba(X_test)\n",
    "    prob_0 = probs[0][0]\n",
    "    size = len(probs)\n",
    "    for i in range(1,size):\n",
    "        prob_0 = np.append(prob_0, probs[i][0])\n",
    "    \n",
    "    prob_1 = probs[0][1]\n",
    "    for i in range(1,size):\n",
    "        prob_1 = np.append(prob_1, probs[i][1])\n",
    "    res = [prob_0, prob_1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9608c8e-6e95-40bc-9316-c298ca16f595",
   "metadata": {},
   "source": [
    "### 出力内容の編集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9ec87eec-71da-4f39-b3ab-30e8967725c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_clf(df,model):# 確信度を追加\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_id = df[4]\n",
    "    # X_test_kamoku = df[5]\n",
    "    y_pred  = model.predict(X_test)\n",
    "    y_pred_probs= get_prob(X_test, model)\n",
    "    prob_0 = y_pred_probs[0]\n",
    "    prob_1 = y_pred_probs[1]\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    \n",
    "    df_test=[]\n",
    "    df_test = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_test.loc[:,'スタッフコード']= X_test_id\n",
    "    # df_test.loc[:,'科目']= X_test_kamoku\n",
    "    df_test.loc[:,'実測値']= y_test\n",
    "    df_test.loc[:,'予測値']= y_pred #上のデータに予測値をマージ\n",
    "    df_test.loc[:,'0の確信度']= prob_0 #上のデータに0の確信度をマージ\n",
    "    df_test.loc[:,'1の確信度']= prob_1 #上のデータに1の確信度をマージ\n",
    "    df_res = df_test #下のコメントアウトを外す時、この行は削除\n",
    "    \"\"\"\n",
    "    #学習データの同じ学年分野カテゴリの中の基礎統計量\n",
    "    df_train = undummify(X_train)\n",
    "    df_train.loc[:,'完全一致率'] = y_train\n",
    "\n",
    "    df_temp = df_train.groupby(['分野','学年'],as_index=False).agg(\n",
    "        学習データ_N数=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"count\"),\n",
    "        学習データ_平均値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"mean\"),\n",
    "        学習データ_中央値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"median\"),\n",
    "        学習データ_最大値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"max\"),\n",
    "        学習データ_最小値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"min\"))\n",
    "    df_res = pd.merge(df_test, df_temp, on=['分野', '学年'], how='left')\n",
    "    \n",
    "    # 実測値_完全一致率をランク分け\n",
    "    x = \"完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'実測一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "\n",
    "        # AI想定完全一致率をランク分け 評価用\n",
    "    x = \"AI想定完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'想定一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "    \"\"\"\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "19d3140e-07f8-4491-945a-d2368cb607cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_clf(df,model):# orijin\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_id = df[4]\n",
    "    # X_test_kamoku = df[5]\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    \n",
    "    df_test=[]\n",
    "    df_test = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_test.loc[:,'スタッフコード']= X_test_id\n",
    "    # df_test.loc[:,'科目']= X_test_kamoku\n",
    "    df_test.loc[:,'実測値']= y_test\n",
    "    df_test.loc[:,'予測値']= y_pred #上のデータに予測値をマージ\n",
    "    df_res = df_test #下のコメントアウトを外す時、この行は削除\n",
    "    \"\"\"\n",
    "    #学習データの同じ学年分野カテゴリの中の基礎統計量\n",
    "    df_train = undummify(X_train)\n",
    "    df_train.loc[:,'完全一致率'] = y_train\n",
    "\n",
    "    df_temp = df_train.groupby(['分野','学年'],as_index=False).agg(\n",
    "        学習データ_N数=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"count\"),\n",
    "        学習データ_平均値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"mean\"),\n",
    "        学習データ_中央値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"median\"),\n",
    "        学習データ_最大値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"max\"),\n",
    "        学習データ_最小値=pd.NamedAgg(column=\"完全一致率\", aggfunc=\"min\"))\n",
    "    df_res = pd.merge(df_test, df_temp, on=['分野', '学年'], how='left')\n",
    "    \n",
    "    # 実測値_完全一致率をランク分け\n",
    "    x = \"完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'実測一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "\n",
    "        # AI想定完全一致率をランク分け 評価用\n",
    "    x = \"AI想定完全一致率\"\n",
    "    conditions = [\n",
    "            (df_res[x] >= 0.95),\n",
    "            (df_res[x] >= 0.7)\n",
    "             ]\n",
    "    choices = [\"0.95~\",\"0.70~0.95\"]\n",
    "    df_res.loc[:,'想定一致率ランク'] = np.select(conditions, choices, default = \"~0.70\")\n",
    "    \"\"\"\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cb83bb2c-9f63-437c-80b7-f4ee6c23259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_reg(df,model):# orijin\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_id = df[4]\n",
    "    # X_test_kamoku = df[5]\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    \n",
    "    df_test=[]\n",
    "    df_test = undummify(X_test)  #企画ペースを入れるためにここをいじった。元はX_test\n",
    "    df_test.loc[:,'スタッフコード']= X_test_id\n",
    "    # df_test.loc[:,'科目']= X_test_kamoku\n",
    "    df_test.loc[:,'実測値']= y_test\n",
    "    df_test.loc[:,'予測値']= y_pred #上のデータに予測値をマージ\n",
    "\n",
    "    #学習データの同じ学年分野カテゴリの中の基礎統計量\n",
    "    df_train = undummify(X_train)\n",
    "    y = '枠更新率'\n",
    "    df_train.loc[:,y] = y_train\n",
    "\n",
    "    df_temp = df_train.groupby(['分野','学年'],as_index=False).agg(\n",
    "        学習データ_N数=pd.NamedAgg(column = y, aggfunc=\"count\"),\n",
    "        学習データ_平均値=pd.NamedAgg(column = y, aggfunc=\"mean\"),\n",
    "        学習データ_中央値=pd.NamedAgg(column = y, aggfunc=\"median\"),\n",
    "        学習データ_最大値=pd.NamedAgg(column = y, aggfunc=\"max\"),\n",
    "        学習データ_最小値=pd.NamedAgg(column = y, aggfunc=\"min\"))\n",
    "    df_res = pd.merge(df_test, df_temp, on=['分野', '学年'], how='left')\n",
    "    \n",
    "    # 実測値_完全一致率をランク分け\n",
    "    x = \"実測値\"\n",
    "    conditions = [\n",
    "            (df_res[x] <= 0.99)\n",
    "             ]\n",
    "    choices = [1]\n",
    "    df_res.loc[:,'実測値ランク'] = np.select(conditions, choices, default = 0)\n",
    "    df_res['実測値ランク'] = df_res['実測値ランク'].astype(int)\n",
    "\n",
    "    # AI想定完全一致率をランク分け 評価用\n",
    "    x = \"予測値\"\n",
    "    conditions = [\n",
    "            (df_res[x] <= 0.99)\n",
    "             ]\n",
    "    choices = [1]\n",
    "    df_res.loc[:,'予測値ランク'] = np.select(conditions, choices, default = 0)\n",
    "    df_res['予測値ランク'] = df_res['予測値ランク'].astype(int)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32a6b70a-7674-442b-bc93-cda3c91b87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(df,model):\n",
    "    \"\"\"\n",
    "    変数の重要度を返す\n",
    "    \"\"\"\n",
    "    X_test = df[2]\n",
    "    feature = model.feature_importances_\n",
    "    label = X_test.columns\n",
    "    indices = np.argsort(feature)\n",
    "\n",
    "    # 特徴量の重要度の棒グラフ\n",
    "    fig =plt.figure (figsize = (10,10))\n",
    "    plt.ion()\n",
    "    plt.barh(range(len(feature)), feature[indices])\n",
    "    plt.yticks(range(len(feature)), label[indices], fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.ylabel(\"Feature\", fontsize=18)\n",
    "    plt.xlabel(\"Feature Importance\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "10c7d867-ab1e-47f6-a5ec-5ce3210a4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用ライブラリ　樹形図作成\n",
    "# from sklearn import tree\n",
    "# import graphviz\n",
    "def make_treegraph(df,model):\n",
    "    \"\"\"\n",
    "    樹形図を作成し、返す\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    X_train_feature_names = X_train.columns.values.tolist()\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "                                    feature_names= X_train_feature_names,\n",
    "                                    # class_names=iris.target_names,\n",
    "                                    filled=True, rounded=True, special_characters=True\n",
    "                                    )\n",
    "    treegraph = graphviz.Source(dot_data) \n",
    "    return treegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1db2660b-6af8-4380-8434-670f1d86823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証用 分類モデル\n",
    "def get_result_test_clf(df_input,case=int):\n",
    "    df = df_input.copy()\n",
    "    df_temp=[]#[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    model = []\n",
    "    pred = []\n",
    "    #新人モデルの結果\n",
    "    if case == 1:\n",
    "        df_temp = make_data_shinjin_clf(df)\n",
    "    #経験者モデルの結果\n",
    "    elif case == 2:\n",
    "        df_temp = make_data_keiken_clf(df)\n",
    "    #テストモデルの結果\n",
    "    elif case == 3:\n",
    "        df_temp = make_data_shinjin_clf2(df)#科目、分野を説明変数から除外\n",
    "    model = train_model_clf(df_temp,a=2,b=1,c=None)\n",
    "    pred = get_test_clf(df_temp, model)\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1d5944ba-9342-4d6e-b192-1453b3e5dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証用　回帰モデル\n",
    "def get_result_test_reg(df_input,case=int):\n",
    "    df = df_input.copy()\n",
    "    df_temp=[]#[X_train,y_train,X_test,y_test,X_test_id,X_test_kamoku]\n",
    "    model = []\n",
    "    pred = []\n",
    "    #新人モデルの結果\n",
    "    if case == 1:\n",
    "        df_temp = make_data_shinjin_reg(df)\n",
    "    #経験者モデルの結果\n",
    "    elif case == 2:\n",
    "        df_temp = make_data_keiken_reg(df)\n",
    "    #テストモデルの結果\n",
    "    elif case == 3:\n",
    "        df_temp = make_data(df)\n",
    "    model = train_model_reg(df_temp,a=2,b=1,c=None)\n",
    "    pred = get_test_reg(df_temp, model)\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "997ab844-b2ca-45a4-9463-f99151fad1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_result_test_clf(df_prets[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fc58d85-e2eb-4f03-ac97-57cc8c35809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_result_test_clf(df_prets[2],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bcb0da87-7f1d-4970-a984-22a638775983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_result_test_reg(df_prets[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ddb78a6-833f-4a7f-a105-fea5beb18a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_result_test_reg(df_prets[2],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "43bae8da-e45a-431b-962e-2f4eed61d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_result_test_clf(df_prets[1],3)#新人分類モデル、科目と分野を変数から除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "422d4920-e7af-4b13-a1fe-b506a603d757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学年</th>\n",
       "      <th>年齢</th>\n",
       "      <th>偏差値</th>\n",
       "      <th>採否時登録時間</th>\n",
       "      <th>依頼枚数</th>\n",
       "      <th>登録試験点数</th>\n",
       "      <th>参加回数</th>\n",
       "      <th>身分</th>\n",
       "      <th>スタッフコード</th>\n",
       "      <th>実測値</th>\n",
       "      <th>予測値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>61.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1236</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>大学生</td>\n",
       "      <td>1060644538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.8</td>\n",
       "      <td>16786</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>大学院生</td>\n",
       "      <td>1060696014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>63.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7758</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>大学生</td>\n",
       "      <td>1070003433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5799</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>大学生</td>\n",
       "      <td>1070009870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3844</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>社会人</td>\n",
       "      <td>1070020037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       学年    年齢   偏差値  採否時登録時間   依頼枚数  登録試験点数  参加回数    身分     スタッフコード  実測値  \\\n",
       "674   3.0  24.0  61.9     75.0   1236      43     0   大学生  1060644538    0   \n",
       "838   2.0  23.0  73.0    100.8  16786      90     0  大学院生  1060696014    0   \n",
       "1714  1.0  22.0  63.8     60.0   7758      84     0   大学生  1070003433    0   \n",
       "2179  3.0  22.0  65.6     80.0   5799      81     0   大学生  1070009870    0   \n",
       "2832  1.0  32.0  49.3     72.0   3844      43     0   社会人  1070020037    1   \n",
       "\n",
       "      予測値  \n",
       "674     1  \n",
       "838     1  \n",
       "1714    0  \n",
       "2179    0  \n",
       "2832    0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46eea85-9458-49d6-8c24-96148e0f339e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##　結果出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107369af-f3c2-4bbb-aa0f-fe128de6cfe4",
   "metadata": {},
   "source": [
    "### 予測値の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4924cc88-fd17-49a8-86cc-203b8c3a981f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#結果出力\n",
    "c1 = get_result_test_clf(df_prets[1],1)#新人分類モデルの検証結果\n",
    "c2 = get_result_test_clf(df_prets[2],2)#経験分類モデルの検証結果\n",
    "\n",
    "c_tag=['実測値','予測値']#y_true, y_pred\n",
    "\n",
    "r1 = get_result_test_reg(df_prets[1],1)#新人回帰モデルの検証結果\n",
    "r2 = get_result_test_reg(df_prets[2],2)#経験回帰モデルの検証結果\n",
    "\n",
    "r_tag=['実測値ランク','予測値ランク']#y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350686ca-c63a-4981-b6ea-9d23185726ef",
   "metadata": {},
   "source": [
    "### 予測値の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "725dbf49-df0a-43ee-a494-bba0dd528a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pathの設定 \n",
    "\"\"\"\n",
    "#ファイル名\n",
    "name_file = \"枠更新率分類モデル_21~22夏_22夏検証_DTs\" #ファイル名\n",
    "#保存先フォルダ\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "#保存するパス\n",
    "path_file = r'{p}/{n}_pred'.format(p = path_folder, n = name_file)#ファイルパスとファイル名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6d5d2524-f9cc-4789-92fd-056cbc39f576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#結果出力\n",
    "c1 = get_result_test_clf(df_prets[1],1)#新人分類モデルの検証結果\n",
    "c2 = get_result_test_clf(df_prets[2],2)#経験分類モデルの検証結果\n",
    "r1 = get_result_test_reg(df_prets[1],1)#新人回帰モデルの検証結果\n",
    "r2 = get_result_test_reg(df_prets[2],2)#経験回帰モデルの検証結果\n",
    "\n",
    "c3 = get_result_test_clf(df_prets[1],3)#新人分類モデル、科目と分野を変数から除外\n",
    "\n",
    "target_names = [0,1] #閾値以上が0, 閾値以下が1\n",
    "\n",
    "c_tag=['実測値','予測値']#y_true, y_pred\n",
    "r_tag=['実測値ランク','予測値ランク']#y_true, y_pred\n",
    "\n",
    "dict_c = {'新人分類': c1, '経験分類': c2, '新人分類_科目分野除外': c3,}\n",
    "dict_r = {'新人回帰': r1, '経験回帰': r2}\n",
    "# dict = {'新人分類': c1, '経験分類': c2, '新人回帰': r1, '経験回帰': r2}\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    for key, df in dict_c.items():\n",
    "        df.to_excel(writer, sheet_name='{}_予測'.format(key),encoding='utf-8-sig', index = False)\n",
    "        df_score = pd.DataFrame(classification_report(y_true = list(df[c_tag[0]]),#評価指標に用いる列を指定し、リスト化\n",
    "                                                      y_pred = list(df[c_tag[1]]),#評価指標に用いる列を指定し、リスト化\n",
    "                                                      target_names = target_names,\n",
    "                                                      output_dict=True))\n",
    "        df_score.to_excel(writer, sheet_name='{}_評価'.format(key),encoding='utf-8-sig', index = True)\n",
    "    for key, df in dict_r.items():\n",
    "        df.to_excel(writer, sheet_name='{}_予測'.format(key),encoding='utf-8-sig', index = False)\n",
    "        df_score = pd.DataFrame(classification_report(y_true = list(df[r_tag[0]]),#評価指標に用いる列を指定し、リスト化\n",
    "                                                      y_pred = list(df[r_tag[1]]),#評価指標に用いる列を指定し、リスト化\n",
    "                                                      target_names = target_names,\n",
    "                                                      output_dict=True))\n",
    "        df_score.to_excel(writer, sheet_name='{}_評価'.format(key),encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf5c56-1118-46ed-93d2-0097621daf24",
   "metadata": {},
   "source": [
    "### 重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "14d0995e-6329-42bd-9b2b-f782d6817ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_imp(df_input, case = int, method = str, suffix = str):\n",
    "    \"\"\"\n",
    "    df_inputはエラー値を除いたデータマートを指定する\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    if method == 'clf':\n",
    "        #新人モデルの結果\n",
    "        if case == 1:\n",
    "            df = make_data_shinjin_clf(df)\n",
    "            model = train_model_clf(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_新人clf.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "\n",
    "        #経験者モデルの結果\n",
    "        elif case == 2:\n",
    "            df = make_data_keiken_clf(df)\n",
    "            model = train_model_clf(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_経験clf.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "            \n",
    "    elif method == 'reg':\n",
    "        #新人モデルの結果\n",
    "        if case == 1:\n",
    "            df = make_data_shinjin_reg(df)\n",
    "            model = train_model_reg(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_新人reg.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "\n",
    "        #経験者モデルの結果\n",
    "        elif case == 2:\n",
    "            df = make_data_keiken_reg(df)\n",
    "            model = train_model_reg(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_経験reg.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9ec53cbd-044f-462e-b28b-a6081653c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "suf = 'GB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "edec0e81-b4bc-4c6e-9051-436c1b1eab84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "get_graph_imp(df_prets[1],case = 1, method = 'clf',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fabb22d5-5914-4a16-a455-fb45d1dd7f79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "get_graph_imp(df_prets[2],case = 2, method = 'clf',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b1168547-2707-44db-96f6-d293414428d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "get_graph_imp(df_prets[1],case = 1, method = 'reg',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5e5b8d8a-7d43-44d4-a46a-652b9dc00347",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "get_graph_imp(df_prets[2],case = 2, method = 'reg',suffix = suf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c3589-9d28-488b-b661-a4529e7f0bb7",
   "metadata": {},
   "source": [
    "### 重要度、樹形図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b9253f58-497a-4d9b-92b4-027e7b3f2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(df_input, case = int, method = str, suffix = str):\n",
    "    \"\"\"\n",
    "    df_inputはエラー値を除いたデータマートを指定する\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    if method == 'clf':\n",
    "        #新人モデルの結果\n",
    "        if case == 1:\n",
    "            df = make_data_shinjin_clf(df)\n",
    "            model = train_model_clf(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_新人clf.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "            #樹形図\n",
    "            treegraph = make_treegraph(df, model)\n",
    "            path_file = r'{p}/{n}_樹形図_{s}_新人clf'.format(p = path_folder, n = name_file, s = suffix)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "\n",
    "        #経験者モデルの結果\n",
    "        elif case == 2:\n",
    "            df = make_data_keiken_clf(df)\n",
    "            model = train_model_clf(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_経験clf.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "            #樹形図\n",
    "            treegraph = make_treegraph(df, model)\n",
    "            path_file = r'{p}/{n}_樹形図_{s}_経験clf'.format(p = path_folder, n = name_file, s = suffix)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "            \n",
    "    elif method == 'reg':\n",
    "        #新人モデルの結果\n",
    "        if case == 1:\n",
    "            df = make_data_shinjin_reg(df)\n",
    "            model = train_model_reg(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_新人reg.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "            #樹形図\n",
    "            treegraph = make_treegraph(df, model)\n",
    "            path_file = r'{p}/{n}_樹形図_{s}_新人reg'.format(p = path_folder, n = name_file, s = suffix)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "\n",
    "        #経験者モデルの結果\n",
    "        elif case == 2:\n",
    "            df = make_data_keiken_reg(df)\n",
    "            model = train_model_reg(df,a=2,b=1,c=None)\n",
    "            #重要度\n",
    "            res = get_importance(df, model)\n",
    "            res.savefig('{p}/{n}_重要度_{s}_経験reg.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "            #樹形図\n",
    "            treegraph = make_treegraph(df, model)\n",
    "            path_file = r'{p}/{n}_樹形図_{s}_経験reg'.format(p = path_folder, n = name_file, s = suffix)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d1b9ae2c-024a-41be-8d30-f97ebe3ca730",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_73974/1535020732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_73974/4049310452.py\u001b[0m in \u001b[0;36mget_graph\u001b[0;34m(df_input, case, method, suffix)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{p}/{n}_重要度_{s}_新人clf.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#樹形図\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtreegraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_treegraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mpath_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'{p}/{n}_樹形図_{s}_新人clf'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#ファイルパスとファイル名\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtreegraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ll/_gcfyf2137x3x6dwgb9nkj740000gp/T/ipykernel_73974/3720707952.py\u001b[0m in \u001b[0;36mmake_treegraph\u001b[0;34m(df, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_train_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     dot_data = tree.export_graphviz(model, out_file=None,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                     \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_train_feature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                     \u001b[0;31m# class_names=iris.target_names,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             precision=precision)\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"impurity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             self.recurse(decision_tree.tree_, 0,\n\u001b[0m\u001b[1;32m    425\u001b[0m                          criterion=decision_tree.criterion)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "get_graph(df_prets[1],case = 1, method = 'clf',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3292fff8-aedb-488b-9c21-b10172345536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_graph(df_prets[2],case = 2, method = 'clf',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "53f6e1db-3745-4832-8c64-0517c43f1c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_graph(df_prets[1],case = 1, method = 'reg',suffix = suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15caa18d-5369-47b2-8713-fb2c6c032398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_graph(df_prets[2],case = 2, method = 'reg',suffix = suf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18421ffc-723c-4211-9648-574b6bc4d00e",
   "metadata": {},
   "source": [
    "### 混合行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ca6ce730-9af9-434d-acd8-f844278280fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pathの設定 \n",
    "\"\"\"\n",
    "#ファイル名\n",
    "name_file = \"枠更新率分類モデル_21~22夏_22夏検証_混合行列_v1\" #ファイル名\n",
    "#保存先フォルダ\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "#保存するパス\n",
    "path_file = r'{p}/{n}.png'.format(p = path_folder, n = name_file)#ファイルパスとファイル名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b5f65624-a885-4d43-a5bb-be1102fe842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a3b2a8cf-fc49-4026-82cb-bbbbab89f0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#描画テスト\n",
    "df = c1\n",
    "y_true = list(df[c_tag[0]])#評価指標に用いる列を指定し、リスト化\n",
    "y_pred = list(df[c_tag[1]])#評価指標に用いる列を指定し、リスト化\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Reds',fmt='d')\n",
    "# plt.savefig('sklearn_confusion_matrix.png')\n",
    "# plt.savefig(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a37a0198-7d11-4bcc-be82-9f4757522e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm(df_input, path_folder, name_file, col_names = list, suffix = str):\n",
    "    \"\"\"\n",
    "    df_input:実測値と予測値を含むDF\n",
    "    col_names:実測値と予測値の列名\n",
    "    混合行列の図を返す\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    y_true =list(df[col_names[0]])#実測ラベル\n",
    "    y_pred =list(df[col_names[1]])#予測ラベル\n",
    "    labels = sorted(list(set(y_true) | set(y_pred)))# ラベルの順序を指定\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels) # 混同行列の取得&ラベル順序指定\n",
    "    fig =plt.figure (figsize = (6.4, 4.8))\n",
    "    sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Reds',fmt='d')\n",
    "    plt.ylabel('実測値', fontsize=13)\n",
    "    plt.xlabel('予測値', fontsize=13)\n",
    "    fig.savefig('{p}/{n}_混合行列_{s}.png'.format(p = path_folder, n = name_file, s = suffix), format=\"png\", dpi=300)\n",
    "    plt.clf()#メモリ解放\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d4e92775-1b56-4852-8562-f18ea5d5adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "suf = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cfc855d6-8e60-49f0-ba6e-7d0232aee62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 460.8x345.6 with 0 Axes>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cm(c1, path_folder, name_file, col_names = c_tag, suffix = '新人分類モデル_{}'.format(suf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "99fe9e33-d16d-4ed5-9072-06e676a492ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 460.8x345.6 with 0 Axes>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cm(c2, path_folder, name_file, col_names = c_tag, suffix = '経験分類モデル_{}'.format(suf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5bcc7ab6-53fd-4801-808b-5fe93b3b9fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 460.8x345.6 with 0 Axes>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cm(r1, path_folder, name_file, col_names = r_tag, suffix = '新人回帰モデル_{}'.format(suf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "96633847-a677-4c87-bb08-9796555c090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 460.8x345.6 with 0 Axes>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cm(r2, path_folder, name_file, col_names = r_tag, suffix = '経験回帰モデル_{}'.format(suf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2440f2-3c21-40de-aa1e-75115218afbb",
   "metadata": {},
   "source": [
    "## 集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "691c5828-0df2-44b8-96f7-83afb0605b09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/s.ogura/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#結果出力\n",
    "c1 = get_result_test_clf(df_prets[1],1)#新人分類モデルの検証結果\n",
    "c2 = get_result_test_clf(df_prets[2],2)#経験分類モデルの検証結果\n",
    "\n",
    "c_tag=['実測値','予測値']#y_true, y_pred\n",
    "\n",
    "r1 = get_result_test_reg(df_prets[1],1)#新人回帰モデルの検証結果\n",
    "r2 = get_result_test_reg(df_prets[2],2)#経験回帰モデルの検証結果\n",
    "\n",
    "r_tag=['実測値ランク','予測値ランク']#y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "54996a61-0274-4414-9c0d-114b727093d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['学年', '年齢', '偏差値', '採否時登録時間', '依頼枚数', '登録試験点数', '参加回数', '科目', '分野',\n",
       "       '身分', 'スタッフコード', '実測値', '予測値', '0の確信度', '1の確信度'], dtype=object)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5a81e1ec-a48a-46dc-8901-d06ddacf605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['前回の完全一致率', '前回の枠更新率', '学年', '年齢', '偏差値', '採否時登録時間', '依頼枚数',\n",
       "       '登録試験点数', '参加回数', '科目', '分野', '身分', 'スタッフコード', '実測値', '予測値',\n",
       "       '0の確信度', '1の確信度'], dtype=object)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83846c96-3360-44d8-89ae-5a33b8e3e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームをコピー\n",
    "#0の確信度の上位95％, 90％, 80％, 70％の値を取得\n",
    "#上位95％の値を持つレコードを抽出し、新しいdfにする\n",
    "#各dfの枠更新率0.99以下の人数/全体の人数を出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "dfc2933b-5f7b-4291-b580-3036bfdd32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_99(df_input):\n",
    "    \"\"\"\n",
    "    データフレームをコピー\n",
    "    0の確信度の上位X％の値を持つレコードを抽出し、新しいdfにする\n",
    "    各dfの枠更新率0.99以下の人数/全体の人数を出す\n",
    "    \"\"\"\n",
    "    df = df_input.copy()    \n",
    "    #下位X%の値を取得する\n",
    "    thresholds = df['0の確信度'].quantile([0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    res = []\n",
    "    # for i in thresholds:\n",
    "    for i, value in enumerate(thresholds):\n",
    "        df_temp = df[df['0の確信度'] >= value]\n",
    "        res.append(len(df_temp[df_temp['実測値']==1]) / len(df_temp))\n",
    "        print(len(df_temp),len(df_temp[df_temp['実測値']==1]),round(res[i], 3))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1a4b2b69-7bdc-4b8c-afb4-b99f90bc4383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733 142 0.194\n",
      "696 131 0.188\n",
      "659 124 0.188\n",
      "586 109 0.186\n",
      "513 90 0.175\n",
      "440 79 0.18\n",
      "367 65 0.177\n",
      "293 46 0.157\n",
      "220 37 0.168\n",
      "147 27 0.184\n",
      "74 13 0.176\n"
     ]
    }
   ],
   "source": [
    "test = calc_99(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5d624804-aa22-49a0-80a0-2e3000468eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677 218 0.13\n",
      "1593 200 0.126\n",
      "1509 189 0.125\n",
      "1341 162 0.121\n",
      "1174 132 0.112\n",
      "1006 107 0.106\n",
      "839 87 0.104\n",
      "671 73 0.109\n",
      "503 57 0.113\n",
      "336 40 0.119\n",
      "168 13 0.077\n"
     ]
    }
   ],
   "source": [
    "test = calc_99(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fdc90-3d3e-4c5e-9b69-3606d148d030",
   "metadata": {},
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d896bb-9d5b-4323-adcd-a7c5cc332d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues',fmt='d')\n",
    "plt.savefig('sklearn_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6e4ab-d244-43b7-8c32-5270bb98cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]#リストで作成\n",
    "y_pred = [0, 1, 1, 1, 1, 0, 0, 0, 1, 1]#リストで作成\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2684175-b345-4a67-b2bc-a1d20e51a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(df_input,case=int):\n",
    "    df = df_input.copy()\n",
    "    path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "    #新人モデルの結果\n",
    "    if case == 0:\n",
    "        dfs=[[],[],[]]\n",
    "        dfs[0] = make_data_shinjin(df,val=0)\n",
    "        dfs[1] = make_data_shinjin2(df,val=0)\n",
    "        dfs[2] = make_data_shinjin3(df,val=0)\n",
    "        models = [[],[],[]]\n",
    "        for i in range(0,len(dfs)):\n",
    "            model = train_model(dfs[i],a=2,b=1,c=None)\n",
    "            res = get_importance(dfs[i], model)\n",
    "            name = \"採点者品質予測_科目混合_完全一致率_重要度_新人{}_0902_v1\".format(i)#ファイル名\n",
    "            path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "            res.savefig('{p}/{n}.png'.format(p = path_folder, n = name), format=\"png\", dpi=300)\n",
    "            treegraph = make_treegraph(dfs[i], model)\n",
    "            name = \"採点者品質予測_科目混合_完全一致率_樹形図_新人{}_0902_v1\".format(i)#ファイル名\n",
    "            path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "\n",
    "    #経験者モデルの結果\n",
    "    elif case == 1:\n",
    "        dfs=[[],[],[]]\n",
    "        dfs[0] = make_data_keiken(df,val=0)\n",
    "        dfs[1] = make_data_keiken2(df,val=0)\n",
    "        dfs[2] = make_data_keiken3(df,val=0)\n",
    "        models = [[],[],[]]\n",
    "        for i in range(0,len(dfs)):\n",
    "            model = train_model(dfs[i],a=2,b=1,c=None)\n",
    "            res = get_importance(dfs[i], model)\n",
    "            name = \"採点者品質予測_科目混合_完全一致率_重要度_経験{}_0902_v1\".format(i)#ファイル名\n",
    "            path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "            res.savefig('{p}/{n}.png'.format(p = path_folder, n = name), format=\"png\", dpi=300)\n",
    "            treegraph = make_treegraph(dfs[i], model)\n",
    "            name = \"採点者品質予測_科目混合_完全一致率_樹形図_経験{}_0902_v1\".format(i)#ファイル名\n",
    "            path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "            treegraph.render(path_file)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dee9c56-9936-46e2-8ce0-e3f2c80229c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "target_names = ['0','1'] #閾値以上が0, 閾値以下が1\n",
    "a=['実測値','予測値']#y_true, y_pred\n",
    "df1 = df_test#モデルの検証結果\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df1.to_excel(writer, sheet_name='22夏検証_test',encoding='utf-8-sig', index = False)\n",
    "    pd.DataFrame(classification_report(y_true = list(df1[a[0]]),\n",
    "                                       y_pred = list(df1[a[1]]),\n",
    "                                       target_names=target_names,output_dict=True)).to_excel(writer, sheet_name='22夏検証_test_score',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6eb376b6-3db7-4274-bde2-53816db6e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "target_names = ['0.70~0.95', '~0.70', '0.95~']\n",
    "a=['実測一致率ランク','想定一致率ランク']#y_true, y_pred\n",
    "df1 = get_result_test(df_pret_shinjin, case = 0)#新人モデルの検証結果\n",
    "df2 = get_result_test(df_pret_keiken, case = 1)#経験モデルの検証結果\n",
    "df3 = get_result_test(df_pret_etc, case = 0)#経験（過去データなし）モデルの検証結果 新人モデルと同じ学習法で、データセットだけ変えてある\n",
    "\n",
    "df1_pred = get_result_pred(df_pret_shinjin, case = 0)#新人モデルの予測結果\n",
    "df2_pred = get_result_pred(df_pret_keiken, case = 1)#経験モデルの予測結果\n",
    "df3_pred = get_result_pred(df_pret_etc, case = 0)#経験（過去データなし）モデルの予測結果\n",
    "\n",
    "\n",
    "name_file = \"採点者品質予測_22冬_予測値_1227_v2\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df1_pred.to_excel(writer, sheet_name='予測_新人_分野',encoding='utf-8-sig', index = False)\n",
    "    df2_pred.to_excel(writer, sheet_name='予測_経験_分野',encoding='utf-8-sig', index = False)\n",
    "    df3_pred.to_excel(writer, sheet_name='予測_経験過去無し_分野',encoding='utf-8-sig', index = False)\n",
    "    df1.to_excel(writer, sheet_name='22夏検証_新人_分野',encoding='utf-8-sig', index = False)\n",
    "    df2.to_excel(writer, sheet_name='22夏検証_経験_分野',encoding='utf-8-sig', index = False)\n",
    "    df3.to_excel(writer, sheet_name='22夏検証_経験過去無し_分野',encoding='utf-8-sig', index = False)\n",
    "    pd.DataFrame(classification_report(y_true = list(df1[a[0]]),\n",
    "                                       y_pred = list(df1[a[1]]),\n",
    "                                       target_names=target_names,output_dict=True)).to_excel(writer, sheet_name='22夏検証_新人_分野_score',encoding='utf-8-sig', index = True)\n",
    "    pd.DataFrame(classification_report(y_true = list(df2[a[0]]),\n",
    "                                       y_pred = list(df2[a[1]]),\n",
    "                                       target_names=target_names,output_dict=True)).to_excel(writer, sheet_name='22夏検証_経験_分野_score',encoding='utf-8-sig', index = True)\n",
    "    pd.DataFrame(classification_report(y_true = list(df3[a[0]]),\n",
    "                                       y_pred = list(df3[a[1]]),\n",
    "                                       target_names=target_names,output_dict=True)).to_excel(writer, sheet_name='22夏検証_経験過去無し_分野_score',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c29b5351-aec6-4f79-88f4-8f03c26a72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5f833d-e17f-451a-a33c-ca87c9ecf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
