{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4e5c2-5cc2-4182-912b-59b5c3ff5dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 作業工程計画\n",
    "\n",
    "使用データ：FMT修正版_CRLEAデータ①入力様式_秋後半_v2_pretreated_v1.xlsx<br>\n",
    "目的：予測値の誤差を集計する<br>\n",
    "学習：検証以外の採点回<br>\n",
    "検証：ある年度のある採点回<br>\n",
    "\n",
    "0. ライブラリを読み込む\n",
    "1. 整形データを読み込む\n",
    "2. 整形データに学習・検証を分ける変数を追加する\n",
    "3. 各組み合わせで予測値と、集計値を出す\n",
    "4. 結果を結合して出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a61eb-834f-4150-a979-2b7ffe145fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a825b8e5-4df0-4c29-867e-f1e72ee3efd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import re \n",
    "\n",
    "\"\"\"\n",
    "機械学習ライブラリの準備\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor #決定木\n",
    "import lightgbm as lgb #lightGBM\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e220-ecc1-4b36-bd44-bc4d08487d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 村上さん pandas_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeb5627-7dea-45f6-b814-273133437f53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "村上さんtoolbox\n",
    "\"\"\"\n",
    "# pandas 基礎集計クラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "#http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac\n",
    "\n",
    "# Jupyterで表示するためには、最初に以下を実行すること\n",
    "%matplotlib inline\n",
    "\n",
    "# Static Classで設計する\n",
    "class pandas_tool:\n",
    "    \n",
    "    # All in one チェック（Jupyterのみ）\n",
    "    def all_basic_summary_jupyter(df):\n",
    "        print(\"■ 型の確認\")\n",
    "        display(pandas_tool.type(df))\n",
    "        print(\"■ 数値型の確認\")\n",
    "        display(pandas_tool.summary(df)[0])\n",
    "        print(\"■ カテゴリ型の確認\")\n",
    "        cate_var_data = list(df.select_dtypes(include=['object']).columns)\n",
    "        ret = pandas_tool.freq(df,cate_var_data)\n",
    "        for d in ret:\n",
    "            display(pd.DataFrame(d))\n",
    "            print(\"---------------\")\n",
    "        print(\"■ 欠損の確認\")\n",
    "        display(pandas_tool.check_missing(df))\n",
    "    \n",
    "    # 相関関係可視化（Jupyterのみ）\n",
    "    def all_value_relation_visualize(df):\n",
    "        #sns.set_context(\"poster\", 1.2, {\"lines.linewidth\": 3})\n",
    "        sns.pairplot(df,size=5)\n",
    "    \n",
    "    # カテゴリ変数でのヒートマップ（Jupyterのみ）\n",
    "    def make_heatmap(df,x,y,value):\n",
    "        target_df = df.pivot_table(index=x,values=value,columns=y)\n",
    "        sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues')\n",
    "    \n",
    "    # 散布図（Jupyterのみ）\n",
    "    def make_scatter_chart(df,x,y):\n",
    "        #sns.jointplot(x=x, y=y, data=df, kind=\"hex\")\n",
    "        sns.jointplot(x=x, y=y, data=df)\n",
    "    \n",
    "    # 組み合わせでヒートマップを作成（Jupyterのみ）\n",
    "    def all_make_heatmap(df,var_list,value):\n",
    "        col_num = 2\n",
    "        var_list_set = list(combinations(var_list,2))\n",
    "        \n",
    "        fig, axes = plt.subplots(int(len(var_list_set)/col_num)+1, col_num, figsize=(18,3+6.5*int(len(var_list_set)/col_num)))\n",
    "        \n",
    "        for i,target in enumerate(var_list_set):\n",
    "            target_df = df.pivot_table(index=target[0],values=value,columns=target[1])\n",
    "            sns.heatmap(target_df, annot=True, fmt='1.1f', cmap='Blues', ax=axes[int(i/col_num), i%col_num])\n",
    "            \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # 数値集計\n",
    "    def summary(df,view=False):\n",
    "        ret=df.describe()\n",
    "        mis_ret=df.isnull().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(\"・統計量\")\n",
    "            print(ret)\n",
    "            print(\"・欠損値\")\n",
    "            print(mis_ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret,mis_ret\n",
    "    \n",
    "    # 型チェック\n",
    "    def type(df,view=False):\n",
    "        ret = df.dtypes\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_rows\")\n",
    "            pd.set_option(\"display.max_rows\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_rows\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損チェック\n",
    "    def check_missing(df,view=False):\n",
    "        not_null_df=df.notnull()\n",
    "        ret=pd.DataFrame()\n",
    "        for name in not_null_df.columns:\n",
    "            tmp_df=not_null_df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            ret = pd.concat([ret,tmp_df],axis=1)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 欠損値のオブザベーションを抽出\n",
    "    def get_miss_data(df,column,view=False):\n",
    "        ret=df[df[column].isnull()]\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        return ret\n",
    "    \n",
    "    # 欠損値を中央値で補完\n",
    "    def fill_miss_med(df,var_name):\n",
    "        var=df[var_name].median()\n",
    "        df[var_name].fillna(var,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 欠損値を0で補完\n",
    "    def fill_miss_zero(df,var_name):\n",
    "        df[var_name].fillna(0,inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # 特定の値を欠損とみなす\n",
    "    def apply_miss_value(df,var_name,value):\n",
    "        df[var_name]=df[var_name].replace(value,np.nan)\n",
    "        return df\n",
    "    \n",
    "    # 重複チェック\n",
    "    def check_dup(df,columns,view=False):\n",
    "        ret=pd.DataFrame()\n",
    "        for name in columns:\n",
    "            dup_cnt=df[name].duplicated().sum()\n",
    "            tmp_df = pd.DataFrame({'var_name':[name],'dup_cnt':[dup_cnt]})\n",
    "            ret = pd.concat([ret,tmp_df],axis=0,ignore_index= True)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 組み合わせ重複チェック\n",
    "    def check_dup_comb(df,columns,view=False):\n",
    "        ret = df[columns].duplicated().sum()\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # ユニークデータ取得\n",
    "    def get_uniq_data(df,uniq_key,sort_key,keep='first'):\n",
    "        ret = df.sort_values(by=sort_key)\n",
    "        ret.drop_duplicates(subset=uniq_key, keep=keep, inplace=True)\n",
    "        return ret\n",
    "    \n",
    "    # カテゴリ集計\n",
    "    def freq(df,columns,view=False):\n",
    "        ret=list()\n",
    "        for name in columns:\n",
    "            tmp_df=df[name].value_counts()\n",
    "            tmp_df.name=name\n",
    "            #ret = pd.concat([ret,tmp_df],axis=1)\n",
    "            ret.append(tmp_df)\n",
    "        \n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            for r in ret:\n",
    "                print(r)\n",
    "                #display(r)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # 複雑な集計\n",
    "    def tabulate(df,row,col=None,var='',func=np.sum,view=False):\n",
    "        if var == '':\n",
    "            tmp_df=df.reset_index(drop=False,inplace=False)\n",
    "            ret=pd.pivot_table(data=tmp_df, values='index', index=row, columns=col, aggfunc='count', dropna=False, fill_value=0 ,margins = False)\n",
    "            tmp_df=None\n",
    "        else:\n",
    "            ret=pd.pivot_table(data=df, values=var, index=row, columns=col, aggfunc=func, dropna=False, fill_value=0 ,margins = False)\n",
    "        if view:\n",
    "            param=pd.get_option(\"display.max_columns\")\n",
    "            pd.set_option(\"display.max_columns\",1000)\n",
    "            print(ret)\n",
    "            pd.set_option(\"display.max_columns\",param)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # マージ\n",
    "    def merge(df1,df2,key,how,view=True):\n",
    "        if view:\n",
    "            print(\"df1のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df1,key,True)\n",
    "            print(\"df2のキー重複\")\n",
    "            pandas_tool.check_dup_comb(df2,key,True)\n",
    "            \n",
    "            print(\"df1のオブザベーション:{0}\".format(len(df1)))\n",
    "            print(\"df2のオブザベーション:{0}\".format(len(df2)))\n",
    "        \n",
    "        ret=pd.merge(df1,df2,how=how,on=key)\n",
    "        \n",
    "        if view:\n",
    "            print(\"mergeのオブザベーション:{0}\".format(len(ret)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    # Rank\n",
    "    def rank(df,var,num,suffix='_rank',check=False):\n",
    "        labels=[i for i in range(0,num)]\n",
    "        df[var+suffix]=pd.qcut(df[var], num, labels=labels)\n",
    "        \n",
    "        # check data\n",
    "        if check:\n",
    "            ret=pd.DataFrame()\n",
    "            max_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.max,view=False)\n",
    "            max_df.name='max'\n",
    "            min_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func=np.min,view=False)\n",
    "            min_df.name='min'\n",
    "            cnt_df=pandas_tool.tabulate(df=df,row=[var+suffix],var=var,func='count',view=False)\n",
    "            cnt_df.name='count'\n",
    "            ret=pd.concat([ret,min_df,max_df,cnt_df],axis=1)\n",
    "            return df,ret\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Rank適用(min基準)\n",
    "    def apply_rank(df,rank_df):\n",
    "        tmp_df=copy.deepcopy(rank_df)\n",
    "        tmp_df.reset_index(drop=False,inplace=True)\n",
    "        target_name=tmp_df.columns[3]\n",
    "        tmp_df.columns=[\"rank\",\"min\",\"max\",\"cnt\"]\n",
    "        \n",
    "        def judge_thld(row):\n",
    "            ret_var = -1\n",
    "            cond_list = [\"if 0 : ret_var = 0\"]\n",
    "            \n",
    "            for i in range(1,len(tmp_df)):\n",
    "                cond_list.append(\"elif row < \" +str(tmp_df.ix[i,'min'])+ \" : ret_var = \" + str(tmp_df.ix[i-1,'rank']))\n",
    "            \n",
    "            cond_list.append(\"else: ret_var = \" + str(tmp_df.ix[len(tmp_df)-1,'rank']))\n",
    "            cond_str=\"\\r\\n\".join(cond_list)\n",
    "            # ローカル辞書をexecと共有する\n",
    "            local_dict=locals()\n",
    "            exec(cond_str,local_dict)\n",
    "            return local_dict[\"ret_var\"]\n",
    "        \n",
    "        df[target_name+\"_rank\"]=df[target_name].apply(judge_thld)\n",
    "        return df\n",
    "    \n",
    "    # Min%以下はMin%点に、Max%以上はMax%点にクリップする\n",
    "    def clip_min_max(df,col_list,apply_df=None,max_pct=0.99,min_pct=0.01):\n",
    "        p_min = df[col_list].quantile(min_pct)\n",
    "        p_max = df[col_list].quantile(max_pct)\n",
    "        \n",
    "        df[col] = df[col_list].clip(p_min,p_max,axis=1)\n",
    "        \n",
    "        # もしも適用先のデータがあるならば（例えば検証データ）対応\n",
    "        if apply_df is not None:\n",
    "            apply_df[col] = apply_df[col_list].clip(p_min,p_max,axis=1)\n",
    "            return df,apply_df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    # 文字列→数値変換\n",
    "    def conv_float(df,column,percent_flg=False):\n",
    "        \n",
    "        def conv_f(row):\n",
    "            if row[column] == \"\" or row[column] is np.nan:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return float(row[column])\n",
    "        \n",
    "        df[column]=df[column].str.replace(\"\\\\\",\"\").str.replace(\",\",\"\").str.replace(\"%\",\"\").str.strip()\n",
    "        df[column]=df.apply(conv_f,axis=1)\n",
    "        \n",
    "        if percent_flg:\n",
    "            df[column]=df[column]/100\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9a4cd-ddb6-4c9f-a6c8-c39a1e582fa3",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8028c87-0361-4ccd-ba82-45996a2ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エクセルを読み込み、シートごとにデータフレームに入れる\n",
    "\"\"\"\n",
    "path_name = ファイルパス\n",
    "sn_list = エクセルシート名のリスト\n",
    "\"\"\"\n",
    "path_name = \"/Users/s.ogura/Documents/CRLEA/data/intermediatedata/FMT修正版_CRLEAデータ①入力様式_秋後半_v2_pretreated_v1.xlsx\"\n",
    "path_file =  r'{}'.format(path_name)\n",
    "input_file = pd.ExcelFile(path_file)\n",
    "sn_list = input_file.sheet_names\n",
    "#sn_list ['国語', '数学','英語']\n",
    "\n",
    "# Excelファイルの読み込み\n",
    "df_jpn = pd.read_excel(path_file, sn_list[0], header=0, index_col=None,skiprows=None,dtype = {'ロット番号': object})#headerを修正\n",
    "df_math = pd.read_excel(path_file, sn_list[1], header=0, index_col=None,skiprows=None,dtype = {'ロット番号': object})#headerを修正\n",
    "df_eng = pd.read_excel(path_file, sn_list[2], header=0, index_col=None,skiprows=None,dtype = {'ロット番号': object})#headerを修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e0cb10-72d9-45b0-9da9-f8c1fb4e4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test,predのデータ分類ラベル あとで試す。\n",
    "def make_datalabel(df_input):\n",
    "    df = df_input.copy()\n",
    "    conditions = [\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '春'),#0\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '夏'),#1\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '秋'),#2\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '冬'),#3\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '春'),#4\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '夏'),#5\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '秋'),#6\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '冬'),#7\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '春'),#8\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '夏'),#9\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '秋'),#10\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '冬'),#11\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '春'),#12\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '夏'),#13\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '秋'),#14\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '冬'),#15\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '春'),#16\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '夏'),#17\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '秋')]#18\n",
    "    choices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "    df.loc[:,'data'] = np.select(conditions, choices, default = np.nan)\n",
    "    \n",
    "    conditions = [\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '春'),#0\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '夏'),#1\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '秋'),#2\n",
    "        (df['年度'] == 2018)&(df['採点回'] == '冬'),#3\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '春'),#4\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '夏'),#5\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '秋'),#6\n",
    "        (df['年度'] == 2019)&(df['採点回'] == '冬'),#7\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '春'),#8\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '夏'),#9\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '秋'),#10\n",
    "        (df['年度'] == 2020)&(df['採点回'] == '冬'),#11\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '春'),#12\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '夏'),#13\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '秋'),#14\n",
    "        (df['年度'] == 2021)&(df['採点回'] == '冬'),#15\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '春'),#16\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '夏'),#17\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '秋'),#16\n",
    "        (df['年度'] == 2022)&(df['採点回'] == '冬')]#18\n",
    "    choices = ['18春','18夏','18秋','18冬','19春','19夏','19秋','19冬',\n",
    "               '20春','20夏','20秋','20冬','21春','21夏','21秋','21冬',\n",
    "               '22春','22夏','22秋','22冬']\n",
    "    df.loc[:,'ラベル'] = np.select(conditions, choices, default = np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9b86f8c-76c0-4b03-98e2-16a055cb5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpn = make_datalabel(df_jpn)\n",
    "df_math = make_datalabel(df_math)\n",
    "df_eng = make_datalabel(df_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95706061-10f1-4e73-91b3-bb0a2a8cdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jpn = df_jpn[~(df_jpn['data']==18)]\n",
    "df_math = df_math[~(df_math['data']==18)]\n",
    "df_eng = df_eng[~(df_eng['data']==18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09edbffe-7bf8-4f44-8756-976a802689ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22夏', '21冬', '21秋', '21夏', '20冬', '20秋', '20夏', '19冬', '19秋',\n",
       "       '19夏', '18冬', '18秋', '18夏'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jpn['ラベル'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e375a4a-a79e-4066-a29b-b50aa8e27d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22夏', '21夏', '21秋', '21冬', '21春', '20夏', '20秋', '20冬', '19夏',\n",
       "       '19秋', '19冬', '18夏', '18秋', '18冬'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_math['ラベル'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dceaf79-0633-403e-a658-477f2b55ff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22夏', '21冬', '21秋', '21夏', '20冬', '20秋', '20夏', '19冬', '19秋',\n",
       "       '19夏', '18冬', '18秋', '18夏'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng['ラベル'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9bc41-1ac9-40ed-89b3-4e150d4a56ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ab959-12d5-4ce6-823d-6178b9dfb6e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DecisionTreeRegressorメソッドの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618955c-8f83-48ea-93f6-62ba625af289",
   "metadata": {
    "tags": []
   },
   "source": [
    "|引数名|概要|デフォルト|\n",
    "| :---- | :---- | :---- |\n",
    "|criterion|不純度を測定する基準（平均二乗誤差、平均絶対誤差など）|‘mse’|\n",
    "|splitter|条件探索アルゴリズムを選択するオプション（’best’と’rondom’が指定可能）|‘best’|\n",
    "|max_depth|決定木のノード深さの制限値。ツリーが深くなりすぎて過学習の状態に陥った際は、このパラメータが正則化の役割を果たす。|None|\n",
    "|min_samples_split|ノードを分割するために必要なサンプルの最小値|2|\n",
    "|min_samples_leaf|1ノードの深さを作成するために必要となるデータ数の最小値。指定した値以上のデータ数を持たないノードは作られない。|1|\n",
    "|min_weight_fraction_leaf|サンプルの重みを考慮した上でのmin_samples_leafに該当|0.0|\n",
    "|max_features|ランダムに指定する説明変数の数(全ての説明変数がモデル学習に活用されるわけではなく、ランダムに割り振られる）|None|\n",
    "|random_state|乱数シード|None|\n",
    "|max_leaf_nodes|作成される決定木の葉の数を、指定した値以下に制御する|None|\n",
    "|min_impurity_decrease|決定木の成長の早期停止するための閾値。不純度が指定の値より減少した場合、ノードを分岐し、不純度が指定の値より減少しなければ分岐を抑制。|0.0|\n",
    "|ccp_alpha|ccp_alphaが大きいほどプルーニングされるノードの数が増加。プルーニングとは、精度低下をできるだけ抑えながら過剰な重みを排除するプロセスを指す。|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41ca56-b79f-4fc9-b31b-0124275aca28",
   "metadata": {},
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce4f56e3-afa1-4494-947c-01e779ddfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
    "ダミー変数を元に戻す。エクセル出力用\n",
    "\"\"\"\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b16875-94cc-4b1b-9658-8a485473e99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', '分野', 'ロット番号', 'ポイント採点', '文字数', 'ポイント数',\n",
       "       '配点要素の数', '配点', '必須条件の有無', '在宅勤務', '企画ペース', '最終ペース', 'data', 'ラベル'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jpn.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c74dc4c-34ba-4bb3-a31f-34ce39e13092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', 'ロット番号', '（1）実点・立式点', '（1）カッコ点・立式点',\n",
       "       '（1）実点・答え点', '（1）カッコ点・答え点', '（1）実点・その他', '（1）カッコ点・その他',\n",
       "       '（2）実点・立式点', '（2）カッコ点・立式点', '（2）実点・答え点', '（2）カッコ点・答え点',\n",
       "       '（2）実点・その他', '（2）カッコ点・その他', '（3）実点・立式点', '（3）カッコ点・立式点',\n",
       "       '（3）実点・答え点', '（3）カッコ点・答え点', '（3）実点・その他', '（3）カッコ点・その他',\n",
       "       '（1）ポイント数合計', '（2）ポイント数合計', '（3）ポイント数合計', 'ポイント採点', '（1）配点',\n",
       "       '（2）配点', '（3）配点', '企画ペース', '最終ペース', '模範解答の記述行数（１）', '模範解答の記述行数（２）',\n",
       "       '模範解答の記述行数（３）', '補足資料の枚数', '在宅勤務', '分野', 'data', 'ラベル'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_math.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb5bb870-0f71-4108-b50d-b2c3d2008933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', 'ロット番号', '大問', '分野', '解答言語', 'ポイント採点',\n",
       "       '企画ペース', '最終ペース', 'パターン数', '配点合計', '文字数合計', 'ポイント数合計', '減点要素の数合計',\n",
       "       '在宅勤務', 'data', 'ラベル'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "613da24b-7ee7-4a2f-a1a1-4449ce8ecfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data(df_input, data = int, kamoku=str):#秋採点予測用前処理\n",
    "    \n",
    "    \"\"\"\n",
    "    国語モデル用の学習と検証データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    x = data\n",
    "    if kamoku == 'jpn':\n",
    "        #jpn\n",
    "        #1.不要な列削除\n",
    "        df = df.drop(columns = [\"科目\"])\n",
    "\n",
    "        #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "        df = pd.get_dummies(df, columns=['分野'])\n",
    "    if kamoku == 'math':\n",
    "        #math\n",
    "        #1.不要な列削除\n",
    "        df = df.drop(columns = ['補足資料の枚数'])\n",
    "\n",
    "        #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "        df = pd.get_dummies(df, columns=['科目','分野'])\n",
    "    if kamoku == 'eng':\n",
    "        #1.不要な列削除\n",
    "        df = df.drop(columns = ['大問','科目'])\n",
    "\n",
    "        #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "        df = pd.get_dummies(df, drop_first=True, columns=['解答言語'])\n",
    "        df = pd.get_dummies(df, columns=['分野'])\n",
    "    \n",
    "    \"\"\"\n",
    "    #2.1 予測DFと学習検証DFの作成\n",
    "    df_pred = df.copy()  \n",
    "    df_pred= df_pred[df_pred['data'] == x]#納品する用の予測値算出に使うデータ。納品データの型にも使う。\n",
    "    df = df[~(df['data'] == x)]#モデル作成と検証に使うデータ。22秋を除いて作成。\n",
    "    \"\"\"\n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = {\"最終ペース\"})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['最終ペース','data']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~(df_X['data'] == x)]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~(df_y['data'] == x)]\n",
    "\n",
    "    \"\"\"検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[df_X['data'] == x]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[df_y['data'] == x]\n",
    "    \n",
    "    \"\"\"納品用\"\"\"\n",
    "    \"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_pred = df_pred.drop(columns = {\"最終ペース\",\"企画ペース\",'採点回',\"年度\",'ロット番号','data'})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    #訓練用目的変数\n",
    "    #y_pred = df_pred.loc[:,['年度','採点回_夏','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \"\"\"\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回\",\"年度\",\"ロット番号\",'ラベル','data']#結果出力で使うけど学習には使わない\n",
    "    rem_cols_y = ['data']\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_kikaku =X_test.loc[:,['企画ペース']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_kikaku]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e280a5af-7c0a-4398-9a87-adf07a3e8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "モデル作成\n",
    "\"\"\"\n",
    "def train_model(df,a=2,b=1,c=None):\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    model = DecisionTreeRegressor(criterion='mse', \n",
    "                                   splitter='best', \n",
    "                                   max_depth=c, \n",
    "                                   min_samples_split=a, #3,4,5とか？\n",
    "                                   min_samples_leaf=b,#2とか \n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features=None, \n",
    "                                   random_state=0,#出力結果の固定のため \n",
    "                                   max_leaf_nodes=None, \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   ccp_alpha=0.0\n",
    "                                  )\n",
    "\n",
    "    #上記のパラメータでモデルを学習する\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aad7d6ce-2b2f-4c2b-bc4a-a9a9be99f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_past_summary(X_train,y_train): \n",
    "    \"\"\"\n",
    "    学習データを使って分野別の集計値を返す\n",
    "    \"\"\"\n",
    "    #X_trainとy_trainをconcatしたdfを作る\n",
    "    df = pd.concat([X_train, y_train], axis=1)\n",
    "    #dfをundemmify\n",
    "    df = undummify(df)\n",
    "\n",
    "    group_df1 = df[['分野','学年','最終ペース']].groupby(['分野','学年']).mean().round(1).rename(columns={\"最終ペース\":\"学習データ_平均値\"})\n",
    "    group_df1.reset_index(inplace=True)\n",
    "\n",
    "    group_df2 = df[['分野','学年','最終ペース']].groupby(['分野','学年']).max().round(1).rename(columns={\"最終ペース\":\"学習データ_最大値\"})\n",
    "    group_df2.reset_index(inplace=True)\n",
    "\n",
    "    group_df3 = df[['分野','学年','最終ペース']].groupby(['分野','学年']).min().round(1).rename(columns={\"最終ペース\":\"学習データ_最小値\"})\n",
    "    group_df3.reset_index(inplace=True)\n",
    "\n",
    "    group_df4 = df[['分野','学年','最終ペース']].groupby(['分野','学年']).median().round(1).rename(columns={\"最終ペース\":\"学習データ_中央値\"})\n",
    "    group_df4.reset_index(inplace=True)\n",
    "\n",
    "    group_df5 = df[['分野','学年','最終ペース']].groupby(['分野','学年']).count().round(1).rename(columns={\"最終ペース\":\"学習データ_N数\"})\n",
    "    group_df5.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    # merge\n",
    "    group_df = pd.merge(group_df1,group_df2, on = ['分野','学年'],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df3, on = ['分野','学年'],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df4, on = ['分野','学年'],how = 'left')\n",
    "    group_df = pd.merge(group_df,group_df5, on = ['分野','学年'],how = 'left')\n",
    "    #group_df = group_df.rename(columns={category:\"分野\"})\n",
    "    return group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "815d5fff-162f-40f1-b0f6-89f206240927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(df): \n",
    "    \"\"\"\n",
    "    学習データを結合したdfを返す\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    #X_trainとy_trainをconcatしたdfを作る\n",
    "    df = pd.concat([X_train, y_train], axis=1)\n",
    "    #dfをundemmify\n",
    "    res = undummify(df)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7645d667-974a-4826-92a4-aedae1d0e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(df,model):# 検証データの予測値を出し、使用した訓練データの過去集計値をくっつける.\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、乖離度（予測値/実測値）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    y_train= df[1]\n",
    "    X_test = df[2]\n",
    "    y_test = df[3]\n",
    "    X_test_kikaku = df[4]\n",
    "    y_pred  = model.predict(X_test)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(X_test) \n",
    "    df_res.loc[:,'AI予測ペース']= y_pred #上のデータに予測値をマージ\n",
    "    df_res.loc[:,'企画ペース']= X_test_kikaku\n",
    "    df_res.loc[:,'最終ペース']= y_test\n",
    "    df_res.loc[:,'AI予測/人予測']= df_res['AI予測ペース']/df_res['企画ペース']#AI予測値と人予測値の比率を列に追加 \n",
    "    df_res.loc[:,'AI乖離度']= df_res['AI予測ペース']/df_res['最終ペース']#実測値と予測値の比率を列に追加 \n",
    "    df_res.loc[:,'元の乖離度']= df_res['企画ペース']/df_res['最終ペース']#実測値と予測値の比率を列に追加       \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "    choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "    df_res.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "    \n",
    "    # 最終ペースをランク分け\n",
    "    x = \"最終ペース\"\n",
    "    conditions = [\n",
    "        (df_res[x] >= 600),\n",
    "        (df_res[x] >= 550),\n",
    "        (df_res[x] >= 500),\n",
    "        (df_res[x] >= 450),\n",
    "        (df_res[x] >= 400),\n",
    "        (df_res[x] >= 350),\n",
    "        (df_res[x] >= 300),\n",
    "        (df_res[x] >= 250),\n",
    "        (df_res[x] >= 200),\n",
    "        (df_res[x] >= 150),\n",
    "        (df_res[x] >= 100),\n",
    "        (df_res[x] >= 50),\n",
    "        (df_res[x] >= 0)\n",
    "         ]\n",
    "    choices = [\"600~\", \"550~600\", \"500~550\", \"450~500\", \"400~450\", \"350~400\",\"300~350\",\n",
    "               \"250~300\", \"200~250\", \"150~200\", \"100~150\", \"050~100\",\"00〜50\"]\n",
    "    df_res.loc[:,'最終ランク2'] = np.select(conditions, choices, default = 0)\n",
    "    \n",
    "    #大外れの予測値に対してフラグ作成\n",
    "    x = \"AI予測/人予測\"\n",
    "    conditions = [\n",
    "        (df_res[x] > 1.5),\n",
    "        (df_res[x] < 0.5)\n",
    "         ]\n",
    "    choices = [1,1]\n",
    "    df_res.loc[:,'flag_AI予測/人予測'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "    x = \"AI乖離度\"\n",
    "    conditions = [\n",
    "        (df_res[x] > 1.5),\n",
    "        (df_res[x] < 0.5)\n",
    "         ]\n",
    "    choices = [1,1]\n",
    "    df_res.loc[:,'flag_AI予測/実測値'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "    x = \"元の乖離度\"\n",
    "    conditions = [\n",
    "        (df_res[x] > 1.5),\n",
    "        (df_res[x] < 0.5)\n",
    "         ]\n",
    "    choices = [1,1]\n",
    "    df_res.loc[:,'flag_企画/実測値'] = np.select(conditions, choices, default = 0)\n",
    "    \n",
    "    df_ref = make_past_summary(X_train,y_train)\n",
    "    df_res = pd.merge(df_res,df_ref, on = ['分野','学年'],how = 'left')\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3708adb1-0732-46fb-a978-0b2a348afafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(df,model):# 予測データの予測値を出し、使用した訓練データの過去集計値をくっつける.\n",
    "    \"\"\"\n",
    "    モデルを使って、予測値を出し、予測値、最終ペース、差分、乖離度（予測値/最終ペース）を列に追加したdfを返す。\n",
    "    \"\"\"\n",
    "    X_train= df[0]#訓練の説明変数\n",
    "    y_train= df[1]#訓練の目的変数\n",
    "    X_pred = df[5]#予測の説明変数\n",
    "    df_pred = df[6]#予測の元データ。説明変数以外の情報を含む。\n",
    "    y_pred  = model.predict(X_pred)\n",
    "    \n",
    "    #得た結果を学習データとマージしてデータフレームで返す\n",
    "    df_res=[]\n",
    "    df_res = undummify(df_pred) \n",
    "    df_res.loc[:,'AI想定ペース']= y_pred #上のデータに予測値をマージ\n",
    "    #訓練データの統計量を作成して、結合\n",
    "    df_ref = make_past_summary(X_train,y_train)\n",
    "    df_res = pd.merge(df_res,df_ref, on = ['分野','学年'],how = 'left')\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ace7b1-b6b5-43be-ba98-f350497a4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(df,model):\n",
    "    \"\"\"\n",
    "    変数の重要度を返す\n",
    "    \"\"\"\n",
    "    X_test = df[2]\n",
    "    feature = model.feature_importances_\n",
    "    label = X_test.columns\n",
    "    indices = np.argsort(feature)\n",
    "\n",
    "    # 特徴量の重要度の棒グラフ\n",
    "    fig =plt.figure (figsize = (10,10))\n",
    "    plt.ion()\n",
    "    plt.barh(range(len(feature)), feature[indices])\n",
    "    plt.yticks(range(len(feature)), label[indices], fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.ylabel(\"Feature\", fontsize=18)\n",
    "    plt.xlabel(\"Feature Importance\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3962c3c-804f-4cb9-98f6-5920ed5c6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用ライブラリ　樹形図作成\n",
    "# from sklearn import tree\n",
    "# import graphviz\n",
    "def make_treegraph(df,model):\n",
    "    \"\"\"\n",
    "    樹形図を作成し、返す\n",
    "    \"\"\"\n",
    "    X_train= df[0]\n",
    "    X_train_feature_names = X_train.columns.values.tolist()\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "                                    feature_names= X_train_feature_names,\n",
    "                                    # class_names=iris.target_names,\n",
    "                                    filled=True, rounded=True, special_characters=True\n",
    "                                    )\n",
    "    treegraph = graphviz.Source(dot_data) \n",
    "    return treegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f95656a-7b3e-4823-b08d-89f8e218f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行関数\n",
    "def get_result(df_input,data,kamoku):\n",
    "    df = df_input.copy()\n",
    "    df_pret = make_data(df,data,kamoku)#データマートをML用に整形\n",
    "    model = train_model(df_pret,a=2,b=1,c=None)#モデル訓練\n",
    "    df_test = get_test(df_pret, model)#検証データ\n",
    "    df_res = df_test\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8feda705-5cbe-4a1e-bc22-e136e7bfd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#繰り返しの実行\n",
    "\n",
    "def get_output(df_input,kamoku):\n",
    "    df = df_input.copy()\n",
    "    data_list = sorted(df['data'].unique())#リストを作成し昇順に並び替え\n",
    "    df_res=[]\n",
    "    for i in data_list:\n",
    "        ret = get_result(df,i,kamoku)\n",
    "        ret['data']=i #予測結果にdataをデータグループとしてつける\n",
    "        df_res.append(ret)\n",
    "    #集計結果を一つのDFに結合\n",
    "    dfs = df_res[0]\n",
    "    for i in df_res[1:]:\n",
    "        dfs = dfs.append(i)\n",
    "    #ラベル作成\n",
    "    df_label= df[['data','ラベル']]\n",
    "    df_label = df_label.drop_duplicates()\n",
    "    #join\n",
    "    df1 = dfs\n",
    "    df2 = df_label\n",
    "    result = pandas_tool.merge(df1,df2, key = [\"data\"],how = 'left')\n",
    "    #企画ペースの欠損削除\n",
    "    colname='企画ペース'\n",
    "    result2 = result.dropna(subset=[colname])\n",
    "    results =[result, result2]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13102faa-b3ef-4660-9d5c-10925d6e0e4e",
   "metadata": {},
   "source": [
    "## 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d087ae2b-888c-4305-9ee3-9282bd90f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "319\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:332\n",
      "df2のオブザベーション:13\n",
      "mergeのオブザベーション:332\n"
     ]
    }
   ],
   "source": [
    "#予測値のDF作成\n",
    "df_res_jpn = get_output(df_jpn,'jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac891f78-1903-400c-af36-ba94c596bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI予測ペース','AI予測/人予測','AI乖離度','元の乖離度']\n",
    "df_dm = df_jpn #データマート\n",
    "df_res = df_res_jpn\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_国語_1215_v3\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='データマート',encoding='utf-8-sig', index = False)\n",
    "    df_res[0].to_excel(writer, sheet_name='検証値',encoding='utf-8-sig', index = False)\n",
    "    df_res[1].to_excel(writer, sheet_name='検証値_企画ペース0除去',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df_res[0].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7800af82-3a1f-4532-a7b0-6102c94091a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "449\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:463\n",
      "df2のオブザベーション:14\n",
      "mergeのオブザベーション:463\n"
     ]
    }
   ],
   "source": [
    "#予測値のDF作成\n",
    "df_res_math = get_output(df_math,'math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0db11aa2-b895-4980-8a83-e40079bcaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI予測ペース','AI予測/人予測','AI乖離度','元の乖離度']\n",
    "df_dm = df_math #データマート\n",
    "df_res = df_res_math\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_数学_1215_v3\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='データマート',encoding='utf-8-sig', index = False)\n",
    "    df_res[0].to_excel(writer, sheet_name='検証値',encoding='utf-8-sig', index = False)\n",
    "    df_res[1].to_excel(writer, sheet_name='検証値_企画ペース0除去',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df_res[0].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29dfb04e-f74e-40bc-b0a2-34cc0a97242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "339\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:352\n",
      "df2のオブザベーション:13\n",
      "mergeのオブザベーション:352\n"
     ]
    }
   ],
   "source": [
    "#予測値のDF作成\n",
    "df_res_eng = get_output(df_eng,'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e78c90d6-3f21-43c7-9ba1-0d37b90174e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI予測ペース','AI予測/人予測','AI乖離度','元の乖離度']\n",
    "df_dm = df_eng #データマート\n",
    "df_res = df_res_eng\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_英語_1215_v3\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='データマート',encoding='utf-8-sig', index = False)\n",
    "    df_res[0].to_excel(writer, sheet_name='検証値',encoding='utf-8-sig', index = False)\n",
    "    df_res[1].to_excel(writer, sheet_name='検証値_企画ペース0除去',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df_res[0].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc111f93-93b6-4039-859e-aa1fd90cb5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "csvの書き出し\n",
    "\"\"\"\n",
    "#保存先\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "df = df_res_jpn[0]\n",
    "name = \"採点ペース_学習データ分布_国語_v1\"\n",
    "df.to_csv('{}/{}.csv'.format(path_folder,\"{}\".format(name)),encoding='utf-8-sig',index=False)\n",
    "\n",
    "df = df_res_math[0]\n",
    "name = \"採点ペース_学習データ分布_数学_v1\"\n",
    "df.to_csv('{}/{}.csv'.format(path_folder,\"{}\".format(name)),encoding='utf-8-sig',index=False)\n",
    "\n",
    "df = df_res_eng[0]\n",
    "name = \"採点ペース_学習データ分布_英語_v1\"\n",
    "df.to_csv('{}/{}.csv'.format(path_folder,\"{}\".format(name)),encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653610e3-8f3b-40e2-bd36-b1e82fa9400f",
   "metadata": {},
   "source": [
    "# 予測値の集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b3e4da1-4a60-4a0c-9f2b-6baebda69d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_jpn\n",
    "df_input2 = df_res_jpn[0]\n",
    "kamoku = '国語'\n",
    "#学習データの科目分野別基礎統計量を作る\n",
    "df1 = df_input.copy()\n",
    "df1g = df1[['分野','最終ペース']].groupby(['分野']).describe().round(1)\n",
    "\n",
    "#予測値の科目分野別基礎統計量を作る\n",
    "df2 = df_input2.copy()\n",
    "df2g = df2[['分野','AI乖離度','flag_AI予測/実測値']].groupby(['分野']).describe().round(2)\n",
    "\n",
    "#分野名で結合する\n",
    "df_ret = pd.merge(df1g,df2g, on = ['分野'],how = 'left')\n",
    "df_ret['科目']= kamoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "343aa734-aeca-46e2-b507-992f90c7b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stat_table(df_input, df_input2):\n",
    "    #学習データの科目分野別基礎統計量を作る\n",
    "    df1 = df_input.copy()\n",
    "    df1g = df1[['分野','最終ペース']].groupby(['分野']).describe().round(1)\n",
    "\n",
    "    #予測値の科目分野別基礎統計量を作る\n",
    "    df2 = df_input2.copy()\n",
    "    df2g = df2[['分野','AI乖離度','flag_AI予測/実測値']].groupby(['分野']).describe().round(2)\n",
    "\n",
    "    #分野名で結合する\n",
    "    df_ret = pd.merge(df1g,df2g, on = ['分野'],how = 'left')\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6832d5ce-2b50-401c-93a8-c1c5bce39fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat_jpn = make_stat_table(df_jpn,df_res_jpn[0])\n",
    "df_stat_math = make_stat_table(df_math,df_res_math[0])\n",
    "df_stat_eng = make_stat_table(df_eng,df_res_eng[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "837c116f-b855-49c5-8023-2740787db579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "df1 = df_stat_jpn\n",
    "df2 = df_stat_math\n",
    "df3 = df_stat_eng\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_予測集計_v2\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df1.to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = True)\n",
    "    df2.to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = True)\n",
    "    df3.to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaaa8d8-fc4e-4fd7-b34b-11faa86098eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6265b79a-1977-4e55-9052-06dd3061e71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_jpn(df_input, data = int):#秋採点予測用前処理\n",
    "    \n",
    "    \"\"\"\n",
    "    国語モデル用の学習と検証データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    x = data\n",
    "\n",
    "    #1.不要な列削除\n",
    "    df = df.drop(columns = [\"科目\"])\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['分野'])\n",
    "    \"\"\"\n",
    "    #2.1 予測DFと学習検証DFの作成\n",
    "    df_pred = df.copy()  \n",
    "    df_pred= df_pred[df_pred['data'] == x]#納品する用の予測値算出に使うデータ。納品データの型にも使う。\n",
    "    df = df[~(df['data'] == x)]#モデル作成と検証に使うデータ。22秋を除いて作成。\n",
    "    \"\"\"\n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = {\"最終ペース\"})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['最終ペース','data']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~(df_X['data'] == x)]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~(df_y['data'] == x)]\n",
    "\n",
    "    \"\"\"検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[df_X['data'] == x]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[df_y['data'] == x]\n",
    "    \n",
    "    \"\"\"納品用\"\"\"\n",
    "    \"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_pred = df_pred.drop(columns = {\"最終ペース\",\"企画ペース\",'採点回',\"年度\",'ロット番号','data'})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    #訓練用目的変数\n",
    "    #y_pred = df_pred.loc[:,['年度','採点回_夏','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \"\"\"\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回\",\"年度\",\"ロット番号\",'data']#結果出力で使うけど学習には使わない\n",
    "    rem_cols_y = ['data']\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_kikaku =X_test.loc[:,['企画ペース']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    # df_res=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_kikaku]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6274f997-9ee9-4fe1-b18e-a35481ae788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行関数\n",
    "def get_result_jpn(df_input,data):\n",
    "    df = df_input.copy()\n",
    "    df_pret = make_data_jpn(df,data)#データマートをML用に整形\n",
    "    model = train_model(df_pret,a=2,b=1,c=None)#モデル訓練\n",
    "    df_test = get_test(df_pret, model)#検証データ\n",
    "    df_res = df_test\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94ffa8b3-9474-41a1-aad4-dc5e420b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#繰り返しの実行\n",
    "\n",
    "def get_output(df_input):\n",
    "    df = df_input.copy()\n",
    "    data_list = sorted(df['data'].unique())#リストを作成し昇順に並び替え\n",
    "    df_res=[]\n",
    "    for i in data_list:\n",
    "        ret = get_result_jpn(df,i)\n",
    "        ret['data_group']=i #予測結果にdataをデータグループとしてつける\n",
    "        df_res.append(ret)\n",
    "    #集計結果を一つのDFに結合\n",
    "    dfs = df_res[0]\n",
    "    for i in df_res[1:]:\n",
    "        dfs = dfs.append(i)\n",
    "    colname='企画ペース'\n",
    "    dfs2 = dfs.dropna(subset=[colname])\n",
    "    df_ret =[dfs,dfs2]\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ae5f6cb-f4b6-4042-a6a7-e91bf7337978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測値のDF作成\n",
    "df_test = get_output(df_jpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "040636b5-9b62-44fc-9e92-ca990a4afc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "\n",
    "name = \"誤差分析_v1.1\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "#Excel\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name)) as writer:\n",
    "    df_test[0].to_excel(writer, sheet_name='data',encoding='utf-8-sig', index = False)\n",
    "    df_test[1].to_excel(writer, sheet_name='企画ペース空白削除',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5983225b-7b03-4e53-ba5a-d17977062044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI予測ペース','AI予測/人予測','AI乖離度','元の乖離度']\n",
    "df_dm = df_jpn #データマート\n",
    "df_res = df_test\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_国語_1215_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='データマート',encoding='utf-8-sig', index = False)\n",
    "    df_res[0].to_excel(writer, sheet_name='検証値',encoding='utf-8-sig', index = False)\n",
    "    df_res[1].to_excel(writer, sheet_name='検証値_企画ペース0除去',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df_res[0].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約',encoding='utf-8-sig', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ab5e69-53ea-4322-b340-946773b72df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def make_data_jpn(df_input):#秋採点予測 orijinal\n",
    "    \n",
    "    \"\"\"\n",
    "    国語モデル用の学習と検証データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "\n",
    "    #1.不要な列削除\n",
    "    df = df.drop(columns = [\"科目\"])\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['分野'])\n",
    "    df_pred = df.copy()\n",
    "    df_pred= df_pred[(df_pred['採点回'] == '秋')&(df_pred['年度']==2022)]#納品する用の予測値算出に使うデータ。納品データの型にも使う。\n",
    "    df = df[~((df['採点回'] == '秋')&(df['年度']==2022))]#モデル作成と検証に使うデータ。22秋を除いて作成。\n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = {\"最終ペース\"})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回'] == '夏')&(df_X['年度']==2022))]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回'] == '夏')&(df_y['年度']==2022))]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回'] == '夏')&(df_X['年度']==2022)]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回'] == '夏')&(df_y['年度']==2022)]\n",
    "    \"\"\"22秋が納品用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_pred = df_pred.drop(columns = {\"最終ペース\",\"企画ペース\",'採点回',\"年度\",'ロット番号'})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    #訓練用目的変数\n",
    "    #y_pred = df_pred.loc[:,['年度','採点回_夏','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回\",\"年度\",\"ロット番号\"]\n",
    "    rem_cols_y = [\"採点回\",\"年度\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_kikaku =X_test.loc[:,['企画ペース']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "\n",
    "    return df_res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "372f0662-84e3-4a56-b5ae-9e324908b18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_pret_jpn = make_data_jpn(df_jpn)#旧変数で2020-2021\\nmodel_jpn = train_model(df_pret_jpn,a=2,b=1,c=None)\\ndf_train=get_train(df_pret_jpn)\\ndf_test = get_test(df_pret_jpn, model_jpn)\\ndf_pred = get_pred(df_pret_jpn, model_jpn)\\ndf_res_jpn=[df_train, df_test, df_pred]\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#機械学習の実行\n",
    "\"\"\"\n",
    "df_pret_jpn = make_data_jpn(df_jpn)#旧変数で2020-2021\n",
    "model_jpn = train_model(df_pret_jpn,a=2,b=1,c=None)\n",
    "df_train=get_train(df_pret_jpn)\n",
    "df_test = get_test(df_pret_jpn, model_jpn)\n",
    "df_pred = get_pred(df_pret_jpn, model_jpn)\n",
    "df_res_jpn=[df_train, df_test, df_pred]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d23c2b60-d4b0-4906-9061-1e6d3b652e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#機械学習の実行関数\n",
    "def get_result_jpn(df_input):\n",
    "    df = df_input.copy()\n",
    "    df_pret = make_data_jpn(df)#データマートをML用に整形\n",
    "    model = train_model(df_pret,a=2,b=1,c=None)#モデル訓練\n",
    "    df_train= get_train(df_pret)#訓練データ\n",
    "    df_test = get_test(df_pret, model)#検証データ\n",
    "    df_pred = get_pred(df_pret, model)#予測データ\n",
    "    df_res=[df_pret, model, df_train, df_test, df_pred]#予測用\n",
    "    return df_res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02acb289-2d81-442e-a714-bab184f39b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行\n",
    "df_res_jpn = get_result_jpn(df_jpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0d16a9-d39f-45ea-b16a-c38acf6ec21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習値と予測値の説明変数の列の並びが等しいか\n",
    "#df_res[0]=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "df = df_res_jpn\n",
    "df[0][0].columns.values == df[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b01149e-a7d8-4690-bf32-d01fc8aab827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['学年', 'ポイント採点', '文字数', 'ポイント数', '配点要素の数', '配点', '必須条件の有無', '在宅勤務',\n",
       "       '分野_古文（内説）', '分野_古文（現訳）', '分野_小説', '分野_漢文（内説）', '分野_漢文（書下し）',\n",
       "       '分野_漢文（現訳）', '分野_評論', '分野_随筆'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#説明変数の確認\n",
    "df_res_jpn[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda7303a-2871-4866-b97a-d524d2a29388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データの数\n",
    "len(df_jpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2834c7f3-53f7-485d-bb4c-37d62724773d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習するデータの数\n",
    "len(df_res_jpn[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b863d0-dfad-40dc-84c5-e304b77de6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証するデータの数\n",
    "len(df_res_jpn[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b194e8c-7e6d-4e13-8ca8-a82d8e3a962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測するデータの数\n",
    "len(df_res_jpn[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba32800f-ce0c-4bd3-a212-a076f1a8448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','実企誤差','実予誤差','AI乖離度','元の乖離度']\n",
    "df=df_res_jpn\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測誤差_国語_1215_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[2].to_excel(writer, sheet_name='訓練値_国語',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='検証値_国語',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df[3].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約_国語',encoding='utf-8-sig', index = True)\n",
    "    df[4].to_excel(writer, sheet_name='予測値_国語',encoding='utf-8-sig', index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a47459-1ac0-4a27-a73f-3afe5e8f09fb",
   "metadata": {},
   "source": [
    "## 数学でモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e8288ac-cb43-4af6-8158-0e72fae3f355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_math(df_input):#秋採点予測　orijinal\n",
    "    \n",
    "    \"\"\"\n",
    "    国語モデル用の学習と検証データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "\n",
    "    #1.不要な列削除\n",
    "    df = df.drop(columns = ['補足資料の枚数'])\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, columns=['科目','分野'])\n",
    "    df_pred = df.copy()\n",
    "    df_pred= df_pred[(df_pred['採点回'] == '秋')&(df_pred['年度']==2022)]#納品する用の予測値算出に使うデータ。納品データの型にも使う。\n",
    "    df = df[~((df['採点回'] == '秋')&(df['年度']==2022))]#モデル作成と検証に使うデータ。22秋を除いて作成。\n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = {\"最終ペース\"})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回'] == '夏')&(df_X['年度']==2022))]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回'] == '夏')&(df_y['年度']==2022))]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回'] == '夏')&(df_X['年度']==2022)]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回'] == '夏')&(df_y['年度']==2022)]\n",
    "    \"\"\"22秋が納品用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_pred = df_pred.drop(columns = {\"最終ペース\",\"企画ペース\",'採点回',\"年度\",'ロット番号'})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    #訓練用目的変数\n",
    "    #y_pred = df_pred.loc[:,['年度','採点回_夏','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回\",\"年度\",\"ロット番号\"]\n",
    "    rem_cols_y = [\"採点回\",\"年度\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_kikaku =X_test.loc[:,['企画ペース']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2300c2f-8482-428a-a2aa-0b2921d86030",
   "metadata": {},
   "source": [
    "## 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9718066b-1886-43af-9466-c25cc1fbdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行関数\n",
    "def get_result_math(df):\n",
    "    df_pret = make_data_math(df)#旧変数で2020-2021\n",
    "    model = train_model(df_pret,a=2,b=1,c=None)\n",
    "    df_train= get_train(df_pret)\n",
    "    df_test = get_test(df_pret, model)\n",
    "    df_pred = get_pred(df_pret, model)\n",
    "    df_res=[df_pret, model, df_train, df_test, df_pred]\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac7b69be-6302-43ec-b3a4-2d05182f74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行\n",
    "df_res_math = get_result_math(df_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70f114be-bdfe-480c-82ea-6d62055e34ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習値と予測値の説明変数の列の並びが等しいか\n",
    "#df_res[0]=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "df = df_res_math\n",
    "df[0][0].columns.values == df[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bda700a-e725-4510-bad0-013a029c132e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['学年', '（1）実点・立式点', '（1）カッコ点・立式点', '（1）実点・答え点', '（1）カッコ点・答え点',\n",
       "       '（1）実点・その他', '（1）カッコ点・その他', '（2）実点・立式点', '（2）カッコ点・立式点',\n",
       "       '（2）実点・答え点', '（2）カッコ点・答え点', '（2）実点・その他', '（2）カッコ点・その他',\n",
       "       '（3）実点・立式点', '（3）カッコ点・立式点', '（3）実点・答え点', '（3）カッコ点・答え点',\n",
       "       '（3）実点・その他', '（3）カッコ点・その他', '（1）ポイント数合計', '（2）ポイント数合計',\n",
       "       '（3）ポイント数合計', 'ポイント採点', '（1）配点', '（2）配点', '（3）配点', '模範解答の記述行数（１）',\n",
       "       '模範解答の記述行数（２）', '模範解答の記述行数（３）', '在宅勤務', '科目_数学X', '科目_数学X/A',\n",
       "       '科目_数学X/A・Y/B', '科目_数学Y', '科目_数学Y/B', '科目_数学Z', '分野_いろいろな式',\n",
       "       '分野_データの分析', '分野_ベクトル', '分野_三角関数', '分野_二次関数', '分野_図形と方程式',\n",
       "       '分野_図形と計量', '分野_図形の性質', '分野_場合の数と確率', '分野_平面上の曲線と複素数平面',\n",
       "       '分野_微分法・積分法', '分野_指数関数・対数関数', '分野_数と式', '分野_数列', '分野_数列の極限',\n",
       "       '分野_整数の性質'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#説明変数の確認\n",
    "df_res_math[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e528a1f6-a4f0-412f-ae30-fc0881e87e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データの数\n",
    "len(df_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1f96fba-48db-4153-aa58-36baa1cd607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習するデータの数\n",
    "len(df_res_math[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65a19761-3394-4f22-8810-7f096207efc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証するデータの数\n",
    "len(df_res_math[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80a029f7-cab8-4a00-8497-81464966f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測するデータの数\n",
    "len(df_res_math[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c67b0b59-5825-4e17-ac31-99e79ded4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','実企誤差','実予誤差','AI乖離度','元の乖離度']\n",
    "df=df_res_math\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測_22秋後半納品_数学_1025_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[2].to_excel(writer, sheet_name='訓練値_数学',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='検証値_数学',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df[3].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約_数学',encoding='utf-8-sig', index = True)\n",
    "    df[4].to_excel(writer, sheet_name='予測値_数学',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d65e1e-cbde-4e9f-afd4-d3d9e7d9c875",
   "metadata": {},
   "source": [
    "## 英語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "951ebdd6-779d-443c-a472-7f2b485039d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['年度', '採点回', '学年', '科目', 'ロット番号', '大問', '分野', '解答言語', 'ポイント採点',\n",
       "       '企画ペース', '最終ペース', 'パターン数', '配点合計', '文字数合計', 'ポイント数合計', '減点要素の数合計',\n",
       "       '在宅勤務'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ceb8073-2ef2-4b3d-9d84-f3bbd29cb82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "年度            int64\n",
       "採点回          object\n",
       "学年            int64\n",
       "科目           object\n",
       "ロット番号        object\n",
       "大問            int64\n",
       "分野           object\n",
       "解答言語         object\n",
       "ポイント採点        int64\n",
       "企画ペース       float64\n",
       "最終ペース       float64\n",
       "パターン数         int64\n",
       "配点合計          int64\n",
       "文字数合計       float64\n",
       "ポイント数合計     float64\n",
       "減点要素の数合計      int64\n",
       "在宅勤務          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee1c72b0-a4d9-497e-beb3-c73a82ae6254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data_eng(df_input):#秋採点予測\n",
    "    \n",
    "    \"\"\"\n",
    "    国語モデル用の学習と検証データを作成\n",
    "    1.データから不要な列を削除\n",
    "    2.ダミー化\n",
    "    3.説明変数と目的変数に分ける\n",
    "    4.学習と検証に分ける\n",
    "    5.選択用変数を除外し、各データフレームを作成\n",
    "    6.[X_train,y_train,X_test,y_test,X_test_info]をデータフレームとしてreturn\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "\n",
    "    #1.不要な列削除\n",
    "    df = df.drop(columns = ['大問','科目'])\n",
    "\n",
    "    #2.名義変数のエンコーディング pandas get_dummies関数でone hot encording\n",
    "    df = pd.get_dummies(df, drop_first=True, columns=['解答言語'])\n",
    "    #df = pd.get_dummies(df, columns=['解答言語'])\n",
    "    df = pd.get_dummies(df, columns=['分野'])\n",
    "    df_pred = df.copy()\n",
    "    df_pred= df_pred[(df_pred['採点回'] == '秋')&(df_pred['年度']==2022)]#納品する用の予測値算出に使うデータ。納品データの型にも使う。\n",
    "    df = df[~((df['採点回'] == '秋')&(df['年度']==2022))]#モデル作成と検証に使うデータ。22秋を除いて作成。\n",
    "    #3.上記のデータセットを説明変数と目的変数で分ける\n",
    "    df_X = df.drop(columns = {\"最終ペース\"})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    df_y = df.loc[:,['年度','採点回','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #4.データフレームの分離\n",
    "    \"\"\"秋冬が訓練用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_train = df_X[~((df_X['採点回'] == '夏')&(df_X['年度']==2022))]\n",
    "    #訓練用目的変数\n",
    "    y_train = df_y[~((df_y['採点回'] == '夏')&(df_y['年度']==2022))]\n",
    "\n",
    "    \"\"\"22夏が検証用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_test = df_X[(df_X['採点回'] == '夏')&(df_X['年度']==2022)]\n",
    "    #訓練用目的変数\n",
    "    y_test = df_y[(df_y['採点回'] == '夏')&(df_y['年度']==2022)]\n",
    "    \"\"\"22秋が納品用\"\"\"\n",
    "    #訓練用説明変数\n",
    "    X_pred = df_pred.drop(columns = {\"最終ペース\",\"企画ペース\",'採点回',\"年度\",'ロット番号'})#目的変数を除外した（説明変数と選択用変数だけ含む）データフレーム\n",
    "    #訓練用目的変数\n",
    "    #y_pred = df_pred.loc[:,['年度','採点回_夏','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "    \n",
    "    #5.不要な変数を削除\n",
    "    rem_cols_x = [\"企画ペース\",\"採点回\",\"年度\",\"ロット番号\"]\n",
    "    rem_cols_y = [\"採点回\",\"年度\"]\n",
    "\n",
    "    #説明変数\n",
    "    X_train = X_train.drop(columns = rem_cols_x)\n",
    "    X_test_kikaku =X_test.loc[:,['企画ペース']]\n",
    "    X_test = X_test.drop(columns = rem_cols_x)\n",
    "         \n",
    "    #目的変数\n",
    "    y_train = y_train.drop(columns = rem_cols_y)\n",
    "    y_test = y_test.drop(columns = rem_cols_y)\n",
    "    \n",
    "    #各モデル用データを各データフレームにまとめ、それらをさらにデータフレームにまとめて返す。\n",
    "    df_res=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2b14-7578-44df-a15b-4c43373ad6c1",
   "metadata": {},
   "source": [
    "## 結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "293f340d-1abd-47dd-865e-2a93aac1ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行関数\n",
    "def get_result_eng(df):\n",
    "    df_pret = make_data_eng(df)#旧変数で2020-2021\n",
    "    model = train_model(df_pret,a=2,b=1,c=None)\n",
    "    df_train= get_train(df_pret)\n",
    "    df_test = get_test(df_pret, model)\n",
    "    df_pred = get_pred(df_pret, model)\n",
    "    df_res=[df_pret, model, df_train, df_test, df_pred]\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae0e20e5-e58c-49e5-ace8-cd21fb52d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習の実行\n",
    "df_res_eng = get_result_eng(df_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6497e1e3-3764-4a11-9327-1c51b207927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習値と予測値の説明変数の列の並びが等しいか\n",
    "#df_res[0]=[X_train,y_train,X_test,y_test,X_test_kikaku,X_pred,df_pred]\n",
    "df = df_res_eng\n",
    "df[0][0].columns.values == df[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6dd5030-fe88-487b-9b7c-56ac1587052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['学年', 'ポイント採点', 'パターン数', '配点合計', '文字数合計', 'ポイント数合計', '減点要素の数合計',\n",
       "       '在宅勤務', '解答言語_英語', '分野_リスニング', '分野_内容説明', '分野_和訳', '分野_自由英作文',\n",
       "       '分野_英作文', '分野_英作文（単語）', '分野_英訳', '分野_要約'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#説明変数の確認\n",
    "df_res_eng[0][5].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b69e5f1-4efa-4c57-8d77-3cc13b4e8fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データの数\n",
    "len(df_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce6f6852-8062-485c-a18d-825503e2d495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習するデータの数\n",
    "len(df_res_eng[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5cd3a62-12b1-47a6-8294-e628d0948bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証するデータの数\n",
    "len(df_res_eng[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3af74a82-0529-4c10-9d44-e1732b0d5e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測するデータの数\n",
    "len(df_res_eng[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26cb9bea-2706-429d-90a1-846cb5f14e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['学年', 'ポイント採点', 'パターン数', '配点合計', '文字数合計', 'ポイント数合計', '減点要素の数合計', '在宅勤務',\n",
       "       '解答言語', '分野', 'AI想定ペース', '最終ペース', '企画ペース', '実企誤差', '実予誤差', 'AI乖離度',\n",
       "       '元の乖離度', '最終ランク', '学習データ_平均値', '学習データ_最大値', '学習データ_最小値', '学習データ_中央値',\n",
       "       '学習データ_N数'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24d3f394-9ca9-4501-bb21-f688440e180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','実企誤差','実予誤差','AI乖離度','元の乖離度']\n",
    "df=df_res_eng.copy()\n",
    "\n",
    "\n",
    "name_file = \"分野別ペース予測_22秋後半納品_英語_1025_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df[2].to_excel(writer, sheet_name='訓練値_英語',encoding='utf-8-sig', index = False)\n",
    "    df[3].to_excel(writer, sheet_name='検証値_英語',encoding='utf-8-sig', index = False)\n",
    "    pandas_tool.summary(df[3].loc[:,select_cols])[0].to_excel(writer, sheet_name='検証値要約_英語',encoding='utf-8-sig', index = True)\n",
    "    df[4].to_excel(writer, sheet_name='予測値_英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16e2b8d8-6b00-4fa3-8baa-47efb660fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果出力\n",
    "select_cols = ['最終ペース','企画ペース','AI想定ペース','実企誤差','実予誤差','AI乖離度','元の乖離度']\n",
    "\n",
    "name_file = \"22秋後半_1028_DA予測値_設問別ペース_手動修正前_v1\" #ファイル名\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name_file)#ファイルパスとファイル名\n",
    "\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name_file)) as writer:\n",
    "    df_res_jpn[4].to_excel(writer, sheet_name='予測値_国語',encoding='utf-8-sig', index = False)\n",
    "    df_res_math[4].to_excel(writer, sheet_name='予測値_数学',encoding='utf-8-sig', index = False)\n",
    "    df_res_eng[4].to_excel(writer, sheet_name='予測値_英語',encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b90173-26d8-4f73-bc9d-5cdd6a170663",
   "metadata": {},
   "source": [
    "# 以下はメモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f52f54b3-6bda-414b-8abb-ec71b86d3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#重要度出力\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "\n",
    "res = get_importance(df_pret_eng, model_eng)\n",
    "name = \"分野別ペース予測重要度_英語_22夏検証_0905_v1\"#ファイル名\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "res.savefig('{}/{}.png'.format(path_folder,name), format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26f1334e-0817-4b95-84bc-50e750672e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/s.ogura/Documents/CRLEA/data/output/分野別ペース予測樹形図_英語_22夏検証_0905_v1.pdf'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#樹形図出力\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "\n",
    "treegraph = make_treegraph(df_pret_eng, model_eng)\n",
    "name = \"分野別ペース予測樹形図_英語_22夏検証_0905_v1\" #ファイル名\n",
    "path_file = r'{p}/{n}'.format(p = path_folder, n = name)#ファイルパスとファイル名\n",
    "treegraph.render(path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe180c3-786e-491a-90f5-117b113c339f",
   "metadata": {},
   "source": [
    "# 各科目の予測に用いた学年、分野、ランク別件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e632ac6-e2ab-4d86-be37-608a5d40dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:25\n",
      "df2のオブザベーション:90\n",
      "mergeのオブザベーション:25\n"
     ]
    }
   ],
   "source": [
    "df = df_jpn.copy()\n",
    "df = df.loc[:,['年度','採点回','学年','分野','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "\n",
    "x = \"最終ペース\"\n",
    "conditions = [\n",
    "        (df[x] >= 600),\n",
    "        (df[x] >= 500),\n",
    "        (df[x] >= 400),\n",
    "        (df[x] >= 300),\n",
    "        (df[x] >= 200),\n",
    "        (df[x] >= 100),\n",
    "        (df[x] >= 0)\n",
    "         ]\n",
    "choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "df.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "#3.上記のデータセットを説明変数と目的変数で分ける\n",
    "df_y = df[(df['採点回'] == '夏')&(df['年度']==2021)]\n",
    "df_X = df[~((df['採点回'] == '夏')&(df['年度']==2021))]\n",
    "\n",
    "df_y = df_y.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_y = df_y.sort_values(['分野','学年','最終ランク'])\n",
    "df_y = df_y.rename(columns = {'年度':'予測データの件数'})\n",
    "res_y = df_y.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "                            \n",
    "df_X = df_X.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_X = df_X.sort_values(['分野','学年','最終ランク'])\n",
    "df_X = df_X.rename(columns = {'年度':'学習データの件数'})\n",
    "res_X = df_X.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "res_j = pandas_tool.merge(res_y, res_X,key=['学年','最終ランク','分野'],how='left',view=True)\n",
    "res_j = res_j.fillna({'学習データの件数': 0})\n",
    "res_j['科目']='国語'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc3638b-1065-443b-8414-fb57d9c1e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:36\n",
      "df2のオブザベーション:125\n",
      "mergeのオブザベーション:36\n"
     ]
    }
   ],
   "source": [
    "df = df_math.copy()\n",
    "df = df.loc[:,['年度','採点回','学年','分野','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "\n",
    "x = \"最終ペース\"\n",
    "conditions = [\n",
    "        (df[x] >= 600),\n",
    "        (df[x] >= 500),\n",
    "        (df[x] >= 400),\n",
    "        (df[x] >= 300),\n",
    "        (df[x] >= 200),\n",
    "        (df[x] >= 100),\n",
    "        (df[x] >= 0)\n",
    "         ]\n",
    "choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "df.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "#3.上記のデータセットを説明変数と目的変数で分ける\n",
    "df_y = df[(df['採点回'] == '夏')&(df['年度']==2021)]\n",
    "df_X = df[~((df['採点回'] == '夏')&(df['年度']==2021))]\n",
    "\n",
    "df_y = df_y.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_y = df_y.sort_values(['分野','学年','最終ランク'])\n",
    "df_y = df_y.rename(columns = {'年度':'予測データの件数'})\n",
    "res_y = df_y.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "                            \n",
    "df_X = df_X.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_X = df_X.sort_values(['分野','学年','最終ランク'])\n",
    "df_X = df_X.rename(columns = {'年度':'学習データの件数'})\n",
    "res_X = df_X.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "res_m = pandas_tool.merge(res_y, res_X,key=['学年','最終ランク','分野'],how='left',view=True)\n",
    "res_m = res_m.fillna({'学習データの件数': 0})\n",
    "res_m['科目']='数学'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fc69d8c-5003-4b6c-a49d-68e26bc20f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1のキー重複\n",
      "0\n",
      "df2のキー重複\n",
      "0\n",
      "df1のオブザベーション:23\n",
      "df2のオブザベーション:64\n",
      "mergeのオブザベーション:23\n"
     ]
    }
   ],
   "source": [
    "df = df_eng.copy()\n",
    "df = df.loc[:,['年度','採点回','学年','分野','最終ペース']]#目的変数と選択用変数だけ含むデータフレーム\n",
    "\n",
    "x = \"最終ペース\"\n",
    "conditions = [\n",
    "        (df[x] >= 600),\n",
    "        (df[x] >= 500),\n",
    "        (df[x] >= 400),\n",
    "        (df[x] >= 300),\n",
    "        (df[x] >= 200),\n",
    "        (df[x] >= 100),\n",
    "        (df[x] >= 0)\n",
    "         ]\n",
    "choices = [\"600~\", \"500~600\", \"400~500\", \"300~400\", \"200~300\", \"100~200\",\"0~100\"]\n",
    "df.loc[:,'最終ランク'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "#3.上記のデータセットを説明変数と目的変数で分ける\n",
    "df_y = df[(df['採点回'] == '夏')&(df['年度']==2021)]\n",
    "df_X = df[~((df['採点回'] == '夏')&(df['年度']==2021))]\n",
    "\n",
    "df_y = df_y.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_y = df_y.sort_values(['分野','学年','最終ランク'])\n",
    "df_y = df_y.rename(columns = {'年度':'予測データの件数'})\n",
    "res_y = df_y.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "                            \n",
    "df_X = df_X.groupby(['学年','最終ランク','分野'],as_index=False).count()\n",
    "df_X = df_X.sort_values(['分野','学年','最終ランク'])\n",
    "df_X = df_X.rename(columns = {'年度':'学習データの件数'})\n",
    "res_X = df_X.drop(columns = ['採点回','最終ペース'])\n",
    "\n",
    "res_e = pandas_tool.merge(res_y, res_X,key=['学年','最終ランク','分野'],how='left',view=True)\n",
    "res_e = res_e.fillna({'学習データの件数': 0})\n",
    "res_e['科目']='英語'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d95fc6d-9c54-49d5-b6d3-c6cd86325ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excelの書き出し \n",
    "\"\"\"\n",
    "\n",
    "df1 = res_j\n",
    "df2 = res_m\n",
    "df3 = res_e\n",
    "\n",
    "name = \"分野別ペース予測8月モデル_学習検証データ件数\"\n",
    "path_folder = r\"/Users/s.ogura/Documents/CRLEA/data/output\"#フォルダパス\n",
    "\n",
    "#Excel\n",
    "with pd.ExcelWriter('{}/{}.xlsx'.format(path_folder,name)) as writer:\n",
    "    df1.to_excel(writer, sheet_name='国語',encoding='utf-8-sig', index = False)\n",
    "    df2.to_excel(writer, sheet_name='数学',encoding='utf-8-sig', index = False)\n",
    "    df3.to_excel(writer, sheet_name='英語',encoding='utf-8-sig', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
